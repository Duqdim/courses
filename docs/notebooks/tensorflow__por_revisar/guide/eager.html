

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2018 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2018 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow__por_revisar/guide/eager.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2018-The-TensorFlow-Authors.">
<h1>Copyright 2018 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2018-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="Eager-execution">
<h2>Eager execution<a class="headerlink" href="#Eager-execution" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>8a7ecd014bd5421f8057bc6eade7035d|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>9babae044a0f49d9af5c81c950c0dd25|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>a1d437c6b9ae4cb4988a574257e60af7|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>a36bf41c1fe34b1ab458bda3cba9ebd8|Download notebook</p>
</td></table><p>TensorFlow’s eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. To follow along with this guide, run the code samples below in an interactive <code class="docutils literal notranslate"><span class="pre">python</span></code> interpreter.</p>
<p>Eager execution is a flexible machine learning platform for research and experimentation, providing:</p>
<ul class="simple">
<li><p><em>An intuitive interface</em>—Structure your code naturally and use Python data structures. Quickly iterate on small models and small data.</p></li>
<li><p><em>Easier debugging</em>—Call ops directly to inspect running models and test changes. Use standard Python debugging tools for immediate error reporting.</p></li>
<li><p><em>Natural control flow</em>—Use Python control flow instead of graph control flow, simplifying the specification of dynamic models.</p></li>
</ul>
<p>Eager execution supports most TensorFlow operations and GPU acceleration.</p>
<p>Note: Some models may experience increased overhead with eager execution enabled. Performance improvements are ongoing, but please <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues">file a bug</a> if you find a problem and share your benchmarks.</p>
<div class="section" id="Setup-and-basic-usage">
<h3>Setup and basic usage<a class="headerlink" href="#Setup-and-basic-usage" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import os

import tensorflow as tf

import cProfile
</pre></div>
</div>
</div>
<p>In Tensorflow 2.0, eager execution is enabled by default.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>tf.executing_eagerly()
</pre></div>
</div>
</div>
<p>Now you can run TensorFlow operations and the results will return immediately:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x = [[2.]]
m = tf.matmul(x, x)
print(&quot;hello, {}&quot;.format(m))
</pre></div>
</div>
</div>
<p>Enabling eager execution changes how TensorFlow operations behave—now they immediately evaluate and return their values to Python. <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> objects reference concrete values instead of symbolic handles to nodes in a computational graph. Since there isn’t a computational graph to build and run later in a session, it’s easy to inspect results using <code class="docutils literal notranslate"><span class="pre">print()</span></code> or a debugger. Evaluating, printing, and checking tensor values does not break the flow for computing gradients.</p>
<p>Eager execution works nicely with <a class="reference external" href="http://www.numpy.org/">NumPy</a>. NumPy operations accept <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> arguments. The TensorFlow <code class="docutils literal notranslate"><span class="pre">tf.math</span></code> operations convert Python objects and NumPy arrays to <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> objects. The <code class="docutils literal notranslate"><span class="pre">tf.Tensor.numpy</span></code> method returns the object’s value as a NumPy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>a = tf.constant([[1, 2],
                 [3, 4]])
print(a)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Broadcasting support
b = tf.add(a, 1)
print(b)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Operator overloading is supported
print(a * b)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Use NumPy values
import numpy as np

c = np.multiply(a, b)
print(c)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Obtain numpy value from a tensor:
print(a.numpy())
# =&gt; [[1 2]
#     [3 4]]
</pre></div>
</div>
</div>
</div>
<div class="section" id="Dynamic-control-flow">
<h3>Dynamic control flow<a class="headerlink" href="#Dynamic-control-flow" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A major benefit of eager execution is that all the functionality of the host language is available while your model is executing. So, for example, it is easy to write <a class="reference external" href="https://en.wikipedia.org/wiki/Fizz_buzz">fizzbuzz</a>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def fizzbuzz(max_num):
  counter = tf.constant(0)
  max_num = tf.convert_to_tensor(max_num)
  for num in range(1, max_num.numpy()+1):
    num = tf.constant(num)
    if int(num % 3) == 0 and int(num % 5) == 0:
      print(&#39;FizzBuzz&#39;)
    elif int(num % 3) == 0:
      print(&#39;Fizz&#39;)
    elif int(num % 5) == 0:
      print(&#39;Buzz&#39;)
    else:
      print(num.numpy())
    counter += 1
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>fizzbuzz(15)
</pre></div>
</div>
</div>
<p>This has conditionals that depend on tensor values and it prints these values at runtime.</p>
</div>
<div class="section" id="Eager-training">
<h3>Eager training<a class="headerlink" href="#Eager-training" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Computing-gradients">
<h4>Computing gradients<a class="headerlink" href="#Computing-gradients" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation">Automatic differentiation</a> is useful for implementing machine learning algorithms such as <a class="reference external" href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> for training neural networks. During eager execution, use <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code> to trace operations for computing gradients later.</p>
<p>You can use <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code> to train and/or compute gradients in eager. It is especially useful for complicated training loops.</p>
<p>Since different operations can occur during each call, all forward-pass operations get recorded to a “tape”. To compute the gradient, play the tape backwards and then discard. A particular <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code> can only compute one gradient; subsequent calls throw a runtime error.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>w = tf.Variable([[1.0]])
with tf.GradientTape() as tape:
  loss = w * w

grad = tape.gradient(loss, w)
print(grad)  # =&gt; tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Train-a-model">
<h4>Train a model<a class="headerlink" href="#Train-a-model" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The following example creates a multi-layer model that classifies the standard MNIST handwritten digits. It demonstrates the optimizer and layer APIs to build trainable graphs in an eager execution environment.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Fetch and format the mnist data
(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()

dataset = tf.data.Dataset.from_tensor_slices(
  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),
   tf.cast(mnist_labels,tf.int64)))
dataset = dataset.shuffle(1000).batch(32)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Build the model
mnist_model = tf.keras.Sequential([
  tf.keras.layers.Conv2D(16,[3,3], activation=&#39;relu&#39;,
                         input_shape=(None, None, 1)),
  tf.keras.layers.Conv2D(16,[3,3], activation=&#39;relu&#39;),
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(10)
])
</pre></div>
</div>
</div>
<p>Even without training, call the model and inspect the output in eager execution:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for images,labels in dataset.take(1):
  print(&quot;Logits: &quot;, mnist_model(images[0:1]).numpy())
</pre></div>
</div>
</div>
<p>While keras models have a builtin training loop (using the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method), sometimes you need more customization. Here’s an example, of a training loop implemented with eager:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>optimizer = tf.keras.optimizers.Adam()
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

loss_history = []
</pre></div>
</div>
</div>
<p>Note: Use the assert functions in <code class="docutils literal notranslate"><span class="pre">tf.debugging</span></code> to check if a condition holds up. This works in eager and graph execution.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def train_step(images, labels):
  with tf.GradientTape() as tape:
    logits = mnist_model(images, training=True)

    # Add asserts to check the shape of the output.
    tf.debugging.assert_equal(logits.shape, (32, 10))

    loss_value = loss_object(labels, logits)

  loss_history.append(loss_value.numpy().mean())
  grads = tape.gradient(loss_value, mnist_model.trainable_variables)
  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def train(epochs):
  for epoch in range(epochs):
    for (batch, (images, labels)) in enumerate(dataset):
      train_step(images, labels)
    print (&#39;Epoch {} finished&#39;.format(epoch))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train(epochs = 3)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import matplotlib.pyplot as plt

plt.plot(loss_history)
plt.xlabel(&#39;Batch #&#39;)
plt.ylabel(&#39;Loss [entropy]&#39;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Variables-and-optimizers">
<h4>Variables and optimizers<a class="headerlink" href="#Variables-and-optimizers" title="Enlazar permanentemente con este título">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> objects store mutable <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>-like values accessed during training to make automatic differentiation easier.</p>
<p>The collections of variables can be encapsulated into layers or models, along with methods that operate on them. See <a class="reference external" href="./keras/custom_layers_and_models.ipynb">Custom Keras layers and models</a> for details. The main difference between layers and models is that models add methods like <code class="docutils literal notranslate"><span class="pre">Model.fit</span></code>, <code class="docutils literal notranslate"><span class="pre">Model.evaluate</span></code>, and <code class="docutils literal notranslate"><span class="pre">Model.save</span></code>.</p>
<p>For example, the automatic differentiation example above can be rewritten:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class Linear(tf.keras.Model):
  def __init__(self):
    super(Linear, self).__init__()
    self.W = tf.Variable(5., name=&#39;weight&#39;)
    self.B = tf.Variable(10., name=&#39;bias&#39;)
  def call(self, inputs):
    return inputs * self.W + self.B
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># A toy dataset of points around 3 * x + 2
NUM_EXAMPLES = 2000
training_inputs = tf.random.normal([NUM_EXAMPLES])
noise = tf.random.normal([NUM_EXAMPLES])
training_outputs = training_inputs * 3 + 2 + noise

# The loss function to be optimized
def loss(model, inputs, targets):
  error = model(inputs) - targets
  return tf.reduce_mean(tf.square(error))

def grad(model, inputs, targets):
  with tf.GradientTape() as tape:
    loss_value = loss(model, inputs, targets)
  return tape.gradient(loss_value, [model.W, model.B])
</pre></div>
</div>
</div>
<p>Next:</p>
<ol class="arabic simple">
<li><p>Create the model.</p></li>
<li><p>The Derivatives of a loss function with respect to model parameters.</p></li>
<li><p>A strategy for updating the variables based on the derivatives.</p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = Linear()
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)

print(&quot;Initial loss: {:.3f}&quot;.format(loss(model, training_inputs, training_outputs)))

steps = 300
for i in range(steps):
  grads = grad(model, training_inputs, training_outputs)
  optimizer.apply_gradients(zip(grads, [model.W, model.B]))
  if i % 20 == 0:
    print(&quot;Loss at step {:03d}: {:.3f}&quot;.format(i, loss(model, training_inputs, training_outputs)))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Final loss: {:.3f}&quot;.format(loss(model, training_inputs, training_outputs)))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;W = {}, B = {}&quot;.format(model.W.numpy(), model.B.numpy()))
</pre></div>
</div>
</div>
<p>Note: Variables persist until the last reference to the python object is removed, and is the variable is deleted.</p>
</div>
<div class="section" id="Object-based-saving">
<h4>Object-based saving<a class="headerlink" href="#Object-based-saving" title="Enlazar permanentemente con este título">¶</a></h4>
<p>A <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> includes a convenient <code class="docutils literal notranslate"><span class="pre">save_weights</span></code> method allowing you to easily create a checkpoint:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model.save_weights(&#39;weights&#39;)
status = model.load_weights(&#39;weights&#39;)
</pre></div>
</div>
</div>
<p>Using <code class="docutils literal notranslate"><span class="pre">tf.train.Checkpoint</span></code> you can take full control over this process.</p>
<p>This section is an abbreviated version of the <a class="reference internal" href="checkpoint.html"><span class="doc">guide to training checkpoints</span></a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x = tf.Variable(10.)
checkpoint = tf.train.Checkpoint(x=x)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x.assign(2.)   # Assign a new value to the variables and save.
checkpoint_path = &#39;./ckpt/&#39;
checkpoint.save(checkpoint_path)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x.assign(11.)  # Change the variable after saving.

# Restore values from the checkpoint
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))

print(x)  # =&gt; 2.0
</pre></div>
</div>
</div>
<p>To save and load models, <code class="docutils literal notranslate"><span class="pre">tf.train.Checkpoint</span></code> stores the internal state of objects, without requiring hidden variables. To record the state of a <code class="docutils literal notranslate"><span class="pre">model</span></code>, an <code class="docutils literal notranslate"><span class="pre">optimizer</span></code>, and a global step, pass them to a <code class="docutils literal notranslate"><span class="pre">tf.train.Checkpoint</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = tf.keras.Sequential([
  tf.keras.layers.Conv2D(16,[3,3], activation=&#39;relu&#39;),
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(10)
])
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
checkpoint_dir = &#39;path/to/model_dir&#39;
if not os.path.exists(checkpoint_dir):
  os.makedirs(checkpoint_dir)
checkpoint_prefix = os.path.join(checkpoint_dir, &quot;ckpt&quot;)
root = tf.train.Checkpoint(optimizer=optimizer,
                           model=model)

root.save(checkpoint_prefix)
root.restore(tf.train.latest_checkpoint(checkpoint_dir))
</pre></div>
</div>
</div>
<p>Note: In many training loops, variables are created after <code class="docutils literal notranslate"><span class="pre">tf.train.Checkpoint.restore</span></code> is called. These variables will be restored as soon as they are created, and assertions are available to ensure that a checkpoint has been fully loaded. See the <a class="reference internal" href="checkpoint.html"><span class="doc">guide to training checkpoints</span></a> for details.</p>
</div>
<div class="section" id="Object-oriented-metrics">
<h4>Object-oriented metrics<a class="headerlink" href="#Object-oriented-metrics" title="Enlazar permanentemente con este título">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">tf.keras.metrics</span></code> are stored as objects. Update a metric by passing the new data to the callable, and retrieve the result using the <code class="docutils literal notranslate"><span class="pre">tf.keras.metrics.result</span></code> method, for example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>m = tf.keras.metrics.Mean(&quot;loss&quot;)
m(0)
m(5)
m.result()  # =&gt; 2.5
m([8, 9])
m.result()  # =&gt; 5.5
</pre></div>
</div>
</div>
</div>
<div class="section" id="Summaries-and-TensorBoard">
<h4>Summaries and TensorBoard<a class="headerlink" href="#Summaries-and-TensorBoard" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference external" href="https://tensorflow.org/tensorboard">TensorBoard</a> is a visualization tool for understanding, debugging and optimizing the model training process. It uses summary events that are written while executing the program.</p>
<p>You can use <code class="docutils literal notranslate"><span class="pre">tf.summary</span></code> to record summaries of variable in eager execution. For example, to record summaries of <code class="docutils literal notranslate"><span class="pre">loss</span></code> once every 100 training steps:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>logdir = &quot;./tb/&quot;
writer = tf.summary.create_file_writer(logdir)

steps = 1000
with writer.as_default():  # or call writer.set_as_default() before the loop.
  for i in range(steps):
    step = i + 1
    # Calculate loss with your real train function.
    loss = 1 - 0.001 * step
    if step % 100 == 0:
      tf.summary.scalar(&#39;loss&#39;, loss, step=step)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>!ls tb/
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Advanced-automatic-differentiation-topics">
<h3>Advanced automatic differentiation topics<a class="headerlink" href="#Advanced-automatic-differentiation-topics" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Dynamic-models">
<h4>Dynamic models<a class="headerlink" href="#Dynamic-models" title="Enlazar permanentemente con este título">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code> can also be used in dynamic models. This example for a <a class="reference external" href="https://wikipedia.org/wiki/Backtracking_line_search">backtracking line search</a> algorithm looks like normal NumPy code, except there are gradients and is differentiable, despite the complex control flow:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def line_search_step(fn, init_x, rate=1.0):
  with tf.GradientTape() as tape:
    # Variables are automatically tracked.
    # But to calculate a gradient from a tensor, you must `watch` it.
    tape.watch(init_x)
    value = fn(init_x)
  grad = tape.gradient(value, init_x)
  grad_norm = tf.reduce_sum(grad * grad)
  init_value = value
  while value &gt; init_value - rate * grad_norm:
    x = init_x - rate * grad
    value = fn(x)
    rate /= 2.0
  return x, value
</pre></div>
</div>
</div>
</div>
<div class="section" id="Custom-gradients">
<h4>Custom gradients<a class="headerlink" href="#Custom-gradients" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Custom gradients are an easy way to override gradients. Within the forward function, define the gradient with respect to the inputs, outputs, or intermediate results. For example, here’s an easy way to clip the norm of the gradients in the backward pass:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.custom_gradient
def clip_gradient_by_norm(x, norm):
  y = tf.identity(x)
  def grad_fn(dresult):
    return [tf.clip_by_norm(dresult, norm), None]
  return y, grad_fn
</pre></div>
</div>
</div>
<p>Custom gradients are commonly used to provide a numerically stable gradient for a sequence of operations:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def log1pexp(x):
  return tf.math.log(1 + tf.exp(x))

def grad_log1pexp(x):
  with tf.GradientTape() as tape:
    tape.watch(x)
    value = log1pexp(x)
  return tape.gradient(value, x)

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># The gradient computation works fine at x = 0.
grad_log1pexp(tf.constant(0.)).numpy()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># However, x = 100 fails because of numerical instability.
grad_log1pexp(tf.constant(100.)).numpy()
</pre></div>
</div>
</div>
<p>Here, the <code class="docutils literal notranslate"><span class="pre">log1pexp</span></code> function can be analytically simplified with a custom gradient. The implementation below reuses the value for <code class="docutils literal notranslate"><span class="pre">tf.exp(x)</span></code> that is computed during the forward pass—making it more efficient by eliminating redundant calculations:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.custom_gradient
def log1pexp(x):
  e = tf.exp(x)
  def grad(dy):
    return dy * (1 - 1 / (1 + e))
  return tf.math.log(1 + e), grad

def grad_log1pexp(x):
  with tf.GradientTape() as tape:
    tape.watch(x)
    value = log1pexp(x)
  return tape.gradient(value, x)

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># As before, the gradient computation works fine at x = 0.
grad_log1pexp(tf.constant(0.)).numpy()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># And the gradient computation also works at x = 100.
grad_log1pexp(tf.constant(100.)).numpy()
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Performance">
<h3>Performance<a class="headerlink" href="#Performance" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Computation is automatically offloaded to GPUs during eager execution. If you want control over where a computation runs you can enclose it in a <code class="docutils literal notranslate"><span class="pre">tf.device('/gpu:0')</span></code> block (or the CPU equivalent):</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import time

def measure(x, steps):
  # TensorFlow initializes a GPU the first time it&#39;s used, exclude from timing.
  tf.matmul(x, x)
  start = time.time()
  for i in range(steps):
    x = tf.matmul(x, x)
  # tf.matmul can return before completing the matrix multiplication
  # (e.g., can return after enqueing the operation on a CUDA stream).
  # The x.numpy() call below will ensure that all enqueued operations
  # have completed (and will also copy the result to host memory,
  # so we&#39;re including a little more than just the matmul operation
  # time).
  _ = x.numpy()
  end = time.time()
  return end - start

shape = (1000, 1000)
steps = 200
print(&quot;Time to multiply a {} matrix by itself {} times:&quot;.format(shape, steps))

# Run on CPU:
with tf.device(&quot;/cpu:0&quot;):
  print(&quot;CPU: {} secs&quot;.format(measure(tf.random.normal(shape), steps)))

# Run on GPU, if available:
if tf.config.list_physical_devices(&quot;GPU&quot;):
  with tf.device(&quot;/gpu:0&quot;):
    print(&quot;GPU: {} secs&quot;.format(measure(tf.random.normal(shape), steps)))
else:
  print(&quot;GPU: not found&quot;)
</pre></div>
</div>
</div>
<p>A <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> object can be copied to a different device to execute its operations:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>if tf.config.list_physical_devices(&quot;GPU&quot;):
  x = tf.random.normal([10, 10])

  x_gpu0 = x.gpu()
  x_cpu = x.cpu()

  _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU
  _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0
</pre></div>
</div>
</div>
<div class="section" id="Benchmarks">
<h4>Benchmarks<a class="headerlink" href="#Benchmarks" title="Enlazar permanentemente con este título">¶</a></h4>
<p>For compute-heavy models, such as <a class="reference external" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/eager/benchmarks/resnet50">ResNet50</a> training on a GPU, eager execution performance is comparable to <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> execution. But this gap grows larger for models with less computation and there is work to be done for optimizing hot code paths for models with lots of small operations.</p>
</div>
</div>
<div class="section" id="Work-with-functions">
<h3>Work with functions<a class="headerlink" href="#Work-with-functions" title="Enlazar permanentemente con este título">¶</a></h3>
<p>While eager execution makes development and debugging more interactive, TensorFlow 1.x style graph execution has advantages for distributed training, performance optimizations, and production deployment. To bridge this gap, TensorFlow 2.0 introduces <code class="docutils literal notranslate"><span class="pre">function</span></code>s via the <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> API. For more information, see the <a class="reference internal" href="function.html"><span class="doc">tf.function</span></a> guide.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>