

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2018 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2018 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow__por_revisar/guide/migrate.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2018-The-TensorFlow-Authors.">
<h1>Copyright 2018 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2018-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="Migrate-your-TensorFlow-1-code-to-TensorFlow-2">
<h2>Migrate your TensorFlow 1 code to TensorFlow 2<a class="headerlink" href="#Migrate-your-TensorFlow-1-code-to-TensorFlow-2" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left">  <td>

|9451b1389ccc45b68dc90b995e1f1281| View on TensorFlow.org</td>  <td>

|8a51e3101bc945fc9e55e27ee3df2f41| Run in Google Colab</td>  <td>

|ad0314bda02d474082ebce1d04b622fe| View source on GitHub</td><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>58fd7aa1b9c14a248c26e4479bae1888|Download notebook</p>
</td></table><p>This guide is for users of low-level TensorFlow APIs. If you are using the high-level APIs (<code class="docutils literal notranslate"><span class="pre">tf.keras</span></code>) there may be little or no action you need to take to make your code fully TensorFlow 2.x compatible:</p>
<ul class="simple">
<li><p>Check your <a class="reference external" href="#keras_optimizer_lr">optimizer’s default learning rate</a>.</p></li>
<li><p>Note that the “name” that metrics are logged to <a class="reference external" href="#keras_metric_names">may have changed</a>.</p></li>
</ul>
<p>It is still possible to run 1.x code, unmodified (<a class="reference external" href="https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md">except for contrib</a>), in TensorFlow 2.x:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow.compat.v1</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">disable_v2_behavior</span><span class="p">()</span>
</pre></div>
</div>
<p>However, this does not let you take advantage of many of the improvements made in TensorFlow 2.x. This guide will help you upgrade your code, making it simpler, more performant, and easier to maintain.</p>
<div class="section" id="Automatic-conversion-script">
<h3>Automatic conversion script<a class="headerlink" href="#Automatic-conversion-script" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The first step, before attempting to implement the changes described in this guide, is to try running the <a class="reference internal" href="upgrade.html"><span class="doc">upgrade script</span></a>.</p>
<p>This will execute an initial pass at upgrading your code to TensorFlow 2.x but it can’t make your code idiomatic to v2. Your code may still make use of <code class="docutils literal notranslate"><span class="pre">tf.compat.v1</span></code> endpoints to access placeholders, sessions, collections, and other 1.x-style functionality.</p>
</div>
<div class="section" id="Top-level-behavioral-changes">
<h3>Top-level behavioral changes<a class="headerlink" href="#Top-level-behavioral-changes" title="Enlazar permanentemente con este título">¶</a></h3>
<p>If your code works in TensorFlow 2.x using <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.disable_v2_behavior</span></code>, there are still global behavioral changes you may need to address. The major changes are:</p>
<ul class="simple">
<li><p><em>Eager execution, ``v1.enable_eager_execution()``</em> : Any code that implicitly uses a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> will fail. Be sure to wrap this code in a <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">tf.Graph().as_default()</span></code> context.</p></li>
<li><p><em>Resource variables, ``v1.enable_resource_variables()``</em>: Some code may depends on non-deterministic behaviors enabled by TensorFlow reference variables. Resource variables are locked while being written to, and so provide more intuitive consistency guarantees.</p>
<ul>
<li><p>This may change behavior in edge cases.</p></li>
<li><p>This may create extra copies and can have higher memory usage.</p></li>
<li><p>This can be disabled by passing <code class="docutils literal notranslate"><span class="pre">use_resource=False</span></code> to the <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> constructor.</p></li>
</ul>
</li>
<li><p><em>Tensor shapes, ``v1.enable_v2_tensorshape()``</em>: TensorFlow 2.x simplifies the behavior of tensor shapes. Instead of <code class="docutils literal notranslate"><span class="pre">t.shape[0].value</span></code> you can say <code class="docutils literal notranslate"><span class="pre">t.shape[0]</span></code>. These changes should be small, and it makes sense to fix them right away. Refer to the <a class="reference external" href="#tensorshape">TensorShape</a> section for examples.</p></li>
<li><p><em>Control flow, ``v1.enable_control_flow_v2()``</em>: The TensorFlow 2.x control flow implementation has been simplified, and so produces different graph representations. Please <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues">file bugs</a> for any issues.</p></li>
</ul>
</div>
<div class="section" id="Create-code-for-TensorFlow-2.x">
<h3>Create code for TensorFlow 2.x<a class="headerlink" href="#Create-code-for-TensorFlow-2.x" title="Enlazar permanentemente con este título">¶</a></h3>
<p>This guide will walk through several examples of converting TensorFlow 1.x code to TensorFlow 2.x. These changes will let your code take advantage of performance optimizations and simplified API calls.</p>
<p>In each case, the pattern is:</p>
<div class="section" id="1.-Replace-v1.Session.run-calls">
<h4>1. Replace <code class="docutils literal notranslate"><span class="pre">v1.Session.run</span></code> calls<a class="headerlink" href="#1.-Replace-v1.Session.run-calls" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Every <code class="docutils literal notranslate"><span class="pre">v1.Session.run</span></code> call should be replaced by a Python function.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">feed_dict</span></code> and <code class="docutils literal notranslate"><span class="pre">v1.placeholder</span></code>s become function arguments.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">fetches</span></code> become the function’s return value.</p></li>
<li><p>During conversion eager execution allows easy debugging with standard Python tools like <code class="docutils literal notranslate"><span class="pre">pdb</span></code>.</p></li>
</ul>
<p>After that, add a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> decorator to make it run efficiently in graph. Check out the <a class="reference internal" href="function.html"><span class="doc">Autograph guide</span></a> for more information about how this works.</p>
<p>Note that:</p>
<ul class="simple">
<li><p>Unlike <code class="docutils literal notranslate"><span class="pre">v1.Session.run</span></code>, a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> has a fixed return signature and always returns all outputs. If this causes performance problems, create two separate functions.</p></li>
<li><p>There is no need for a <code class="docutils literal notranslate"><span class="pre">tf.control_dependencies</span></code> or similar operations: A <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> behaves as if it were run in the order written. <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> assignments and <code class="docutils literal notranslate"><span class="pre">tf.assert</span></code>s, for example, are executed automatically.</p></li>
</ul>
<p>The <a class="reference external" href="#converting_models">converting models section</a> contains a working example of this conversion process.</p>
</div>
<div class="section" id="2.-Use-Python-objects-to-track-variables-and-losses">
<h4>2. Use Python objects to track variables and losses<a class="headerlink" href="#2.-Use-Python-objects-to-track-variables-and-losses" title="Enlazar permanentemente con este título">¶</a></h4>
<p>All name-based variable tracking is strongly discouraged in TensorFlow 2.x. Use Python objects to to track variables.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> instead of <code class="docutils literal notranslate"><span class="pre">v1.get_variable</span></code>.</p>
<p>Every <code class="docutils literal notranslate"><span class="pre">v1.variable_scope</span></code> should be converted to a Python object. Typically this will be one of:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.Module</span></code></p></li>
</ul>
<p>If you need to aggregate lists of variables (like <code class="docutils literal notranslate"><span class="pre">tf.Graph.get_collection(tf.GraphKeys.VARIABLES)</span></code>), use the <code class="docutils literal notranslate"><span class="pre">.variables</span></code> and <code class="docutils literal notranslate"><span class="pre">.trainable_variables</span></code> attributes of the <code class="docutils literal notranslate"><span class="pre">Layer</span></code> and <code class="docutils literal notranslate"><span class="pre">Model</span></code> objects.</p>
<p>These <code class="docutils literal notranslate"><span class="pre">Layer</span></code> and <code class="docutils literal notranslate"><span class="pre">Model</span></code> classes implement several other properties that remove the need for global collections. Their <code class="docutils literal notranslate"><span class="pre">.losses</span></code> property can be a replacement for using the <code class="docutils literal notranslate"><span class="pre">tf.GraphKeys.LOSSES</span></code> collection.</p>
<p>Refer to the <a class="reference external" href="keras.ipynb">Keras guides</a> for more details.</p>
<p>Warning: Many <code class="docutils literal notranslate"><span class="pre">tf.compat.v1</span></code> symbols use the global collections implicitly.</p>
</div>
<div class="section" id="3.-Upgrade-your-training-loops">
<h4>3. Upgrade your training loops<a class="headerlink" href="#3.-Upgrade-your-training-loops" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Use the highest-level API that works for your use case. Prefer <code class="docutils literal notranslate"><span class="pre">tf.keras.Model.fit</span></code> over building your own training loops.</p>
<p>These high level functions manage a lot of the low-level details that might be easy to miss if you write your own training loop. For example, they automatically collect the regularization losses, and set the <code class="docutils literal notranslate"><span class="pre">training=True</span></code> argument when calling the model.</p>
</div>
<div class="section" id="4.-Upgrade-your-data-input-pipelines">
<h4>4. Upgrade your data input pipelines<a class="headerlink" href="#4.-Upgrade-your-data-input-pipelines" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Use <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> datasets for data input. These objects are efficient, expressive, and integrate well with tensorflow.</p>
<p>They can be passed directly to the <code class="docutils literal notranslate"><span class="pre">tf.keras.Model.fit</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>They can be iterated over directly standard Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">example_batch</span><span class="p">,</span> <span class="n">label_batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="section" id="5.-Migrate-off-compat.v1-symbols">
<h4>5. Migrate off <code class="docutils literal notranslate"><span class="pre">compat.v1</span></code> symbols<a class="headerlink" href="#5.-Migrate-off-compat.v1-symbols" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.compat.v1</span></code> module contains the complete TensorFlow 1.x API, with its original semantics.</p>
<p>The <a class="reference internal" href="upgrade.html"><span class="doc">TensorFlow 2.x upgrade script</span></a> will convert symbols to their v2 equivalents if such a conversion is safe, i.e., if it can determine that the behavior of the TensorFlow 2.x version is exactly equivalent (for instance, it will rename <code class="docutils literal notranslate"><span class="pre">v1.arg_max</span></code> to <code class="docutils literal notranslate"><span class="pre">tf.argmax</span></code>, since those are the same function).</p>
<p>After the upgrade script is done with a piece of code, it is likely there are many mentions of <code class="docutils literal notranslate"><span class="pre">compat.v1</span></code>. It is worth going through the code and converting these manually to the v2 equivalent (it should be mentioned in the log if there is one).</p>
</div>
</div>
<div class="section" id="Converting-models">
<h3>Converting models<a class="headerlink" href="#Converting-models" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Low-level-variables-&amp;-operator-execution">
<h4>Low-level variables &amp; operator execution<a class="headerlink" href="#Low-level-variables-&-operator-execution" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Examples of low-level API use include:</p>
<ul class="simple">
<li><p>Using variable scopes to control reuse.</p></li>
<li><p>Creating variables with <code class="docutils literal notranslate"><span class="pre">v1.get_variable</span></code>.</p></li>
<li><p>Accessing collections explicitly.</p></li>
<li><p>Accessing collections implicitly with methods like:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">v1.global_variables</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1.losses.get_regularization_loss</span></code></p></li>
</ul>
</li>
<li><p>Using <code class="docutils literal notranslate"><span class="pre">v1.placeholder</span></code> to set up graph inputs.</p></li>
<li><p>Executing graphs with <code class="docutils literal notranslate"><span class="pre">Session.run</span></code>.</p></li>
<li><p>Initializing variables manually.</p></li>
</ul>
<div class="section" id="Before-converting">
<h5>Before converting<a class="headerlink" href="#Before-converting" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Here is what these patterns may look like in code using TensorFlow 1.x.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import tensorflow as tf
import tensorflow.compat.v1 as v1

import tensorflow_datasets as tfds
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>g = v1.Graph()

with g.as_default():
  in_a = v1.placeholder(dtype=v1.float32, shape=(2))
  in_b = v1.placeholder(dtype=v1.float32, shape=(2))

  def forward(x):
    with v1.variable_scope(&quot;matmul&quot;, reuse=v1.AUTO_REUSE):
      W = v1.get_variable(&quot;W&quot;, initializer=v1.ones(shape=(2,2)),
                          regularizer=lambda x:tf.reduce_mean(x**2))
      b = v1.get_variable(&quot;b&quot;, initializer=v1.zeros(shape=(2)))
      return W * x + b

  out_a = forward(in_a)
  out_b = forward(in_b)
  reg_loss=v1.losses.get_regularization_loss(scope=&quot;matmul&quot;)

with v1.Session(graph=g) as sess:
  sess.run(v1.global_variables_initializer())
  outs = sess.run([out_a, out_b, reg_loss],
                    feed_dict={in_a: [1, 0], in_b: [0, 1]})

print(outs[0])
print()
print(outs[1])
print()
print(outs[2])
</pre></div>
</div>
</div>
</div>
<div class="section" id="After-converting">
<h5>After converting<a class="headerlink" href="#After-converting" title="Enlazar permanentemente con este título">¶</a></h5>
<p>In the converted code:</p>
<ul class="simple">
<li><p>The variables are local Python objects.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">forward</span></code> function still defines the calculation.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">Session.run</span></code> call is replaced with a call to <code class="docutils literal notranslate"><span class="pre">forward</span></code>.</p></li>
<li><p>The optional <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> decorator can be added for performance.</p></li>
<li><p>The regularizations are calculated manually, without referring to any global collection.</p></li>
<li><p><strong>There’s no usage of sessions or placeholders</strong>.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>W = tf.Variable(tf.ones(shape=(2,2)), name=&quot;W&quot;)
b = tf.Variable(tf.zeros(shape=(2)), name=&quot;b&quot;)

@tf.function
def forward(x):
  return W * x + b

out_a = forward([1,0])
print(out_a)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>out_b = forward([0,1])

regularizer = tf.keras.regularizers.l2(0.04)
reg_loss=regularizer(W)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Models-based-on-tf.layers">
<h4>Models based on <code class="docutils literal notranslate"><span class="pre">tf.layers</span></code><a class="headerlink" href="#Models-based-on-tf.layers" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">v1.layers</span></code> module is used to contain layer-functions that relied on <code class="docutils literal notranslate"><span class="pre">v1.variable_scope</span></code> to define and reuse variables.</p>
<div class="section" id="id3">
<h5>Before converting<a class="headerlink" href="#id3" title="Enlazar permanentemente con este título">¶</a></h5>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def model(x, training, scope=&#39;model&#39;):
  with v1.variable_scope(scope, reuse=v1.AUTO_REUSE):
    x = v1.layers.conv2d(x, 32, 3, activation=v1.nn.relu,
          kernel_regularizer=lambda x:0.004*tf.reduce_mean(x**2))
    x = v1.layers.max_pooling2d(x, (2, 2), 1)
    x = v1.layers.flatten(x)
    x = v1.layers.dropout(x, 0.1, training=training)
    x = v1.layers.dense(x, 64, activation=v1.nn.relu)
    x = v1.layers.batch_normalization(x, training=training)
    x = v1.layers.dense(x, 10)
    return x
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train_data = tf.ones(shape=(1, 28, 28, 1))
test_data = tf.ones(shape=(1, 28, 28, 1))

train_out = model(train_data, training=True)
test_out = model(test_data, training=False)

print(train_out)
print()
print(test_out)
</pre></div>
</div>
</div>
</div>
<div class="section" id="id4">
<h5>After converting<a class="headerlink" href="#id4" title="Enlazar permanentemente con este título">¶</a></h5>
<ul class="simple">
<li><p>The simple stack of layers fits neatly into <code class="docutils literal notranslate"><span class="pre">tf.keras.Sequential</span></code>. (For more complex models, check out the <a class="reference external" href="keras/custom_layers_and_models.ipynb">custom layers and models</a> and <a class="reference external" href="keras/functional.ipynb">the functional API</a> guides.)</p></li>
<li><p>The model tracks the variables, and regularization losses.</p></li>
<li><p>The conversion was one-to-one because there is a direct mapping from <code class="docutils literal notranslate"><span class="pre">v1.layers</span></code> to <code class="docutils literal notranslate"><span class="pre">tf.keras.layers</span></code>.</p></li>
</ul>
<p>Most arguments stayed the same. But notice the differences:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">training</span></code> argument is passed to each layer by the model when it runs.</p></li>
<li><p>The first argument to the original <code class="docutils literal notranslate"><span class="pre">model</span></code> function (the input <code class="docutils literal notranslate"><span class="pre">x</span></code>) is gone. This is because object layers separate building the model from calling the model.</p></li>
</ul>
<p>Also note that:</p>
<ul class="simple">
<li><p>If you are using regularizers or initializers from <code class="docutils literal notranslate"><span class="pre">tf.contrib</span></code>, these have more argument changes than others.</p></li>
<li><p>The code no longer writes to collections, so functions like <code class="docutils literal notranslate"><span class="pre">v1.losses.get_regularization_loss</span></code> will no longer return these values, potentially breaking your training loops.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, 3, activation=&#39;relu&#39;,
                           kernel_regularizer=tf.keras.regularizers.l2(0.04),
                           input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(64, activation=&#39;relu&#39;),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(10)
])

train_data = tf.ones(shape=(1, 28, 28, 1))
test_data = tf.ones(shape=(1, 28, 28, 1))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train_out = model(train_data, training=True)
print(train_out)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>test_out = model(test_data, training=False)
print(test_out)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Here are all the trainable variables
len(model.trainable_variables)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Here is the regularization loss
model.losses
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Mixed-variables-&amp;-v1.layers">
<h4>Mixed variables &amp; <code class="docutils literal notranslate"><span class="pre">v1.layers</span></code><a class="headerlink" href="#Mixed-variables-&-v1.layers" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Existing code often mixes lower-level TensorFlow 1.x variables and operations with higher-level <code class="docutils literal notranslate"><span class="pre">v1.layers</span></code>.</p>
<div class="section" id="id5">
<h5>Before converting<a class="headerlink" href="#id5" title="Enlazar permanentemente con este título">¶</a></h5>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def model(x, training, scope=&#39;model&#39;):
  with v1.variable_scope(scope, reuse=v1.AUTO_REUSE):
    W = v1.get_variable(
      &quot;W&quot;, dtype=v1.float32,
      initializer=v1.ones(shape=x.shape),
      regularizer=lambda x:0.004*tf.reduce_mean(x**2),
      trainable=True)
    if training:
      x = x + W
    else:
      x = x + W * 0.5
    x = v1.layers.conv2d(x, 32, 3, activation=tf.nn.relu)
    x = v1.layers.max_pooling2d(x, (2, 2), 1)
    x = v1.layers.flatten(x)
    return x

train_out = model(train_data, training=True)
test_out = model(test_data, training=False)
</pre></div>
</div>
</div>
</div>
<div class="section" id="id6">
<h5>After converting<a class="headerlink" href="#id6" title="Enlazar permanentemente con este título">¶</a></h5>
<p>To convert this code, follow the pattern of mapping layers to layers as in the previous example.</p>
<p>The general pattern is:</p>
<ul class="simple">
<li><p>Collect layer parameters in <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p></li>
<li><p>Build the variables in <code class="docutils literal notranslate"><span class="pre">build</span></code>.</p></li>
<li><p>Execute the calculations in <code class="docutils literal notranslate"><span class="pre">call</span></code>, and return the result.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">v1.variable_scope</span></code> is essentially a layer of its own. So rewrite it as a <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code>. Check out the <a class="reference external" href="keras/custom_layers_and_models.ipynb">Making new Layers and Models via subclassing guide</a> for details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Create a custom layer for part of the model
class CustomLayer(tf.keras.layers.Layer):
  def __init__(self, *args, **kwargs):
    super(CustomLayer, self).__init__(*args, **kwargs)

  def build(self, input_shape):
    self.w = self.add_weight(
        shape=input_shape[1:],
        dtype=tf.float32,
        initializer=tf.keras.initializers.ones(),
        regularizer=tf.keras.regularizers.l2(0.02),
        trainable=True)

  # Call method will sometimes get used in graph mode,
  # training will get turned into a tensor
  @tf.function
  def call(self, inputs, training=None):
    if training:
      return inputs + self.w
    else:
      return inputs + self.w * 0.5
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>custom_layer = CustomLayer()
print(custom_layer([1]).numpy())
print(custom_layer([1], training=True).numpy())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train_data = tf.ones(shape=(1, 28, 28, 1))
test_data = tf.ones(shape=(1, 28, 28, 1))

# Build the model including the custom layer
model = tf.keras.Sequential([
    CustomLayer(input_shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
])

train_out = model(train_data, training=True)
test_out = model(test_data, training=False)

</pre></div>
</div>
</div>
<p>Some things to note:</p>
<ul class="simple">
<li><p>Subclassed Keras models and layers need to run in both v1 graphs (no automatic control dependencies) and in eager mode:</p>
<ul>
<li><p>Wrap the <code class="docutils literal notranslate"><span class="pre">call</span></code> in a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> to get autograph and automatic control dependencies.</p></li>
</ul>
</li>
<li><p>Don’t forget to accept a <code class="docutils literal notranslate"><span class="pre">training</span></code> argument to <code class="docutils literal notranslate"><span class="pre">call</span></code>:</p>
<ul>
<li><p>Sometimes it is a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code></p></li>
<li><p>Sometimes it is a Python boolean</p></li>
</ul>
</li>
<li><p>Create model variables in constructor or <code class="docutils literal notranslate"><span class="pre">Model.build</span></code> using <code class="docutils literal notranslate"><span class="pre">self.add_weight:</span> <span class="pre">-</span> <span class="pre">In</span></code>Model.build<code class="docutils literal notranslate"><span class="pre">you</span> <span class="pre">have</span> <span class="pre">access</span> <span class="pre">to</span> <span class="pre">the</span> <span class="pre">input</span> <span class="pre">shape,</span> <span class="pre">so</span> <span class="pre">can</span> <span class="pre">create</span> <span class="pre">weights</span> <span class="pre">with</span> <span class="pre">matching</span> <span class="pre">shape</span> <span class="pre">-</span> <span class="pre">Using</span></code>tf.keras.layers.Layer.add_weight` allows Keras to track variables and regularization losses</p></li>
<li><p>Don’t keep <code class="docutils literal notranslate"><span class="pre">tf.Tensors</span></code> in your objects:</p>
<ul>
<li><p>They might get created either in a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> or in the eager context, and these tensors behave differently</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code>s for state, they are always usable from both contexts</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.Tensors</span></code> are only for intermediate values</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="A-note-on-Slim-and-contrib.layers">
<h4>A note on Slim and contrib.layers<a class="headerlink" href="#A-note-on-Slim-and-contrib.layers" title="Enlazar permanentemente con este título">¶</a></h4>
<p>A large amount of older TensorFlow 1.x code uses the <a class="reference external" href="https://ai.googleblog.com/2016/08/tf-slim-high-level-library-to-define.html">Slim</a> library, which was packaged with TensorFlow 1.x as <code class="docutils literal notranslate"><span class="pre">tf.contrib.layers</span></code>. As a <code class="docutils literal notranslate"><span class="pre">contrib</span></code> module, this is no longer available in TensorFlow 2.x, even in <code class="docutils literal notranslate"><span class="pre">tf.compat.v1</span></code>. Converting code using Slim to TensorFlow 2.x is more involved than converting repositories that use <code class="docutils literal notranslate"><span class="pre">v1.layers</span></code>. In fact, it may make sense to convert your Slim code to <code class="docutils literal notranslate"><span class="pre">v1.layers</span></code>
first, then convert to Keras.</p>
<ul class="simple">
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">arg_scopes</span></code>, all args need to be explicit.</p></li>
<li><p>If you use them, split <code class="docutils literal notranslate"><span class="pre">normalizer_fn</span></code> and <code class="docutils literal notranslate"><span class="pre">activation_fn</span></code> into their own layers.</p></li>
<li><p>Separable conv layers map to one or more different Keras layers (depthwise, pointwise, and separable Keras layers).</p></li>
<li><p>Slim and <code class="docutils literal notranslate"><span class="pre">v1.layers</span></code> have different argument names and default values.</p></li>
<li><p>Some args have different scales.</p></li>
<li><p>If you use Slim pre-trained models, try out Keras’s pre-traimed models from <code class="docutils literal notranslate"><span class="pre">tf.keras.applications</span></code> or <a class="reference external" href="https://tfhub.dev/s?tf-version=tf2&amp;q=slim">TF Hub</a>’s TensorFlow 2.x SavedModels exported from the original Slim code.</p></li>
</ul>
<p>Some <code class="docutils literal notranslate"><span class="pre">tf.contrib</span></code> layers might not have been moved to core TensorFlow but have instead been moved to the <a class="reference external" href="https://www.tensorflow.org/addons/overview">TensorFlow Addons package</a>.</p>
</div>
</div>
<div class="section" id="Training">
<h3>Training<a class="headerlink" href="#Training" title="Enlazar permanentemente con este título">¶</a></h3>
<p>There are many ways to feed data to a <code class="docutils literal notranslate"><span class="pre">tf.keras</span></code> model. They will accept Python generators and Numpy arrays as input.</p>
<p>The recommended way to feed data to a model is to use the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> package, which contains a collection of high performance classes for manipulating data.</p>
<p>If you are still using <code class="docutils literal notranslate"><span class="pre">tf.queue</span></code>, these are now only supported as data-structures, not as input pipelines.</p>
<div class="section" id="Using-TensorFlow-Datasets">
<h4>Using TensorFlow Datasets<a class="headerlink" href="#Using-TensorFlow-Datasets" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The <a class="reference external" href="https://tensorflow.org/datasets">TensorFlow Datasets</a> package (<code class="docutils literal notranslate"><span class="pre">tfds</span></code>) contains utilities for loading predefined datasets as <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> objects.</p>
<p>For this example, you can load the MNIST dataset using <code class="docutils literal notranslate"><span class="pre">tfds</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>datasets, info = tfds.load(name=&#39;mnist&#39;, with_info=True, as_supervised=True)
mnist_train, mnist_test = datasets[&#39;train&#39;], datasets[&#39;test&#39;]
</pre></div>
</div>
</div>
<p>Then prepare the data for training:</p>
<ul class="simple">
<li><p>Re-scale each image.</p></li>
<li><p>Shuffle the order of the examples.</p></li>
<li><p>Collect batches of images and labels.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>BUFFER_SIZE = 10 # Use a much larger value for real code
BATCH_SIZE = 64
NUM_EPOCHS = 5


def scale(image, label):
  image = tf.cast(image, tf.float32)
  image /= 255

  return image, label
</pre></div>
</div>
</div>
<p>To keep the example short, trim the dataset to only return 5 batches:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
test_data = mnist_test.map(scale).batch(BATCH_SIZE)

STEPS_PER_EPOCH = 5

train_data = train_data.take(STEPS_PER_EPOCH)
test_data = test_data.take(STEPS_PER_EPOCH)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>image_batch, label_batch = next(iter(train_data))
</pre></div>
</div>
</div>
</div>
<div class="section" id="Use-Keras-training-loops">
<h4>Use Keras training loops<a class="headerlink" href="#Use-Keras-training-loops" title="Enlazar permanentemente con este título">¶</a></h4>
<p>If you don’t need low-level control of your training process, using Keras’s built-in <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">evaluate</span></code>, and <code class="docutils literal notranslate"><span class="pre">predict</span></code> methods is recommended. These methods provide a uniform interface to train the model regardless of the implementation (sequential, functional, or sub-classed).</p>
<p>The advantages of these methods include:</p>
<ul class="simple">
<li><p>They accept Numpy arrays, Python generators and, <code class="docutils literal notranslate"><span class="pre">tf.data.Datasets</span></code>.</p></li>
<li><p>They apply regularization, and activation losses automatically.</p></li>
<li><p>They support <code class="docutils literal notranslate"><span class="pre">tf.distribute</span></code> <a class="reference internal" href="distributed_training.html"><span class="doc">for multi-device training</span></a>.</p></li>
<li><p>They support arbitrary callables as losses and metrics.</p></li>
<li><p>They support callbacks like <code class="docutils literal notranslate"><span class="pre">tf.keras.callbacks.TensorBoard</span></code>, and custom callbacks.</p></li>
<li><p>They are performant, automatically using TensorFlow graphs.</p></li>
</ul>
<p>Here is an example of training a model using a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>. (For details on how this works, check out the <a class="reference external" href="../tutorials">tutorials</a> section.)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, 3, activation=&#39;relu&#39;,
                           kernel_regularizer=tf.keras.regularizers.l2(0.02),
                           input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(64, activation=&#39;relu&#39;),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(10)
])

# Model is the full model w/o custom layers
model.compile(optimizer=&#39;adam&#39;,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=[&#39;accuracy&#39;])

model.fit(train_data, epochs=NUM_EPOCHS)
loss, acc = model.evaluate(test_data)

print(&quot;Loss {}, Accuracy {}&quot;.format(loss, acc))
</pre></div>
</div>
</div>
</div>
<div class="section" id="Write-your-own-loop">
<h4>Write your own loop<a class="headerlink" href="#Write-your-own-loop" title="Enlazar permanentemente con este título">¶</a></h4>
<p>If the Keras model’s training step works for you, but you need more control outside that step, consider using the <code class="docutils literal notranslate"><span class="pre">tf.keras.Model.train_on_batch</span></code> method, in your own data-iteration loop.</p>
<p>Remember: Many things can be implemented as a <code class="docutils literal notranslate"><span class="pre">tf.keras.callbacks.Callback</span></code>.</p>
<p>This method has many of the advantages of the methods mentioned in the previous section, but gives the user control of the outer loop.</p>
<p>You can also use <code class="docutils literal notranslate"><span class="pre">tf.keras.Model.test_on_batch</span></code> or <code class="docutils literal notranslate"><span class="pre">tf.keras.Model.evaluate</span></code> to check performance during training.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">train_on_batch</span></code> and <code class="docutils literal notranslate"><span class="pre">test_on_batch</span></code> by default return the loss and metrics for the single batch. If you pass <code class="docutils literal notranslate"><span class="pre">reset_metrics=False</span></code>, they return accumulated metrics and you must remember to appropriately reset the metric accumulators. Also, remember that some metrics like <code class="docutils literal notranslate"><span class="pre">AUC</span></code> require <code class="docutils literal notranslate"><span class="pre">reset_metrics=False</span></code> to be calculated correctly.</p>
<p>To continue training the above model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Model is the full model w/o custom layers
model.compile(optimizer=&#39;adam&#39;,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=[&#39;accuracy&#39;])

for epoch in range(NUM_EPOCHS):
  # Reset the metric accumulators
  model.reset_metrics()

  for image_batch, label_batch in train_data:
    result = model.train_on_batch(image_batch, label_batch)
    metrics_names = model.metrics_names
    print(&quot;train: &quot;,
          &quot;{}: {:.3f}&quot;.format(metrics_names[0], result[0]),
          &quot;{}: {:.3f}&quot;.format(metrics_names[1], result[1]))
  for image_batch, label_batch in test_data:
    result = model.test_on_batch(image_batch, label_batch,
                                 # Return accumulated metrics
                                 reset_metrics=False)
  metrics_names = model.metrics_names
  print(&quot;\neval: &quot;,
        &quot;{}: {:.3f}&quot;.format(metrics_names[0], result[0]),
        &quot;{}: {:.3f}&quot;.format(metrics_names[1], result[1]))
</pre></div>
</div>
</div>
</div>
<div class="section" id="Customize-the-training-step">
<h4>Customize the training step<a class="headerlink" href="#Customize-the-training-step" title="Enlazar permanentemente con este título">¶</a></h4>
<p>If you need more flexibility and control, you can have it by implementing your own training loop. There are three steps:</p>
<ol class="arabic simple">
<li><p>Iterate over a Python generator or <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> to get batches of examples.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code> to collect gradients.</p></li>
<li><p>Use one of the <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code> to apply weight updates to the model’s variables.</p></li>
</ol>
<p>Remember:</p>
<ul class="simple">
<li><p>Always include a <code class="docutils literal notranslate"><span class="pre">training</span></code> argument on the <code class="docutils literal notranslate"><span class="pre">call</span></code> method of subclassed layers and models.</p></li>
<li><p>Make sure to call the model with the <code class="docutils literal notranslate"><span class="pre">training</span></code> argument set correctly.</p></li>
<li><p>Depending on usage, model variables may not exist until the model is run on a batch of data.</p></li>
<li><p>You need to manually handle things like regularization losses for the model.</p></li>
</ul>
<p>Note the simplifications relative to v1:</p>
<ul class="simple">
<li><p>There is no need to run variable initializers. Variables are initialized on creation.</p></li>
<li><p>There is no need to add manual control dependencies. Even in <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> operations act as in eager mode.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, 3, activation=&#39;relu&#39;,
                           kernel_regularizer=tf.keras.regularizers.l2(0.02),
                           input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(64, activation=&#39;relu&#39;),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(10)
])

optimizer = tf.keras.optimizers.Adam(0.001)
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

@tf.function
def train_step(inputs, labels):
  with tf.GradientTape() as tape:
    predictions = model(inputs, training=True)
    regularization_loss=tf.math.add_n(model.losses)
    pred_loss=loss_fn(labels, predictions)
    total_loss=pred_loss + regularization_loss

  gradients = tape.gradient(total_loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

for epoch in range(NUM_EPOCHS):
  for inputs, labels in train_data:
    train_step(inputs, labels)
  print(&quot;Finished epoch&quot;, epoch)

</pre></div>
</div>
</div>
</div>
<div class="section" id="New-style-metrics-and-losses">
<h4>New-style metrics and losses<a class="headerlink" href="#New-style-metrics-and-losses" title="Enlazar permanentemente con este título">¶</a></h4>
<p>In TensorFlow 2.x, metrics and losses are objects. These work both eagerly and in <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>s.</p>
<p>A loss object is callable, and expects the (y_true, y_pred) as arguments:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
cce([[1, 0]], [[-1.0,3.0]]).numpy()
</pre></div>
</div>
</div>
<p>A metric object has the following methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Metric.update_state()</span></code>: add new observations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Metric.result()</span></code>: get the current result of the metric, given the observed values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Metric.reset_states()</span></code>: clear all observations.</p></li>
</ul>
<p>The object itself is callable. Calling updates the state with new observations, as with <code class="docutils literal notranslate"><span class="pre">update_state</span></code>, and returns the new result of the metric.</p>
<p>You don’t have to manually initialize a metric’s variables, and because TensorFlow 2.x has automatic control dependencies, you don’t need to worry about those either.</p>
<p>The code below uses a metric to keep track of the mean loss observed within a custom training loop.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Create the metrics
loss_metric = tf.keras.metrics.Mean(name=&#39;train_loss&#39;)
accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name=&#39;train_accuracy&#39;)

@tf.function
def train_step(inputs, labels):
  with tf.GradientTape() as tape:
    predictions = model(inputs, training=True)
    regularization_loss=tf.math.add_n(model.losses)
    pred_loss=loss_fn(labels, predictions)
    total_loss=pred_loss + regularization_loss

  gradients = tape.gradient(total_loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))
  # Update the metrics
  loss_metric.update_state(total_loss)
  accuracy_metric.update_state(labels, predictions)


for epoch in range(NUM_EPOCHS):
  # Reset the metrics
  loss_metric.reset_states()
  accuracy_metric.reset_states()

  for inputs, labels in train_data:
    train_step(inputs, labels)
  # Get the metric results
  mean_loss=loss_metric.result()
  mean_accuracy = accuracy_metric.result()

  print(&#39;Epoch: &#39;, epoch)
  print(&#39;  loss:     {:.3f}&#39;.format(mean_loss))
  print(&#39;  accuracy: {:.3f}&#39;.format(mean_accuracy))

</pre></div>
</div>
</div>
</div>
<div class="section" id="Keras-metric-names">
<h4>Keras metric names<a class="headerlink" href="#Keras-metric-names" title="Enlazar permanentemente con este título">¶</a></h4>
<p>In TensorFlow 2.x, Keras models are more consistent about handling metric names.</p>
<p>Now when you pass a string in the list of metrics, that <em>exact</em> string is used as the metric’s <code class="docutils literal notranslate"><span class="pre">name</span></code>. These names are visible in the history object returned by <code class="docutils literal notranslate"><span class="pre">model.fit</span></code>, and in the logs passed to <code class="docutils literal notranslate"><span class="pre">keras.callbacks</span></code>. is set to the string you passed in the metric list.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model.compile(
    optimizer = tf.keras.optimizers.Adam(0.001),
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics = [&#39;acc&#39;, &#39;accuracy&#39;, tf.keras.metrics.SparseCategoricalAccuracy(name=&quot;my_accuracy&quot;)])
history = model.fit(train_data)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>history.history.keys()
</pre></div>
</div>
</div>
<p>This differs from previous versions where passing <code class="docutils literal notranslate"><span class="pre">metrics=[&quot;accuracy&quot;]</span></code> would result in <code class="docutils literal notranslate"><span class="pre">dict_keys(['loss',</span> <span class="pre">'acc'])</span></code></p>
</div>
<div class="section" id="Keras-optimizers">
<h4>Keras optimizers<a class="headerlink" href="#Keras-optimizers" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The optimizers in <code class="docutils literal notranslate"><span class="pre">v1.train</span></code>, such as <code class="docutils literal notranslate"><span class="pre">v1.train.AdamOptimizer</span></code> and <code class="docutils literal notranslate"><span class="pre">v1.train.GradientDescentOptimizer</span></code>, have equivalents in <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code>.</p>
<div class="section" id="Convert-v1.train-to-keras.optimizers">
<h5>Convert <code class="docutils literal notranslate"><span class="pre">v1.train</span></code> to <code class="docutils literal notranslate"><span class="pre">keras.optimizers</span></code><a class="headerlink" href="#Convert-v1.train-to-keras.optimizers" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Here are things to keep in mind when converting your optimizers:</p>
<ul class="simple">
<li><p>Upgrading your optimizers <a class="reference external" href="#checkpoints">may make old checkpoints incompatible</a>.</p></li>
<li><p>All epsilons now default to <code class="docutils literal notranslate"><span class="pre">1e-7</span></code> instead of <code class="docutils literal notranslate"><span class="pre">1e-8</span></code> (which is negligible in most use cases).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1.train.GradientDescentOptimizer</span></code> can be directly replaced by <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.SGD</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1.train.MomentumOptimizer</span></code> can be directly replaced by the <code class="docutils literal notranslate"><span class="pre">SGD</span></code> optimizer using the momentum argument: <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.SGD(...,</span> <span class="pre">momentum=...)</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1.train.AdamOptimizer</span></code> can be converted to use <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Adam</span></code>. The <code class="docutils literal notranslate"><span class="pre">beta1</span></code> and <code class="docutils literal notranslate"><span class="pre">beta2</span></code> arguments have been renamed to <code class="docutils literal notranslate"><span class="pre">beta_1</span></code> and <code class="docutils literal notranslate"><span class="pre">beta_2</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1.train.RMSPropOptimizer</span></code> can be converted to <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.RMSprop</span></code>. The <code class="docutils literal notranslate"><span class="pre">decay</span></code> argument has been renamed to <code class="docutils literal notranslate"><span class="pre">rho</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1.train.AdadeltaOptimizer</span></code> can be converted directly to <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Adadelta</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.train.AdagradOptimizer</span></code> can be converted directly to <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Adagrad</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.train.FtrlOptimizer</span></code> can be converted directly to <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Ftrl</span></code>. The <code class="docutils literal notranslate"><span class="pre">accum_name</span></code> and <code class="docutils literal notranslate"><span class="pre">linear_name</span></code> arguments have been removed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.contrib.AdamaxOptimizer</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.contrib.NadamOptimizer</span></code> can be converted directly to <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Adamax</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Nadam</span></code>, respectively. The <code class="docutils literal notranslate"><span class="pre">beta1</span></code>, and <code class="docutils literal notranslate"><span class="pre">beta2</span></code> arguments have been renamed to <code class="docutils literal notranslate"><span class="pre">beta_1</span></code> and <code class="docutils literal notranslate"><span class="pre">beta_2</span></code>.</p></li>
</ul>
</div>
<div class="section" id="New-defaults-for-some-tf.keras.optimizers">
<h5>New defaults for some <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code><a class="headerlink" href="#New-defaults-for-some-tf.keras.optimizers" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Warning: If you see a change in convergence behavior for your models, check the default learning rates.</p>
<p>There are no changes for <code class="docutils literal notranslate"><span class="pre">optimizers.SGD</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizers.Adam</span></code>, or <code class="docutils literal notranslate"><span class="pre">optimizers.RMSprop</span></code>.</p>
<p>The following default learning rates have changed:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">optimizers.Adagrad</span></code> from 0.01 to 0.001</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizers.Adadelta</span></code> from 1.0 to 0.001</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizers.Adamax</span></code> from 0.002 to 0.001</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizers.Nadam</span></code> from 0.002 to 0.001</p></li>
</ul>
</div>
</div>
<div class="section" id="TensorBoard">
<h4>TensorBoard<a class="headerlink" href="#TensorBoard" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow 2.x includes significant changes to the <code class="docutils literal notranslate"><span class="pre">tf.summary</span></code> API used to write summary data for visualization in TensorBoard. For a general introduction to the new <code class="docutils literal notranslate"><span class="pre">tf.summary</span></code>, there are <a class="reference external" href="https://www.tensorflow.org/tensorboard/get_started">several tutorials available</a> that use the TensorFlow 2.x API. This includes a <a class="reference external" href="https://www.tensorflow.org/tensorboard/migrate">TensorBoard TensorFlow 2.x migration guide</a>.</p>
</div>
</div>
<div class="section" id="Saving-and-loading">
<h3>Saving and loading<a class="headerlink" href="#Saving-and-loading" title="Enlazar permanentemente con este título">¶</a></h3>
<blockquote>
<div><p>### Checkpoint compatibility</p>
</div></blockquote>
<p>TensorFlow 2.x uses <a class="reference internal" href="checkpoint.html"><span class="doc">object-based checkpoints</span></a>.</p>
<p>Old-style name-based checkpoints can still be loaded, if you’re careful. The code conversion process may result in variable name changes, but there are workarounds.</p>
<p>The simplest approach it to line up the names of the new model with the names in the checkpoint:</p>
<ul class="simple">
<li><p>Variables still all have a <code class="docutils literal notranslate"><span class="pre">name</span></code> argument you can set.</p></li>
<li><p>Keras models also take a <code class="docutils literal notranslate"><span class="pre">name</span></code> argument as which they set as the prefix for their variables.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">v1.name_scope</span></code> function can be used to set variable name prefixes. This is very different from <code class="docutils literal notranslate"><span class="pre">tf.variable_scope</span></code>. It only affects names, and doesn’t track variables and reuse.</p></li>
</ul>
<p>If that does not work for your use case, try the <code class="docutils literal notranslate"><span class="pre">v1.train.init_from_checkpoint</span></code> function. It takes an <code class="docutils literal notranslate"><span class="pre">assignment_map</span></code> argument, which specifies the mapping from old names to new names.</p>
<p>Note: Unlike object-based checkpoints, which can defer loading, name-based checkpoints require that all variables be built when the function is called. Some models defer building variables until you call <code class="docutils literal notranslate"><span class="pre">build</span></code> or run the model on a batch of data.</p>
<p>The <a class="reference external" href="https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tools/checkpoint_converter.py">TensorFlow Estimator repository</a> includes a <a class="reference external" href="#checkpoint_converter">conversion tool</a> to upgrade the checkpoints for premade estimators from TensorFlow 1.x to 2.0. It may serve as an example of how to build a tool for a similar use case.</p>
<div class="section" id="Saved-models-compatibility">
<h4>Saved models compatibility<a class="headerlink" href="#Saved-models-compatibility" title="Enlazar permanentemente con este título">¶</a></h4>
<p>There are no significant compatibility concerns for saved models.</p>
<ul class="simple">
<li><p>TensorFlow 1.x saved_models work in TensorFlow 2.x.</p></li>
<li><p>TensorFlow 2.x saved_models work in TensorFlow 1.x if all the ops are supported.</p></li>
</ul>
</div>
<div class="section" id="A-Graph.pb-or-Graph.pbtxt">
<h4>A Graph.pb or Graph.pbtxt<a class="headerlink" href="#A-Graph.pb-or-Graph.pbtxt" title="Enlazar permanentemente con este título">¶</a></h4>
<p>There is no straightforward way to upgrade a raw <code class="docutils literal notranslate"><span class="pre">Graph.pb</span></code> file to TensorFlow 2.x. Your best bet is to upgrade the code that generated the file.</p>
<p>But, if you have a “frozen graph” (a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> where the variables have been turned into constants), then it is possible to convert this to a <code class="docutils literal notranslate"><span class="pre">`concrete_function</span></code> &lt;<a class="reference external" href="https://tensorflow.org/guide/concrete_function">https://tensorflow.org/guide/concrete_function</a>&gt;`__ using <code class="docutils literal notranslate"><span class="pre">v1.wrap_function</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def wrap_frozen_graph(graph_def, inputs, outputs):
  def _imports_graph_def():
    tf.compat.v1.import_graph_def(graph_def, name=&quot;&quot;)
  wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])
  import_graph = wrapped_import.graph
  return wrapped_import.prune(
      tf.nest.map_structure(import_graph.as_graph_element, inputs),
      tf.nest.map_structure(import_graph.as_graph_element, outputs))
</pre></div>
</div>
</div>
<p>For example, here is a frozed graph for Inception v1, from 2016:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>path = tf.keras.utils.get_file(
    &#39;inception_v1_2016_08_28_frozen.pb&#39;,
    &#39;http://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz&#39;,
    untar=True)
</pre></div>
</div>
</div>
<p>Load the <code class="docutils literal notranslate"><span class="pre">tf.GraphDef</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>graph_def = tf.compat.v1.GraphDef()
loaded = graph_def.ParseFromString(open(path,&#39;rb&#39;).read())
</pre></div>
</div>
</div>
<p>Wrap it into a <code class="docutils literal notranslate"><span class="pre">concrete_function</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>inception_func = wrap_frozen_graph(
    graph_def, inputs=&#39;input:0&#39;,
    outputs=&#39;InceptionV1/InceptionV1/Mixed_3b/Branch_1/Conv2d_0a_1x1/Relu:0&#39;)
</pre></div>
</div>
</div>
<p>Pass it a tensor as input:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>input_img = tf.ones([1,224,224,3], dtype=tf.float32)
inception_func(input_img).shape
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Estimators">
<h3>Estimators<a class="headerlink" href="#Estimators" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Training-with-Estimators">
<h4>Training with Estimators<a class="headerlink" href="#Training-with-Estimators" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Estimators are supported in TensorFlow 2.x.</p>
<p>When you use estimators, you can use <code class="docutils literal notranslate"><span class="pre">input_fn</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.estimator.TrainSpec</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.estimator.EvalSpec</span></code> from TensorFlow 1.x.</p>
<p>Here is an example using <code class="docutils literal notranslate"><span class="pre">input_fn</span></code> with train and evaluate specs.</p>
<div class="section" id="Creating-the-input_fn-and-train/eval-specs">
<h5>Creating the input_fn and train/eval specs<a class="headerlink" href="#Creating-the-input_fn-and-train/eval-specs" title="Enlazar permanentemente con este título">¶</a></h5>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Define the estimator&#39;s input_fn
def input_fn():
  datasets, info = tfds.load(name=&#39;mnist&#39;, with_info=True, as_supervised=True)
  mnist_train, mnist_test = datasets[&#39;train&#39;], datasets[&#39;test&#39;]

  BUFFER_SIZE = 10000
  BATCH_SIZE = 64

  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255

    return image, label[..., tf.newaxis]

  train_data = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
  return train_data.repeat()

# Define train and eval specs
train_spec = tf.estimator.TrainSpec(input_fn=input_fn,
                                    max_steps=STEPS_PER_EPOCH * NUM_EPOCHS)
eval_spec = tf.estimator.EvalSpec(input_fn=input_fn,
                                  steps=STEPS_PER_EPOCH)

</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Using-a-Keras-model-definition">
<h4>Using a Keras model definition<a class="headerlink" href="#Using-a-Keras-model-definition" title="Enlazar permanentemente con este título">¶</a></h4>
<p>There are some differences in how to construct your estimators in TensorFlow 2.x.</p>
<p>It’s recommended that you define your model using Keras, then use the <code class="docutils literal notranslate"><span class="pre">tf.keras.estimator.model_to_estimator</span></code> utility to turn your model into an estimator. The code below shows how to use this utility when creating and training an estimator.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def make_model():
  return tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, 3, activation=&#39;relu&#39;,
                           kernel_regularizer=tf.keras.regularizers.l2(0.02),
                           input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(64, activation=&#39;relu&#39;),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(10)
  ])
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = make_model()

model.compile(optimizer=&#39;adam&#39;,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=[&#39;accuracy&#39;])

estimator = tf.keras.estimator.model_to_estimator(
  keras_model = model
)

tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</pre></div>
</div>
</div>
<p>Note: TensorFlow does not support creating weighted metrics in Keras and converting them to weighted metrics in the Estimator API using <code class="docutils literal notranslate"><span class="pre">model_to_estimator</span></code>. You will have to create these metrics directly on the estimator spec using the <code class="docutils literal notranslate"><span class="pre">add_metrics</span></code> function.</p>
</div>
<div class="section" id="Using-a-custom-model_fn">
<h4>Using a custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code><a class="headerlink" href="#Using-a-custom-model_fn" title="Enlazar permanentemente con este título">¶</a></h4>
<p>If you have an existing custom estimator <code class="docutils literal notranslate"><span class="pre">model_fn</span></code> that you need to maintain, you can convert your <code class="docutils literal notranslate"><span class="pre">model_fn</span></code> to use a Keras model.</p>
<p>However, for compatibility reasons, a custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code> will still run in 1.x-style graph mode. This means there is no eager execution and no automatic control dependencies.</p>
<p>Note: In the long term, you should plan to migrate away from <code class="docutils literal notranslate"><span class="pre">tf.estimator</span></code>, especially using a custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code>. The alternative APIs are <code class="docutils literal notranslate"><span class="pre">tf.keras</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.distribute</span></code>. If you still need an <code class="docutils literal notranslate"><span class="pre">Estimator</span></code> for some part of your training, you can use the <code class="docutils literal notranslate"><span class="pre">tf.keras.estimator.model_to_estimator</span></code> converter to create an <code class="docutils literal notranslate"><span class="pre">Estimator</span></code> from a <code class="docutils literal notranslate"><span class="pre">keras.Model</span></code>.</p>
<div class="section" id="Custom-model_fn-with-minimal-changes">
<h5>Custom model_fn with minimal changes<a class="headerlink" href="#Custom-model_fn-with-minimal-changes" title="Enlazar permanentemente con este título">¶</a></h5>
<p>To make your custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code> work in TensorFlow 2.x, if you prefer minimal changes to the existing code, <code class="docutils literal notranslate"><span class="pre">tf.compat.v1</span></code> symbols such as <code class="docutils literal notranslate"><span class="pre">optimizers</span></code> and <code class="docutils literal notranslate"><span class="pre">metrics</span></code> can be used.</p>
<p>Using a Keras model in a custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code> is similar to using it in a custom training loop:</p>
<ul class="simple">
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">training</span></code> phase appropriately, based on the <code class="docutils literal notranslate"><span class="pre">mode</span></code> argument.</p></li>
<li><p>Explicitly pass the model’s <code class="docutils literal notranslate"><span class="pre">trainable_variables</span></code> to the optimizer.</p></li>
</ul>
<p>But there are important differences, relative to a <a class="reference external" href="#custom_loop">custom loop</a>:</p>
<ul class="simple">
<li><p>Instead of using <code class="docutils literal notranslate"><span class="pre">Model.losses</span></code>, extract the losses using <code class="docutils literal notranslate"><span class="pre">Model.get_losses_for</span></code>.</p></li>
<li><p>Extract the model’s updates using <code class="docutils literal notranslate"><span class="pre">Model.get_updates_for</span></code>.</p></li>
</ul>
<p>Note: “Updates” are changes that need to be applied to a model after each batch. For example, the moving averages of the mean and variance in a <code class="docutils literal notranslate"><span class="pre">layers.BatchNormalization</span></code> layer.</p>
<p>The following code creates an estimator from a custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code>, illustrating all of these concerns.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def my_model_fn(features, labels, mode):
  model = make_model()

  optimizer = tf.compat.v1.train.AdamOptimizer()
  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

  training = (mode == tf.estimator.ModeKeys.TRAIN)
  predictions = model(features, training=training)

  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

  reg_losses = model.get_losses_for(None) + model.get_losses_for(features)
  total_loss=loss_fn(labels, predictions) + tf.math.add_n(reg_losses)

  accuracy = tf.compat.v1.metrics.accuracy(labels=labels,
                                           predictions=tf.math.argmax(predictions, axis=1),
                                           name=&#39;acc_op&#39;)

  update_ops = model.get_updates_for(None) + model.get_updates_for(features)
  minimize_op = optimizer.minimize(
      total_loss,
      var_list=model.trainable_variables,
      global_step=tf.compat.v1.train.get_or_create_global_step())
  train_op = tf.group(minimize_op, update_ops)

  return tf.estimator.EstimatorSpec(
    mode=mode,
    predictions=predictions,
    loss=total_loss,
    train_op=train_op, eval_metric_ops={&#39;accuracy&#39;: accuracy})

# Create the Estimator &amp; Train
estimator = tf.estimator.Estimator(model_fn=my_model_fn)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Custom-model_fn-with-TensorFlow-2.x-symbols">
<h5>Custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code> with TensorFlow 2.x symbols<a class="headerlink" href="#Custom-model_fn-with-TensorFlow-2.x-symbols" title="Enlazar permanentemente con este título">¶</a></h5>
<p>If you want to get rid of all TensorFlow 1.x symbols and upgrade your custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code> to TensorFlow 2.x, you need to update the optimizer and metrics to <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.keras.metrics</span></code>.</p>
<p>In the custom <code class="docutils literal notranslate"><span class="pre">model_fn</span></code>, besides the above <a class="reference external" href="#minimal_changes">changes</a>, more upgrades need to be made:</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code> instead of <code class="docutils literal notranslate"><span class="pre">v1.train.Optimizer</span></code>.</p></li>
<li><p>Explicitly pass the model’s <code class="docutils literal notranslate"><span class="pre">trainable_variables</span></code> to the <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code>.</p></li>
<li><p>To compute the <code class="docutils literal notranslate"><span class="pre">train_op/minimize_op</span></code>,</p>
<ul>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">Optimizer.get_updates</span></code> if the loss is scalar loss <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> (not a callable). The first element in the returned list is the desired <code class="docutils literal notranslate"><span class="pre">train_op/minimize_op</span></code>.</p></li>
<li><p>If the loss is a callable (such as a function), use <code class="docutils literal notranslate"><span class="pre">Optimizer.minimize</span></code> to get the <code class="docutils literal notranslate"><span class="pre">train_op/minimize_op</span></code>.</p></li>
</ul>
</li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">tf.keras.metrics</span></code> instead of <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.metrics</span></code> for evaluation.</p></li>
</ul>
<p>For the above example of <code class="docutils literal notranslate"><span class="pre">my_model_fn</span></code>, the migrated code with TensorFlow 2.x symbols is shown as:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def my_model_fn(features, labels, mode):
  model = make_model()

  training = (mode == tf.estimator.ModeKeys.TRAIN)
  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
  predictions = model(features, training=training)

  # Get both the unconditional losses (the None part)
  # and the input-conditional losses (the features part).
  reg_losses = model.get_losses_for(None) + model.get_losses_for(features)
  total_loss=loss_obj(labels, predictions) + tf.math.add_n(reg_losses)

  # Upgrade to tf.keras.metrics.
  accuracy_obj = tf.keras.metrics.Accuracy(name=&#39;acc_obj&#39;)
  accuracy = accuracy_obj.update_state(
      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))

  train_op = None
  if training:
    # Upgrade to tf.keras.optimizers.
    optimizer = tf.keras.optimizers.Adam()
    # Manually assign tf.compat.v1.global_step variable to optimizer.iterations
    # to make tf.compat.v1.train.global_step increased correctly.
    # This assignment is a must for any `tf.train.SessionRunHook` specified in
    # estimator, as SessionRunHooks rely on global step.
    optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()
    # Get both the unconditional updates (the None part)
    # and the input-conditional updates (the features part).
    update_ops = model.get_updates_for(None) + model.get_updates_for(features)
    # Compute the minimize_op.
    minimize_op = optimizer.get_updates(
        total_loss,
        model.trainable_variables)[0]
    train_op = tf.group(minimize_op, *update_ops)

  return tf.estimator.EstimatorSpec(
    mode=mode,
    predictions=predictions,
    loss=total_loss,
    train_op=train_op,
    eval_metric_ops={&#39;Accuracy&#39;: accuracy_obj})

# Create the Estimator and train.
estimator = tf.estimator.Estimator(model_fn=my_model_fn)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Premade-Estimators">
<h4>Premade Estimators<a class="headerlink" href="#Premade-Estimators" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference external" href="https://www.tensorflow.org/guide/premade_estimators">Premade Estimators</a> in the family of <code class="docutils literal notranslate"><span class="pre">tf.estimator.DNN*</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.estimator.Linear*</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.estimator.DNNLinearCombined*</span></code> are still supported in the TensorFlow 2.x API. However, some arguments have changed:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_partitioner</span></code>: Removed in v2.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss_reduction</span></code>: Updated to <code class="docutils literal notranslate"><span class="pre">tf.keras.losses.Reduction</span></code> instead of <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.losses.Reduction</span></code>. Its default value is also changed to <code class="docutils literal notranslate"><span class="pre">tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE</span></code> from <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.losses.Reduction.SUM</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code>, <code class="docutils literal notranslate"><span class="pre">dnn_optimizer</span></code> and <code class="docutils literal notranslate"><span class="pre">linear_optimizer</span></code>: this argument has been updated to <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code> instead of the <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.train.Optimizer</span></code>.</p></li>
</ol>
<p>To migrate the above changes:</p>
<ol class="arabic simple">
<li><p>No migration is needed for <code class="docutils literal notranslate"><span class="pre">input_layer_partitioner</span></code> since <code class="docutils literal notranslate"><span class="pre">`Distribution</span> <span class="pre">Strategy</span></code> &lt;<a class="reference external" href="https://www.tensorflow.org/guide/distributed_training">https://www.tensorflow.org/guide/distributed_training</a>&gt;`__ will handle it automatically in TensorFlow 2.x.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">loss_reduction</span></code>, check <code class="docutils literal notranslate"><span class="pre">tf.keras.losses.Reduction</span></code> for the supported options.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> arguments:</p>
<ul class="simple">
<li><p>If you do not: 1) pass in the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code>, <code class="docutils literal notranslate"><span class="pre">dnn_optimizer</span></code> or <code class="docutils literal notranslate"><span class="pre">linear_optimizer</span></code> argument, or 2) specify the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> argument as a <code class="docutils literal notranslate"><span class="pre">string</span></code> in your code, then you don’t need to change anything because <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code> is used by default.</p></li>
<li><p>Otherwise, you need to update it from <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.train.Optimizer</span></code> to its corresponding <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code>.</p></li>
</ul>
</li>
</ol>
<div class="section" id="Checkpoint-Converter">
<h5>Checkpoint Converter<a class="headerlink" href="#Checkpoint-Converter" title="Enlazar permanentemente con este título">¶</a></h5>
<p>The migration to <code class="docutils literal notranslate"><span class="pre">keras.optimizers</span></code> will break checkpoints saved using TensorFlow 1.x, as <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code> generates a different set of variables to be saved in checkpoints. To make old checkpoint reusable after your migration to TensorFlow 2.x, try the <a class="reference external" href="https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tools/checkpoint_converter.py">checkpoint converter tool</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>! curl -O https://raw.githubusercontent.com/tensorflow/estimator/master/tensorflow_estimator/python/estimator/tools/checkpoint_converter.py
</pre></div>
</div>
</div>
<p>The tool has built-in help:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>! python checkpoint_converter.py -h
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="TensorShape">
<h3>TensorShape<a class="headerlink" href="#TensorShape" title="Enlazar permanentemente con este título">¶</a></h3>
<p>This class was simplified to hold <code class="docutils literal notranslate"><span class="pre">int</span></code>s, instead of <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.Dimension</span></code> objects. So there is no need to call <code class="docutils literal notranslate"><span class="pre">.value</span></code> to get an <code class="docutils literal notranslate"><span class="pre">int</span></code>.</p>
<p>Individual <code class="docutils literal notranslate"><span class="pre">tf.compat.v1.Dimension</span></code> objects are still accessible from <code class="docutils literal notranslate"><span class="pre">tf.TensorShape.dims</span></code>.</p>
<p>The following demonstrate the differences between TensorFlow 1.x and TensorFlow 2.x.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Create a shape and choose an index
i = 0
shape = tf.TensorShape([16, None, 256])
shape
</pre></div>
</div>
</div>
<p>If you had this in TensorFlow 1.x:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">value</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
</pre></div>
</div>
<p>Then do this in TensorFlow 2.x:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>value = shape[i]
value
</pre></div>
</div>
</div>
<p>If you had this in TensorFlow 1.x:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">dim</span><span class="o">.</span><span class="n">value</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
<p>Then do this in TensorFlow 2.x:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for value in shape:
  print(value)
</pre></div>
</div>
</div>
<p>If you had this in TensorFlow 1.x (or used any other dimension method):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dim</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="n">dim</span><span class="o">.</span><span class="n">assert_is_compatible_with</span><span class="p">(</span><span class="n">other_dim</span><span class="p">)</span>
</pre></div>
</div>
<p>Then do this in TensorFlow 2.x:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>other_dim = 16
Dimension = tf.compat.v1.Dimension

if shape.rank is None:
  dim = Dimension(None)
else:
  dim = shape.dims[i]
dim.is_compatible_with(other_dim) # or any other dimension method
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>shape = tf.TensorShape(None)

if shape:
  dim = shape.dims[i]
  dim.is_compatible_with(other_dim) # or any other dimension method
</pre></div>
</div>
</div>
<p>The boolean value of a <code class="docutils literal notranslate"><span class="pre">tf.TensorShape</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> if the rank is known, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(bool(tf.TensorShape([])))      # Scalar
print(bool(tf.TensorShape([0])))     # 0-length vector
print(bool(tf.TensorShape([1])))     # 1-length vector
print(bool(tf.TensorShape([None])))  # Unknown-length vector
print(bool(tf.TensorShape([1, 10, 100])))       # 3D tensor
print(bool(tf.TensorShape([None, None, None]))) # 3D tensor with no known dimensions
print()
print(bool(tf.TensorShape(None)))  # A tensor with unknown rank.
</pre></div>
</div>
</div>
</div>
<div class="section" id="Other-changes">
<h3>Other changes<a class="headerlink" href="#Other-changes" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li><p>Remove <code class="docutils literal notranslate"><span class="pre">tf.colocate_with</span></code>: TensorFlow’s device placement algorithms have improved significantly. This should no longer be necessary. If removing it causes a performance degredation <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues">please file a bug</a>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">v1.ConfigProto</span></code> usage with the equivalent functions from <code class="docutils literal notranslate"><span class="pre">tf.config</span></code>.</p></li>
</ul>
</div>
<div class="section" id="Conclusions">
<h3>Conclusions<a class="headerlink" href="#Conclusions" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The overall process is:</p>
<ol class="arabic simple">
<li><p>Run the upgrade script.</p></li>
<li><p>Remove contrib symbols.</p></li>
<li><p>Switch your models to an object oriented style (Keras).</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">tf.keras</span></code> or <code class="docutils literal notranslate"><span class="pre">tf.estimator</span></code> training and evaluation loops where you can.</p></li>
<li><p>Otherwise, use custom loops, but be sure to avoid sessions &amp; collections.</p></li>
</ol>
<p>It takes a little work to convert code to idiomatic TensorFlow 2.x, but every change results in:</p>
<ul class="simple">
<li><p>Fewer lines of code.</p></li>
<li><p>Increased clarity and simplicity.</p></li>
<li><p>Easier debugging.</p></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>