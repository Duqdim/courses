

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2018 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2018 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow__por_revisar/guide/saved_model.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2018-The-TensorFlow-Authors.">
<h1>Copyright 2018 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2018-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="Using-the-SavedModel-format">
<h2>Using the SavedModel format<a class="headerlink" href="#Using-the-SavedModel-format" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>ac2119e3a8ca42a1a8092c1b06892f0f|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>b88a868664614f119f58006403b2f799|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>6dd729be144a4338a5316b2ac1811861|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>8f2af64d23fb48609998670b96a6514e|Download notebook</p>
</td></table><p>A SavedModel contains a complete TensorFlow program, including trained parameters (i.e, <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code>s) and computation. It does not require the original model building code to run, which makes it useful for sharing or deploying with <a class="reference external" href="https://tensorflow.org/lite">TFLite</a>, <a class="reference external" href="https://js.tensorflow.org/">TensorFlow.js</a>, <a class="reference external" href="https://www.tensorflow.org/tfx/serving/tutorials/Serving_REST_simple">TensorFlow Serving</a>, or <a class="reference external" href="https://tensorflow.org/hub">TensorFlow Hub</a>.</p>
<p>You can save and load a model in the SavedModel format using the following APIs: - Low-level <code class="docutils literal notranslate"><span class="pre">tf.saved_model</span></code> API. This document describes how to use this API in detail. - Save: <code class="docutils literal notranslate"><span class="pre">tf.saved_model.save(model,</span> <span class="pre">path_to_dir)</span></code> - Load: <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">=</span> <span class="pre">tf.saved_model.load(path_to_dir)</span></code> - High-level <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> API. Refer to <a class="reference external" href="keras/save_and_serialize.ipynb">the keras save and serialize guide</a>. - If you just want to save/load weights during training, refer to <a class="reference internal" href="checkpoint.html"><span class="doc">the checkpoints
guide</span></a>.</p>
<div class="section" id="Creating-a-SavedModel-from-Keras">
<h3>Creating a SavedModel from Keras<a class="headerlink" href="#Creating-a-SavedModel-from-Keras" title="Enlazar permanentemente con este título">¶</a></h3>
<p>For a quick introduction, this section exports a pre-trained Keras model and serves image classification requests with it. The rest of the guide will fill in details and discuss other ways to create SavedModels.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import os
import tempfile

from matplotlib import pyplot as plt
import numpy as np
import tensorflow as tf

tmpdir = tempfile.mkdtemp()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>physical_devices = tf.config.list_physical_devices(&#39;GPU&#39;)
for device in physical_devices:
  tf.config.experimental.set_memory_growth(device, True)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>file = tf.keras.utils.get_file(
    &quot;grace_hopper.jpg&quot;,
    &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg&quot;)
img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])
plt.imshow(img)
plt.axis(&#39;off&#39;)
x = tf.keras.preprocessing.image.img_to_array(img)
x = tf.keras.applications.mobilenet.preprocess_input(
    x[tf.newaxis,...])
</pre></div>
</div>
</div>
<p>You’ll use an image of Grace Hopper as a running example, and a Keras pre-trained image classification model since it’s easy to use. Custom models work too, and are covered in detail later.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>labels_path = tf.keras.utils.get_file(
    &#39;ImageNetLabels.txt&#39;,
    &#39;https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt&#39;)
imagenet_labels = np.array(open(labels_path).read().splitlines())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>pretrained_model = tf.keras.applications.MobileNet()
result_before_save = pretrained_model(x)

decoded = imagenet_labels[np.argsort(result_before_save)[0,::-1][:5]+1]

print(&quot;Result before saving:\n&quot;, decoded)
</pre></div>
</div>
</div>
<p>The top prediction for this image is “military uniform”.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>mobilenet_save_path = os.path.join(tmpdir, &quot;mobilenet/1/&quot;)
tf.saved_model.save(pretrained_model, mobilenet_save_path)
</pre></div>
</div>
</div>
<p>The save-path follows a convention used by TensorFlow Serving where the last path component (<code class="docutils literal notranslate"><span class="pre">1/</span></code> here) is a version number for your model - it allows tools like Tensorflow Serving to reason about the relative freshness.</p>
<p>You can load the SavedModel back into Python with <code class="docutils literal notranslate"><span class="pre">tf.saved_model.load</span></code> and see how Admiral Hopper’s image is classified.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>loaded = tf.saved_model.load(mobilenet_save_path)
print(list(loaded.signatures.keys()))  # [&quot;serving_default&quot;]
</pre></div>
</div>
</div>
<p>Imported signatures always return dictionaries. To customize signature names and output dictionary keys, see <a class="reference external" href="#specifying_signatures_during_export">Specifying signatures during export</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>infer = loaded.signatures[&quot;serving_default&quot;]
print(infer.structured_outputs)
</pre></div>
</div>
</div>
<p>Running inference from the SavedModel gives the same result as the original model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>labeling = infer(tf.constant(x))[pretrained_model.output_names[0]]

decoded = imagenet_labels[np.argsort(labeling)[0,::-1][:5]+1]

print(&quot;Result after saving and loading:\n&quot;, decoded)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Running-a-SavedModel-in-TensorFlow-Serving">
<h3>Running a SavedModel in TensorFlow Serving<a class="headerlink" href="#Running-a-SavedModel-in-TensorFlow-Serving" title="Enlazar permanentemente con este título">¶</a></h3>
<p>SavedModels are usable from Python (more on that below), but production environments typically use a dedicated service for inference without running Python code. This is easy to set up from a SavedModel using TensorFlow Serving.</p>
<p>See the <a class="reference external" href="https://www.tensorflow.org/tfx/tutorials/serving/rest_simple">TensorFlow Serving REST tutorial</a> for an end-to-end tensorflow-serving example.</p>
</div>
<div class="section" id="The-SavedModel-format-on-disk">
<h3>The SavedModel format on disk<a class="headerlink" href="#The-SavedModel-format-on-disk" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A SavedModel is a directory containing serialized signatures and the state needed to run them, including variable values and vocabularies.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>!ls {mobilenet_save_path}
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">saved_model.pb</span></code> file stores the actual TensorFlow program, or model, and a set of named signatures, each identifying a function that accepts tensor inputs and produces tensor outputs.</p>
<p>SavedModels may contain multiple variants of the model (multiple <code class="docutils literal notranslate"><span class="pre">v1.MetaGraphDefs</span></code>, identified with the <code class="docutils literal notranslate"><span class="pre">--tag_set</span></code> flag to <code class="docutils literal notranslate"><span class="pre">saved_model_cli</span></code>), but this is rare. APIs which create multiple variants of a model include <code class="docutils literal notranslate"><span class="pre">`tf.Estimator.experimental_export_all_saved_models</span></code> &lt;<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#experimental_export_all_saved_models">https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#experimental_export_all_saved_models</a>&gt;`__ and in TensorFlow 1.x <code class="docutils literal notranslate"><span class="pre">tf.saved_model.Builder</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>!saved_model_cli show --dir {mobilenet_save_path} --tag_set serve
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">variables</span></code> directory contains a standard training checkpoint (see the <a class="reference internal" href="checkpoint.html"><span class="doc">guide to training checkpoints</span></a>).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>!ls {mobilenet_save_path}/variables
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">assets</span></code> directory contains files used by the TensorFlow graph, for example text files used to initialize vocabulary tables. It is unused in this example.</p>
<p>SavedModels may have an <code class="docutils literal notranslate"><span class="pre">assets.extra</span></code> directory for any files not used by the TensorFlow graph, for example information for consumers about what to do with the SavedModel. TensorFlow itself does not use this directory.</p>
</div>
<div class="section" id="Saving-a-custom-model">
<h3>Saving a custom model<a class="headerlink" href="#Saving-a-custom-model" title="Enlazar permanentemente con este título">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">tf.saved_model.save</span></code> supports saving <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> objects and its subclasses, like <code class="docutils literal notranslate"><span class="pre">tf.keras.Layer</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>.</p>
<p>Let’s look at an example of saving and restoring a <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class CustomModule(tf.Module):

  def __init__(self):
    super(CustomModule, self).__init__()
    self.v = tf.Variable(1.)

  @tf.function
  def __call__(self, x):
    print(&#39;Tracing with&#39;, x)
    return x * self.v

  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])
  def mutate(self, new_v):
    self.v.assign(new_v)

module = CustomModule()
</pre></div>
</div>
</div>
<p>When you save a <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>, any <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> attributes, <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>-decorated methods, and <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>s found via recursive traversal are saved. (See the <a class="reference internal" href="checkpoint.html"><span class="doc">Checkpoint tutorial</span></a> for more about this recursive traversal.) However, any Python attributes, functions, and data are lost. This means that when a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> is saved, no Python code is saved.</p>
<p>If no Python code is saved, how does SavedModel know how to restore the function?</p>
<p>Briefly, <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> works by tracing the Python code to generate a ConcreteFunction (a callable wrapper around <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>). When saving a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>, you’re really saving the <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>’s cache of ConcreteFunctions.</p>
<p>To learn more about the relationship between <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> and ConcreteFunctions, see the <a class="reference external" href="../../guide/function">tf.function guide</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>module_no_signatures_path = os.path.join(tmpdir, &#39;module_no_signatures&#39;)
module(tf.constant(0.))
print(&#39;Saving model...&#39;)
tf.saved_model.save(module, module_no_signatures_path)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Loading-and-using-a-custom-model">
<h3>Loading and using a custom model<a class="headerlink" href="#Loading-and-using-a-custom-model" title="Enlazar permanentemente con este título">¶</a></h3>
<p>When you load a SavedModel in Python, all <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> attributes, <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>-decorated methods, and <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>s are restored in the same object structure as the original saved <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>imported = tf.saved_model.load(module_no_signatures_path)
assert imported(tf.constant(3.)).numpy() == 3
imported.mutate(tf.constant(2.))
assert imported(tf.constant(3.)).numpy() == 6
</pre></div>
</div>
</div>
<p>Because no Python code is saved, calling a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> with a new input signature will fail:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">imported</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">3.</span><span class="p">]))</span>
</pre></div>
</div>
<pre>
ValueError: Could not find matching function to call for canonicalized inputs ((<tf.Tensor 'args_0:0' shape=(1,) dtype=float32>,), {}). Only existing signatures are [((TensorSpec(shape=(), dtype=tf.float32, name=u'x'),), {})].
</pre><div class="section" id="Basic-fine-tuning">
<h4>Basic fine-tuning<a class="headerlink" href="#Basic-fine-tuning" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Variable objects are available, and you can backprop through imported functions. That is enough to fine-tune (i.e. retrain) a SavedModel in simple cases.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>optimizer = tf.optimizers.SGD(0.05)

def train_step():
  with tf.GradientTape() as tape:
    loss = (10. - imported(tf.constant(2.))) ** 2
  variables = tape.watched_variables()
  grads = tape.gradient(loss, variables)
  optimizer.apply_gradients(zip(grads, variables))
  return loss
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for _ in range(10):
  # &quot;v&quot; approaches 5, &quot;loss&quot; approaches 0
  print(&quot;loss={:.2f} v={:.2f}&quot;.format(train_step(), imported.v.numpy()))
</pre></div>
</div>
</div>
</div>
<div class="section" id="General-fine-tuning">
<h4>General fine-tuning<a class="headerlink" href="#General-fine-tuning" title="Enlazar permanentemente con este título">¶</a></h4>
<p>A SavedModel from Keras provides <a class="reference external" href="https://github.com/tensorflow/community/blob/master/rfcs/20190509-keras-saved-model.md#serialization-details">more details</a> than a plain <code class="docutils literal notranslate"><span class="pre">__call__</span></code> to address more advanced cases of fine-tuning. TensorFlow Hub recommends to provide the following of those, if applicable, in SavedModels shared for the purpose of fine-tuning:</p>
<ul class="simple">
<li><p>If the model uses dropout or another technique in which the forward pass differs between training and inference (like batch normalization), the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method takes an optional, Python-valued <code class="docutils literal notranslate"><span class="pre">training=</span></code> argument that defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code> but can be set to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p>Next to the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> attribute, there are <code class="docutils literal notranslate"><span class="pre">.variable</span></code> and <code class="docutils literal notranslate"><span class="pre">.trainable_variable</span></code> attributes with the corresponding lists of variables. A variable that was originally trainable but is meant to be frozen during fine-tuning is omitted from <code class="docutils literal notranslate"><span class="pre">.trainable_variables</span></code>.</p></li>
<li><p>For the sake of frameworks like Keras that represent weight regularizers as attributes of layers or sub-models, there can also be a <code class="docutils literal notranslate"><span class="pre">.regularization_losses</span></code> attribute. It holds a list of zero-argument functions whose values are meant for addition to the total loss.</p></li>
</ul>
<p>Going back to the initial MobileNet example, you can see some of those in action:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>loaded = tf.saved_model.load(mobilenet_save_path)
print(&quot;MobileNet has {} trainable variables: {}, ...&quot;.format(
          len(loaded.trainable_variables),
          &quot;, &quot;.join([v.name for v in loaded.trainable_variables[:5]])))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>trainable_variable_ids = {id(v) for v in loaded.trainable_variables}
non_trainable_variables = [v for v in loaded.variables
                           if id(v) not in trainable_variable_ids]
print(&quot;MobileNet also has {} non-trainable variables: {}, ...&quot;.format(
          len(non_trainable_variables),
          &quot;, &quot;.join([v.name for v in non_trainable_variables[:3]])))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Specifying-signatures-during-export">
<h3>Specifying signatures during export<a class="headerlink" href="#Specifying-signatures-during-export" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Tools like TensorFlow Serving and <code class="docutils literal notranslate"><span class="pre">saved_model_cli</span></code> can interact with SavedModels. To help these tools determine which ConcreteFunctions to use, you need to specify serving signatures. <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>s automatically specify serving signatures, but you’ll have to explicitly declare a serving signature for our custom modules.</p>
<p>IMPORTANT: Unless you need to export your model to an environment other than TensorFlow 2.x with Python, you probably don’t need to export signatures explicitly. If you’re looking for a way of enforcing an input signature for a specific function, see the <code class="docutils literal notranslate"><span class="pre">`input_signature</span></code> &lt;<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/function#args_1">https://www.tensorflow.org/api_docs/python/tf/function#args_1</a>&gt;`__ argument to <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>.</p>
<p>By default, no signatures are declared in a custom <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>assert len(imported.signatures) == 0
</pre></div>
</div>
</div>
<p>To declare a serving signature, specify a ConcreteFunction using the <code class="docutils literal notranslate"><span class="pre">signatures</span></code> kwarg. When specifying a single signature, its signature key will be <code class="docutils literal notranslate"><span class="pre">'serving_default'</span></code>, which is saved as the constant <code class="docutils literal notranslate"><span class="pre">tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>module_with_signature_path = os.path.join(tmpdir, &#39;module_with_signature&#39;)
call = module.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))
tf.saved_model.save(module, module_with_signature_path, signatures=call)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>imported_with_signatures = tf.saved_model.load(module_with_signature_path)
list(imported_with_signatures.signatures.keys())

</pre></div>
</div>
</div>
<p>To export multiple signatures, pass a dictionary of signature keys to ConcreteFunctions. Each signature key corresponds to one ConcreteFunction.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>module_multiple_signatures_path = os.path.join(tmpdir, &#39;module_with_multiple_signatures&#39;)
signatures = {&quot;serving_default&quot;: call,
              &quot;array_input&quot;: module.__call__.get_concrete_function(tf.TensorSpec([None], tf.float32))}

tf.saved_model.save(module, module_multiple_signatures_path, signatures=signatures)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>imported_with_multiple_signatures = tf.saved_model.load(module_multiple_signatures_path)
list(imported_with_multiple_signatures.signatures.keys())
</pre></div>
</div>
</div>
<p>By default, the output tensor names are fairly generic, like <code class="docutils literal notranslate"><span class="pre">output_0</span></code>. To control the names of outputs, modify your <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> to return a dictionary that maps output names to outputs. The names of inputs are derived from the Python function arg names.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class CustomModuleWithOutputName(tf.Module):
  def __init__(self):
    super(CustomModuleWithOutputName, self).__init__()
    self.v = tf.Variable(1.)

  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])
  def __call__(self, x):
    return {&#39;custom_output_name&#39;: x * self.v}

module_output = CustomModuleWithOutputName()
call_output = module_output.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))
module_output_path = os.path.join(tmpdir, &#39;module_with_output_name&#39;)
tf.saved_model.save(module_output, module_output_path,
                    signatures={&#39;serving_default&#39;: call_output})
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>imported_with_output_name = tf.saved_model.load(module_output_path)
imported_with_output_name.signatures[&#39;serving_default&#39;].structured_outputs
</pre></div>
</div>
</div>
</div>
<div class="section" id="Load-a-SavedModel-in-C++">
<h3>Load a SavedModel in C++<a class="headerlink" href="#Load-a-SavedModel-in-C++" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The C++ version of the SavedModel <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/loader.h">loader</a> provides an API to load a SavedModel from a path, while allowing SessionOptions and RunOptions. You have to specify the tags associated with the graph to be loaded. The loaded version of SavedModel is referred to as SavedModelBundle and contains the MetaGraphDef and the session within which it is loaded.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">const</span> <span class="n">string</span> <span class="n">export_dir</span> <span class="o">=</span> <span class="p">...</span>
<span class="n">SavedModelBundle</span> <span class="n">bundle</span><span class="p">;</span>
<span class="p">...</span>
<span class="n">LoadSavedModel</span><span class="p">(</span><span class="n">session_options</span><span class="p">,</span> <span class="n">run_options</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">,</span> <span class="p">{</span><span class="n">kSavedModelTagTrain</span><span class="p">},</span>
               <span class="o">&amp;</span><span class="n">bundle</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="Details-of-the-SavedModel-command-line-interface">
<h3>Details of the SavedModel command line interface<a class="headerlink" href="#Details-of-the-SavedModel-command-line-interface" title="Enlazar permanentemente con este título">¶</a></h3>
<p>You can use the SavedModel Command Line Interface (CLI) to inspect and execute a SavedModel. For example, you can use the CLI to inspect the model’s <code class="docutils literal notranslate"><span class="pre">SignatureDef</span></code>s. The CLI enables you to quickly confirm that the input Tensor dtype and shape match the model. Moreover, if you want to test your model, you can use the CLI to do a sanity check by passing in sample inputs in various formats (for example, Python expressions) and then fetching the output.</p>
<div class="section" id="Install-the-SavedModel-CLI">
<h4>Install the SavedModel CLI<a class="headerlink" href="#Install-the-SavedModel-CLI" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Broadly speaking, you can install TensorFlow in either of the following two ways:</p>
<ul class="simple">
<li><p>By installing a pre-built TensorFlow binary.</p></li>
<li><p>By building TensorFlow from source code.</p></li>
</ul>
<p>If you installed TensorFlow through a pre-built TensorFlow binary, then the SavedModel CLI is already installed on your system at pathname <code class="docutils literal notranslate"><span class="pre">bin/saved_model_cli</span></code>.</p>
<p>If you built TensorFlow from source code, you must run the following additional command to build <code class="docutils literal notranslate"><span class="pre">saved_model_cli</span></code>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ bazel build tensorflow/python/tools:saved_model_cli
</pre></div>
</div>
</div>
<div class="section" id="Overview-of-commands">
<h4>Overview of commands<a class="headerlink" href="#Overview-of-commands" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The SavedModel CLI supports the following two commands on a SavedModel:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">show</span></code>, which shows the computations available from a SavedModel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">run</span></code>, which runs a computation from a SavedModel.</p></li>
</ul>
</div>
<div class="section" id="show-command">
<h4><code class="docutils literal notranslate"><span class="pre">show</span></code> command<a class="headerlink" href="#show-command" title="Enlazar permanentemente con este título">¶</a></h4>
<p>A SavedModel contains one or more model variants (technically, <code class="docutils literal notranslate"><span class="pre">v1.MetaGraphDef</span></code>s), identified by their tag-sets. To serve a model, you might wonder what kind of <code class="docutils literal notranslate"><span class="pre">SignatureDef</span></code>s are in each model variant, and what are their inputs and outputs. The <code class="docutils literal notranslate"><span class="pre">show</span></code> command let you examine the contents of the SavedModel in hierarchical order. Here’s the syntax:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: saved_model_cli show [-h] --dir DIR [--all]
[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]
</pre></div>
</div>
<p>For example, the following command shows all available tag-sets in the SavedModel:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ saved_model_cli show --dir /tmp/saved_model_dir
The given SavedModel contains the following tag-sets:
serve
serve, gpu
</pre></div>
</div>
<p>The following command shows all available <code class="docutils literal notranslate"><span class="pre">SignatureDef</span></code> keys for a tag set:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve
The given SavedModel `MetaGraphDef` contains `SignatureDefs` with the
following keys:
SignatureDef key: &quot;classify_x2_to_y3&quot;
SignatureDef key: &quot;classify_x_to_y&quot;
SignatureDef key: &quot;regress_x2_to_y3&quot;
SignatureDef key: &quot;regress_x_to_y&quot;
SignatureDef key: &quot;regress_x_to_y2&quot;
SignatureDef key: &quot;serving_default&quot;
</pre></div>
</div>
<p>If there are <em>multiple</em> tags in the tag-set, you must specify all tags, each tag separated by a comma. For example:</p>
<pre>
$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve,gpu
</pre><p>To show all inputs and outputs TensorInfo for a specific <code class="docutils literal notranslate"><span class="pre">SignatureDef</span></code>, pass in the <code class="docutils literal notranslate"><span class="pre">SignatureDef</span></code> key to <code class="docutils literal notranslate"><span class="pre">signature_def</span></code> option. This is very useful when you want to know the tensor key value, dtype and shape of the input tensors for executing the computation graph later. For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ saved_model_cli show --dir \
/tmp/saved_model_dir --tag_set serve --signature_def serving_default
The given SavedModel SignatureDef contains the following input(s):
  inputs[&#39;x&#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 1)
      name: x:0
The given SavedModel SignatureDef contains the following output(s):
  outputs[&#39;y&#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 1)
      name: y:0
Method name is: tensorflow/serving/predict
</pre></div>
</div>
<p>To show all available information in the SavedModel, use the <code class="docutils literal notranslate"><span class="pre">--all</span></code> option. For example:</p>
<pre>
$ saved_model_cli show --dir /tmp/saved_model_dir --all
MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['classify_x2_to_y3']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['inputs'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: x2:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['scores'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: y3:0
  Method name is: tensorflow/serving/classify

...

signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['x'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: x:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['y'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1)
        name: y:0
  Method name is: tensorflow/serving/predict
</pre></div>
<div class="section" id="run-command">
<h4><code class="docutils literal notranslate"><span class="pre">run</span></code> command<a class="headerlink" href="#run-command" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Invoke the <code class="docutils literal notranslate"><span class="pre">run</span></code> command to run a graph computation, passing inputs and then displaying (and optionally saving) the outputs. Here’s the syntax:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def
                           SIGNATURE_DEF_KEY [--inputs INPUTS]
                           [--input_exprs INPUT_EXPRS]
                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]
                           [--overwrite] [--tf_debug]
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">run</span></code> command provides the following three ways to pass inputs to the model:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--inputs</span></code> option enables you to pass numpy ndarray in files.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--input_exprs</span></code> option enables you to pass Python expressions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--input_examples</span></code> option enables you to pass <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code>.</p></li>
</ul>
<div class="section" id="--inputs">
<h5><code class="docutils literal notranslate"><span class="pre">--inputs</span></code><a class="headerlink" href="#--inputs" title="Enlazar permanentemente con este título">¶</a></h5>
<p>To pass input data in files, specify the <code class="docutils literal notranslate"><span class="pre">--inputs</span></code> option, which takes the following general format:</p>
<div class="highlight-bsh notranslate"><div class="highlight"><pre><span></span>--inputs &lt;INPUTS&gt;
</pre></div>
</div>
<p>where <em>INPUTS</em> is either of the following formats:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;input_key&gt;=&lt;filename&gt;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;input_key&gt;=&lt;filename&gt;[&lt;variable_name&gt;]</span></code></p></li>
</ul>
<p>You may pass multiple <em>INPUTS</em>. If you do pass multiple inputs, use a semicolon to separate each of the <em>INPUTS</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">saved_model_cli</span></code> uses <code class="docutils literal notranslate"><span class="pre">numpy.load</span></code> to load the <em>filename</em>. The <em>filename</em> may be in any of the following formats:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.npy</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.npz</span></code></p></li>
<li><p>pickle format</p></li>
</ul>
<p>A <code class="docutils literal notranslate"><span class="pre">.npy</span></code> file always contains a numpy ndarray. Therefore, when loading from a <code class="docutils literal notranslate"><span class="pre">.npy</span></code> file, the content will be directly assigned to the specified input tensor. If you specify a <em>variable_name</em> with that <code class="docutils literal notranslate"><span class="pre">.npy</span></code> file, the <em>variable_name</em> will be ignored and a warning will be issued.</p>
<p>When loading from a <code class="docutils literal notranslate"><span class="pre">.npz</span></code> (zip) file, you may optionally specify a <em>variable_name</em> to identify the variable within the zip file to load for the input tensor key. If you don’t specify a <em>variable_name</em>, the SavedModel CLI will check that only one file is included in the zip file and load it for the specified input tensor key.</p>
<p>When loading from a pickle file, if no <code class="docutils literal notranslate"><span class="pre">variable_name</span></code> is specified in the square brackets, whatever that is inside the pickle file will be passed to the specified input tensor key. Otherwise, the SavedModel CLI will assume a dictionary is stored in the pickle file and the value corresponding to the <em>variable_name</em> will be used.</p>
</div>
<div class="section" id="--input_exprs">
<h5><code class="docutils literal notranslate"><span class="pre">--input_exprs</span></code><a class="headerlink" href="#--input_exprs" title="Enlazar permanentemente con este título">¶</a></h5>
<p>To pass inputs through Python expressions, specify the <code class="docutils literal notranslate"><span class="pre">--input_exprs</span></code> option. This can be useful for when you don’t have data files lying around, but still want to sanity check the model with some simple inputs that match the dtype and shape of the model’s <code class="docutils literal notranslate"><span class="pre">SignatureDef</span></code>s. For example:</p>
<div class="highlight-bsh notranslate"><div class="highlight"><pre><span></span>`&lt;input_key&gt;=[[1],[2],[3]]`
</pre></div>
</div>
<p>In addition to Python expressions, you may also pass numpy functions. For example:</p>
<div class="highlight-bsh notranslate"><div class="highlight"><pre><span></span>`&lt;input_key&gt;=np.ones((32,32,3))`
</pre></div>
</div>
<p>(Note that the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> module is already available to you as <code class="docutils literal notranslate"><span class="pre">np</span></code>.)</p>
</div>
<div class="section" id="--input_examples">
<h5><code class="docutils literal notranslate"><span class="pre">--input_examples</span></code><a class="headerlink" href="#--input_examples" title="Enlazar permanentemente con este título">¶</a></h5>
<p>To pass <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code> as inputs, specify the <code class="docutils literal notranslate"><span class="pre">--input_examples</span></code> option. For each input key, it takes a list of dictionary, where each dictionary is an instance of <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code>. The dictionary keys are the features and the values are the value lists for each feature. For example:</p>
<div class="highlight-bsh notranslate"><div class="highlight"><pre><span></span>`&lt;input_key&gt;=[{&quot;age&quot;:[22,24],&quot;education&quot;:[&quot;BS&quot;,&quot;MS&quot;]}]`
</pre></div>
</div>
</div>
<div class="section" id="Save-output">
<h5>Save output<a class="headerlink" href="#Save-output" title="Enlazar permanentemente con este título">¶</a></h5>
<p>By default, the SavedModel CLI writes output to stdout. If a directory is passed to <code class="docutils literal notranslate"><span class="pre">--outdir</span></code> option, the outputs will be saved as <code class="docutils literal notranslate"><span class="pre">.npy</span></code> files named after output tensor keys under the given directory.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">--overwrite</span></code> to overwrite existing output files.</p>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>