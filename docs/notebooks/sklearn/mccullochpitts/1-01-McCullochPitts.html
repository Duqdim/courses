

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Reconocimiento de patrones binarios usando neuronas de McCulloch-Pitts &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "math|output_area"}}</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" />
    <link rel="next" title="Perceptrones binarios" href="../bipolar-perceptron/1-01-perceptron-binario.html" />
    <link rel="prev" title="Afinación de parámetros de modelos en sklearn" href="../sgd/1-03-afinacion-parametros.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-01">Sesión 01</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-02">Sesión 02</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-03">Sesión 03</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-04">Sesión 04</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-05">Sesión 05</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-06">Sesión 06</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-07">Sesión 07</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-08">Sesión 08</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-09">Sesión 09</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-10">Sesión 10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-11">Sesión 11</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-12">Sesión 12</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-13">Sesión 13</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-14">Sesión 14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-15">Sesión 15</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-16">Sesión 16</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a> &raquo;</li>
        
      <li>Reconocimiento de patrones binarios usando neuronas de McCulloch-Pitts</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/sklearn/mccullochpitts/1-01-McCullochPitts.ipynb.txt" rel="nofollow"> Ver código fuente de la página</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Reconocimiento-de-patrones-binarios-usando-neuronas-de-McCulloch-Pitts">
<h1>Reconocimiento de patrones binarios usando neuronas de McCulloch-Pitts<a class="headerlink" href="#Reconocimiento-de-patrones-binarios-usando-neuronas-de-McCulloch-Pitts" title="Enlazar permanentemente con este título">¶</a></h1>
<ul class="simple">
<li><p>30 min | Última modificación: Mayo 28, 2021</p></li>
</ul>
<div class="section" id="Definición-del-problema">
<h2>Definición del problema<a class="headerlink" href="#Definición-del-problema" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El problema real abordado por McCulloch y Pitts consistía en desarrollar un sistema de visión que permite identificar patrones binarios simples.</p>
<p>En términos de los datos, se tiene un conjunto de cuatro patrones binarios de entrada que deben ser reconocidos, donde cada patrón está conformado por tres dígitos binarios <span class="math notranslate nohighlight">\(\{0, 1\}\)</span>. Los patrones a ser reconocidos y su simil con el cerebro son presentados en la figura de abajo. En este caso, el sistema de visión debe determinar el valor de los tres bits (entrada al modelo) y el cerebro debe determinar si el patrón arbitrario observado corresponde a uno de los cuatro patrones indicados
(decisión).</p>
<p>En términos matemáticos, este problema puede ser definido como un problema de clasificación de patrones donde las entradas son todas las cadenas de tres dígitos binarios posibles, y la salida es 1 si la cadena es reconocida y 0 en caso contrario.</p>
<p><img alt="assets/McCullochPitts-01.png" src="../../../_images/McCullochPitts-01.png" /></p>
<p>En otras palabras, se desea tener un modelo matemático <span class="math notranslate nohighlight">\(f(\)</span> <code class="docutils literal notranslate"><span class="pre">Entrada</span></code> <span class="math notranslate nohighlight">\()\)</span> = <code class="docutils literal notranslate"><span class="pre">Salida</span></code> cuyas entradas y salidas están determinadas por la siguiente tabla, donde cero es blanco y uno es gris. Los patrones con salida 1 son los que deben ser reconocidos.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> Entrada   Salida
------------------
   000       0
   001       1
   010       0
   011       0
   100       1
   101       0
   110       1
   111       1
</pre></div>
</div>
</div>
<div class="section" id="Solución">
<h2>Solución<a class="headerlink" href="#Solución" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Modelo-matemático-de-la-neurona">
<h3>Modelo matemático de la neurona<a class="headerlink" href="#Modelo-matemático-de-la-neurona" title="Enlazar permanentemente con este título">¶</a></h3>
<p>El modelo de neurona de <a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_neuron">McCulloch-Pitts</a> fue propuesto originalmente como un postulado sobre la forma en que el cerebro puede reconocer patrones complejos (parte derecha de la figura anterior). Este modelo plantea que, en general, una célula (neurona) puede representarse matemáticamente como una función no lineal que es descrita a continuación.</p>
<p>El modelo de la neurona se basa en una unidad genérica de cómputo que aparece en la figura de abajo. La neurona (unidad de cómputo) recibe varias entradas binarias excitatorias notadas como <span class="math notranslate nohighlight">\(x_i\)</span>; la neurona agrega estas entradas mediante la función <span class="math notranslate nohighlight">\(g()\)</span>, definida usualmente como (parte izquierda de la figura de abajo):</p>
<div class="math notranslate nohighlight">
\[g(x_1, ...,x_n) = v = \sum_{i=1}^n x_i\]</div>
<p>para obtener una entrada neta <span class="math notranslate nohighlight">\(v\)</span>. Posteriormente la entrada neta <span class="math notranslate nohighlight">\(v\)</span> es transformada con una función no lineal <span class="math notranslate nohighlight">\(f()\)</span> definida como:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f(v) =
\begin{cases}
      1, &amp; \text{Si $v \ge \theta$}\\
      0, &amp; \text{Si $v \lt \theta$}\\
\end{cases}\end{split}\]</div>
<p>El valor <span class="math notranslate nohighlight">\(\theta\)</span> es un umbral. Así, la salida de la neurona es un dígito binario <span class="math notranslate nohighlight">\(\{0, 1\}\)</span> (parte central de la figura de abajo).</p>
<p><img alt="assets/McCullochPitts-02.png" src="../../../_images/McCullochPitts-02.png" /></p>
<p>Adicionalmente, la neurona artificial contiene conexiones inhibitorias notadas como <span class="math notranslate nohighlight">\(y_m\)</span>, tal que la salida siempre es cero si alguna de las entradas inhibitorias vale 1, independientemente del valor que puedan tomar las conexiones excitatorias. La representación gráfica de la neurona de McCulloch-Pitts aparece en la parte derecha de la figura anterior.</p>
<p>Las entradas <span class="math notranslate nohighlight">\(x_i\)</span> son señales exitadores, y las señales <span class="math notranslate nohighlight">\(y_j\)</span> son inhibidoras. La salida es cero (0) si alguna de las señales inhibidoras es uno (1). La salida es uno (1) si la suma de señales de entrada es mayor o igual que el umbral (<span class="math notranslate nohighlight">\(\theta\)</span>), y todas las señales inhibidoras son cero (0).</p>
<p>Una neurona de McCulloch-Pitts puede interpretarse como compuerta lógica de umbral (circuito lógico):</p>
<p><img alt="assets/McCullochPitts-06.png" src="../../../_images/McCullochPitts-06.png" /></p>
<p>Por ejemplo:</p>
<ul class="simple">
<li><p>Para <span class="math notranslate nohighlight">\(x_1\)</span> AND <span class="math notranslate nohighlight">\(x_2\)</span>:</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> x1   x2     x1 AND x2    v   Umbral    Salida
             (deseada)                v &gt;= umbral
---------------------------------------------------
 0    0         0         0     2          0
 0    1         0         1     2          0
 1    0         0         1     2          0
 1    1         1         2     2          1
</pre></div>
</div>
<ul class="simple">
<li><p>Para <span class="math notranslate nohighlight">\(x_1\)</span> NOR <span class="math notranslate nohighlight">\(x_2\)</span>:</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> x1   x2     x1 NOR x2    v   Umbral    Salida
             (deseada)                v &gt;= umbral
---------------------------------------------------
 0    0         1         0     0          1
 0    1         0     x1 es inhibitoria    0
 1    0         0     x2 es inhibitoria    0
 1    1         0  x1, x2 son inhibitorias 0
</pre></div>
</div>
<p><strong>Ejercicio.—</strong> Calcule la salida para la siguiente red de neuronas de McCulloch-Pitts.</p>
<p><img alt="assets/McCullochPitts-04.png" src="../../../_images/McCullochPitts-04.png" /></p>
<p>Rta/</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> Entrada  Salida
-----------------
  0 0 0     0
  0 0 1     0
  0 1 0     0
  0 1 1     1
  1 0 0     0
  1 0 1     0
  1 1 0     1
  1 1 1     1
</pre></div>
</div>
</div>
<div class="section" id="Representación-del-problema-de-clasificación-como-una-función-lógica">
<h3>Representación del problema de clasificación como una función lógica<a class="headerlink" href="#Representación-del-problema-de-clasificación-como-una-función-lógica" title="Enlazar permanentemente con este título">¶</a></h3>
<p>El problema de clasificación planteado inicialmente, puede ser resuelto mediante la construcción de una función lógica <span class="math notranslate nohighlight">\(y=f(x_1, x_2, ..., x_n)\)</span> definida como <span class="math notranslate nohighlight">\(f:\{0,1\}^n \to \{0,1\}\)</span> con: <span class="math notranslate nohighlight">\(y \in \{0,1\}\)</span>, y <span class="math notranslate nohighlight">\(x_i \in \{0,1\}\)</span>. En otras palabras, una función lógica es una función <span class="math notranslate nohighlight">\(f\)</span> que recibe como entrada una cadena de bits de tamaño <span class="math notranslate nohighlight">\(n\)</span> o <span class="math notranslate nohighlight">\(\{0,1\}^n\)</span> y devuelve un dígito binario <span class="math notranslate nohighlight">\(\{0,1\}\)</span>. En términos del problema planteado, las entradas a la
función lógica son las cadenas de bits observadas y la salida en un número binario que indica que el patrón se reconoce o no. Para el problema abordado, la función lógica requerida es definida por la siguiente tabla:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> x1 x2 x3   f
---------------
  0  0  0   0
  0  0  1   1
  0  1  0   0
  0  1  1   0
  1  0  0   1
  1  0  1   0
  1  1  0   1
  1  1  1   1
</pre></div>
</div>
</div>
<div class="section" id="Representación-de-funciones-lógicas-mediante-redes-de-neuronas-de-McCulloch-Pitts">
<h3>Representación de funciones lógicas mediante redes de neuronas de McCulloch-Pitts<a class="headerlink" href="#Representación-de-funciones-lógicas-mediante-redes-de-neuronas-de-McCulloch-Pitts" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Una red de neuronas de McCulloch-Pitts de dos capas puede representar cualquier función lógica <span class="math notranslate nohighlight">\(F:\{0,1\}^n \to \{0,1\}\)</span>. A continuación se presenta el proceso de construcción para la función lógica que se presenta en la siguiente figura:</p>
<p><img alt="assets/McCullochPitts-03.png" src="../../../_images/McCullochPitts-03.png" /></p>
<ul class="simple">
<li><p>Se crea una neurona en la primera capa por cada salida igual a 1; para el ejemplo planteado se requieren dos neuronas.</p></li>
<li><p>La segunda capa contiene una neurona que representa la función OR; esto es, si todas las entradas a la neurona son cero, la salida es cero; si una o más entradas son uno, la salida de la neurona es uno. Esta neurona recibe como entrada todas las salida de las neuronas de la primera capa; todas las entradas son excitatorias y el umbral es 1.</p></li>
<li><p>Cada neurona de entrada se especializa en un patrón binario de entrada así: si una entrada es cero, la correspondiente conexión se hace inhibitoria y excitatoria en caso contrario; por ejemplo, para el patrón de entrada 001 (primera neurona de la primera capa) las conexiones para <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(x2\)</span> son inhibitorias y la conexión para <span class="math notranslate nohighlight">\(x_3\)</span> es excitatoria; y para el patrón 010, las conexiones correspondientes a <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(x_3\)</span> son inhibitorias y para <span class="math notranslate nohighlight">\(x_2\)</span>
excitatoria. El valor del umbral de la neurona es la cantidad de unos de la entrada. Así para los patrones 001 y 010 el umbral es 1.</p></li>
</ul>
</div>
<div class="section" id="Representación-matricial-de-la-operación-de-una-red-de-neuronas">
<h3>Representación matricial de la operación de una red de neuronas<a class="headerlink" href="#Representación-matricial-de-la-operación-de-una-red-de-neuronas" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para la implementación, las conexiones entre las neuronas son representadas mediante matrices. Si las conexiones inhibitorias son representas por un número negativo grande <span class="math notranslate nohighlight">\(N\)</span>, las conexiones a la primera capa de procesamiento puede representarse como:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{w} =
\begin{bmatrix}
 N &amp; N &amp; 1 \\
 N &amp; 1 &amp; N
\end{bmatrix}\end{split}\]</div>
<p>donde las filas representan las neuronas y las columnas los dígitos binarios de la entrada.</p>
<p>De esta forma, la entrada neta para el patron 001 es:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
 N &amp; N &amp; 1 \\
 N &amp; 1 &amp; N
\end{bmatrix}
\begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 \\ N \end{bmatrix}\end{split}\]</div>
<p>En la práctica resulta más conveniente usar un vector para representar los umbrales de las neuronas (que en este caso sería un vector de unos), tal que:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} 1 \\ N \end{bmatrix} -
\begin{bmatrix} 1 \\ 1 \end{bmatrix} =
\begin{bmatrix} 0 \\ N-1 \end{bmatrix}\end{split}\]</div>
<p>Seguidamente, se aplica la función de transformación no lineal <span class="math notranslate nohighlight">\(f()\)</span>. El resultado obtenido corresponde a la salida de las dos neuronas de la primera capa de procesamiento.</p>
<div class="math notranslate nohighlight">
\[\begin{split}f \left(\begin{bmatrix} 0 \\ N-1 \end{bmatrix} \right) =
\begin{bmatrix} f(0) \\ f(N-1) \end{bmatrix} =
\begin{bmatrix} 1 \\ 0 \end{bmatrix}\end{split}\]</div>
<p>que fue definida anteriormente como:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f(v) =
\begin{cases}
      1, &amp; \text{Si $v \ge \theta$}\\
      0, &amp; \text{Si $v \lt \theta$}\\
\end{cases}\end{split}\]</div>
<p>Recuerde que <span class="math notranslate nohighlight">\(N\)</span> es un número negativo muy grande, tal que <span class="math notranslate nohighlight">\(f()\)</span> siempre se evalua a cero.</p>
<p>Finalmente, la función OR que representa neurona de salida puede ser computada con la función vectorial <span class="math notranslate nohighlight">\(\max()\)</span>, la cual devuelve el valor máximo de su argumento.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\max \left(\begin{bmatrix} 1 \\ 0 \end{bmatrix} \right) = \max(1, 0) = 1\end{split}\]</div>
<p>Este es el proceso de cálculo que se implementa computacionalmente.</p>
</div>
<div class="section" id="Solución-al-problema-propuesto">
<h3>Solución al problema propuesto<a class="headerlink" href="#Solución-al-problema-propuesto" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para el problema propuesto, cada patrón puede ser codificado como un vector de tres posiciones. Cuando el cuadro es negro, el valor de la posición correspondiente del vector es +1 y cuando es blanco es 0. Cada patrón es asociado a una variable de salida que toma el valor de +1 cuando el patrón debe ser reconocido y 0 cuando debe ser ignorado. De esta forma, el problema puede plantearse como:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    Entrada    Salida
 (x1, x2, x3)                 +----+----+----+
-----------------------       | x1 | x2 | x3 |
      000        0            +----+----+----+
      001        1
      010        0
      011        0
      100        1
      101        0
      110        1
      111        1
</pre></div>
</div>
<p>De esta forma, el patrón 100 se representaría matricialmente como:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{x} =
\begin{bmatrix}
 1 \\
 0 \\
 0
\end{bmatrix}\end{split}\]</div>
</div>
</div>
<div class="section" id="Implementación-en-Python">
<h2>Implementación en Python<a class="headerlink" href="#Implementación-en-Python" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">class</span> <span class="nc">Layer</span><span class="p">:</span>
    <span class="c1">#</span>
    <span class="c1"># Se implementa una clase genérica de capa</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">check_activation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;linear&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)),</span>
                <span class="s2">&quot;relu&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
                <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="p">}[</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">check_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
                <span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
                <span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_activation</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OrLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">check_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">McCullochPittsNetwork</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">input_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">Layer</span><span class="p">(</span>
            <span class="n">units</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;step&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">w</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="p">(</span><span class="n">input_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">w</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">OrLayer</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">coef2string</span><span class="p">(</span><span class="n">coef</span><span class="p">,</span> <span class="n">isvar</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">coef</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">coef</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">isvar</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s2">&quot; + &quot;</span>
                <span class="k">return</span> <span class="s2">&quot; + </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">coef</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">coef</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">isvar</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s2">&quot; - &quot;</span>
                <span class="k">return</span> <span class="s2">&quot; - </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">-</span><span class="n">coef</span><span class="p">)</span>
            <span class="k">return</span> <span class="s2">&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">var2string</span><span class="p">(</span><span class="n">coef</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">coef</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">coef2string</span><span class="p">(</span><span class="n">coef</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;x</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">return</span> <span class="s2">&quot;&quot;</span>


        <span class="n">text_hidden</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">neuron</span><span class="p">,</span> <span class="n">bias</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer</span><span class="o">.</span><span class="n">kernel</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">):</span>
            <span class="n">eq</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">var2string</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neuron</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">bias</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">eq</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">eq</span><span class="p">)</span> <span class="o">+</span> <span class="n">coef2string</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eq</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">eq</span><span class="p">)</span>

            <span class="n">eq</span> <span class="o">=</span> <span class="n">eq</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">eq</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;+&#39;</span><span class="p">:</span>
                <span class="n">eq</span> <span class="o">=</span> <span class="n">eq</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="n">text_hidden</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;step(&quot;</span> <span class="o">+</span> <span class="n">eq</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span><span class="p">)</span>

        <span class="n">text_output</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">coef2string</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="n">t</span>
            <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">text_hidden</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">bias</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">text_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coef2string</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="kc">False</span><span class="p">))</span>

        <span class="n">text_output</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;    &quot;</span> <span class="o">+</span> <span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">text_output</span><span class="p">]</span>
        <span class="n">text_output</span> <span class="o">=</span> <span class="s2">&quot;step(</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_output</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>

        <span class="k">return</span> <span class="n">text_output</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">nn</span><span class="o">.</span><span class="n">hidden_layer</span><span class="o">.</span><span class="n">kernel</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[-4,  1,  1,  1],
       [-4, -4,  1,  1],
       [ 1, -4, -4,  1]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Ejemplo propuesto</span>
<span class="c1">#</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">nn</span> <span class="o">=</span> <span class="n">McCullochPittsNetwork</span><span class="p">()</span>
<span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">nn</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0, 1, 0, 0, 1, 0, 1, 1])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># La red neuronal es equivalente a la siguiente función</span>
<span class="c1">#</span>
<span class="n">nn</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
step(
    + step(- 4x0 - 4x1 + x2 - 1)
    + step(x0 - 4x1 - 4x2 - 1)
    + step(x0 + x1 - 4x2 - 2)
    + step(x0 + x1 + x2 - 3)
    - 1
)
</pre></div></div>
</div>
</div>
<div class="section" id="Notas">
<h2>Notas<a class="headerlink" href="#Notas" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El método de construcción del modelo no resulta adecuado para:</p>
<ul class="simple">
<li><p>Patrones de muchos bits (muchas entradas).</p></li>
<li><p>Más de una salida. En este caso se construye una red para salida.</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Construido con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>