

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2019 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2019 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow/guide/data_performance.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2019-The-TensorFlow-Authors.">
<h1>Copyright 2019 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2019-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="Better-performance-with-the-tf.data-API">
<h2>Better performance with the tf.data API<a class="headerlink" href="#Better-performance-with-the-tf.data-API" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>738242b6c8de4f65b734bcea7e4443f0|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>31857d6eb28343d391238a16362b8fcd|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>67c33b128125447ea68222dcae721743|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>f3f396bbd57b4a719146b7f11886e10e|Download notebook</p>
</td></table><div class="section" id="Overview">
<h3>Overview<a class="headerlink" href="#Overview" title="Enlazar permanentemente con este título">¶</a></h3>
<p>GPUs and TPUs can radically reduce the time required to execute a single training step. Achieving peak performance requires an efficient input pipeline that delivers data for the next step before the current step has finished. The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API helps to build flexible and efficient input pipelines. This document demonstrates how to use the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API to build highly performant TensorFlow input pipelines.</p>
<p>Before you continue, check the <a class="reference internal" href="data.html"><span class="doc">Build TensorFlow input pipelines</span></a> guide to learn how to use the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API.</p>
</div>
<div class="section" id="Resources">
<h3>Resources<a class="headerlink" href="#Resources" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li><p><a class="reference internal" href="data.html"><span class="doc">Build TensorFlow input pipelines</span></a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> API</p></li>
<li><p><cite>Analyze ``tf.data`</cite> performance with the TF Profiler &lt;./data_performance_analysis.md&gt;`__</p></li>
</ul>
</div>
<div class="section" id="Setup">
<h3>Setup<a class="headerlink" href="#Setup" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import tensorflow as tf

import time
</pre></div>
</div>
</div>
<p>Throughout this guide, you will iterate across a dataset and measure the performance. Making reproducible performance benchmarks can be difficult. Different factors affecting reproducibility include:</p>
<ul class="simple">
<li><p>The current CPU load</p></li>
<li><p>The network traffic</p></li>
<li><p>Complex mechanisms, such as cache</p></li>
</ul>
<p>To get a reproducible benchmark, you will build an artificial example.</p>
<div class="section" id="The-dataset">
<h4>The dataset<a class="headerlink" href="#The-dataset" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Start with defining a class inheriting from <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> called <code class="docutils literal notranslate"><span class="pre">ArtificialDataset</span></code>. This dataset:</p>
<ul class="simple">
<li><p>Generates <code class="docutils literal notranslate"><span class="pre">num_samples</span></code> samples (default is 3)</p></li>
<li><p>Sleeps for some time before the first item to simulate opening a file</p></li>
<li><p>Sleeps for some time before producing each item to simulate reading data from a file</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class ArtificialDataset(tf.data.Dataset):
    def _generator(num_samples):
        # Opening the file
        time.sleep(0.03)

        for sample_idx in range(num_samples):
            # Reading data (line, record) from the file
            time.sleep(0.015)

            yield (sample_idx,)

    def __new__(cls, num_samples=3):
        return tf.data.Dataset.from_generator(
            cls._generator,
            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),
            args=(num_samples,)
        )
</pre></div>
</div>
</div>
<p>This dataset is similar to the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.range</span></code> one, adding a fixed delay at the beginning of and in-between each sample.</p>
</div>
<div class="section" id="The-training-loop">
<h4>The training loop<a class="headerlink" href="#The-training-loop" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Next, write a dummy training loop that measures how long it takes to iterate over a dataset. Training time is simulated.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def benchmark(dataset, num_epochs=2):
    start_time = time.perf_counter()
    for epoch_num in range(num_epochs):
        for sample in dataset:
            # Performing a training step
            time.sleep(0.01)
    print(&quot;Execution time:&quot;, time.perf_counter() - start_time)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Optimize-performance">
<h3>Optimize performance<a class="headerlink" href="#Optimize-performance" title="Enlazar permanentemente con este título">¶</a></h3>
<p>To exhibit how performance can be optimized, you will improve the performance of the <code class="docutils literal notranslate"><span class="pre">ArtificialDataset</span></code>.</p>
<div class="section" id="The-naive-approach">
<h4>The naive approach<a class="headerlink" href="#The-naive-approach" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Start with a naive pipeline using no tricks, iterating over the dataset as-is.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>benchmark(ArtificialDataset())
</pre></div>
</div>
</div>
<p>Under the hood, this is how your execution time was spent:</p>
<p><img alt="Data execution time plot - a naive method" src="https://www.tensorflow.org/guide/images/data_performance/naive.svg" /></p>
<p>The plot shows that performing a training step involves:</p>
<ul class="simple">
<li><p>Opening a file if it hasn’t been opened yet</p></li>
<li><p>Fetching a data entry from the file</p></li>
<li><p>Using the data for training</p></li>
</ul>
<p>However, in a naive synchronous implementation like here, while your pipeline is fetching the data, your model is sitting idle. Conversely, while your model is training, the input pipeline is sitting idle. The training step time is thus the sum of opening, reading and training times.</p>
<p>The next sections build on this input pipeline, illustrating best practices for designing performant TensorFlow input pipelines.</p>
</div>
<div class="section" id="Prefetching">
<h4>Prefetching<a class="headerlink" href="#Prefetching" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Prefetching overlaps the preprocessing and model execution of a training step. While the model is executing training step <code class="docutils literal notranslate"><span class="pre">s</span></code>, the input pipeline is reading the data for step <code class="docutils literal notranslate"><span class="pre">s+1</span></code>. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API provides the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.prefetch</span></code> transformation. It can be used to decouple the time when data is produced from the time when data is consumed. In particular, the transformation uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested. The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. You could either
manually tune this value, or set it to <code class="docutils literal notranslate"><span class="pre">tf.data.AUTOTUNE</span></code>, which will prompt the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> runtime to tune the value dynamically at runtime.</p>
<p>Note that the prefetch transformation provides benefits any time there is an opportunity to overlap the work of a “producer” with the work of a “consumer.”</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>benchmark(
    ArtificialDataset()
    .prefetch(tf.data.AUTOTUNE)
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time plot - prefetching method" src="https://www.tensorflow.org/guide/images/data_performance/prefetched.svg" /></p>
<p>Now, as the data execution time plot shows, while the training step is running for sample 0, the input pipeline is reading the data for the sample 1, and so on.</p>
</div>
<div class="section" id="Parallelizing-data-extraction">
<h4>Parallelizing data extraction<a class="headerlink" href="#Parallelizing-data-extraction" title="Enlazar permanentemente con este título">¶</a></h4>
<p>In a real-world setting, the input data may be stored remotely (for example, on Google Cloud Storage or HDFS). A dataset pipeline that works well when reading data locally might become bottlenecked on I/O when reading data remotely because of the following differences between local and remote storage:</p>
<ul class="simple">
<li><p><strong>Time-to-first-byte</strong>: Reading the first byte of a file from remote storage can take orders of magnitude longer than from local storage.</p></li>
<li><p><strong>Read throughput</strong>: While remote storage typically offers large aggregate bandwidth, reading a single file might only be able to utilize a small fraction of this bandwidth.</p></li>
</ul>
<p>In addition, once the raw bytes are loaded into memory, it may also be necessary to deserialize and/or decrypt the data (e.g. <a class="reference external" href="https://developers.google.com/protocol-buffers/">protobuf</a>), which requires additional computation. This overhead is present irrespective of whether the data is stored locally or remotely, but can be worse in the remote case if data is not prefetched effectively.</p>
<p>To mitigate the impact of the various data extraction overheads, the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.interleave</span></code> transformation can be used to parallelize the data loading step, interleaving the contents of other datasets (such as data file readers). The number of datasets to overlap can be specified by the <code class="docutils literal notranslate"><span class="pre">cycle_length</span></code> argument, while the level of parallelism can be specified by the <code class="docutils literal notranslate"><span class="pre">num_parallel_calls</span></code> argument. Similar to the <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> transformation, the <code class="docutils literal notranslate"><span class="pre">interleave</span></code> transformation supports
<code class="docutils literal notranslate"><span class="pre">tf.data.AUTOTUNE</span></code>, which will delegate the decision about what level of parallelism to use to the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> runtime.</p>
<div class="section" id="Sequential-interleave">
<h5>Sequential interleave<a class="headerlink" href="#Sequential-interleave" title="Enlazar permanentemente con este título">¶</a></h5>
<p>The default arguments of the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.interleave</span></code> transformation make it interleave single samples from two datasets sequentially.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>benchmark(
    tf.data.Dataset.range(2)
    .interleave(lambda _: ArtificialDataset())
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time plot - sequential interleave" src="https://www.tensorflow.org/guide/images/data_performance/sequential_interleave.svg" /></p>
<p>This data execution time plot allows to exhibit the behavior of the <code class="docutils literal notranslate"><span class="pre">interleave</span></code> transformation, fetching samples alternatively from the two datasets available. However, no performance improvement is involved here.</p>
</div>
<div class="section" id="Parallel-interleave">
<h5>Parallel interleave<a class="headerlink" href="#Parallel-interleave" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Now, use the <code class="docutils literal notranslate"><span class="pre">num_parallel_calls</span></code> argument of the <code class="docutils literal notranslate"><span class="pre">interleave</span></code> transformation. This loads multiple datasets in parallel, reducing the time waiting for the files to be opened.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>benchmark(
    tf.data.Dataset.range(2)
    .interleave(
        lambda _: ArtificialDataset(),
        num_parallel_calls=tf.data.AUTOTUNE
    )
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time plot - parallel interleave method" src="https://www.tensorflow.org/guide/images/data_performance/parallel_interleave.svg" /></p>
<p>This time, as the data execution time plot shows, the reading of the two datasets is parallelized, reducing the global data processing time.</p>
</div>
</div>
<div class="section" id="Parallelizing-data-transformation">
<h4>Parallelizing data transformation<a class="headerlink" href="#Parallelizing-data-transformation" title="Enlazar permanentemente con este título">¶</a></h4>
<p>When preparing data, input elements may need to be pre-processed. To this end, the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API offers the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.map</span></code> transformation, which applies a user-defined function to each element of the input dataset. Because input elements are independent of one another, the pre-processing can be parallelized across multiple CPU cores. To make this possible, similarly to the <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> and <code class="docutils literal notranslate"><span class="pre">interleave</span></code> transformations, the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation provides the <code class="docutils literal notranslate"><span class="pre">num_parallel_calls</span></code>
argument to specify the level of parallelism.</p>
<p>Choosing the best value for the <code class="docutils literal notranslate"><span class="pre">num_parallel_calls</span></code> argument depends on your hardware, characteristics of your training data (such as its size and shape), the cost of your map function, and what other processing is happening on the CPU at the same time. A simple heuristic is to use the number of available CPU cores. However, as for the <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> and <code class="docutils literal notranslate"><span class="pre">interleave</span></code> transformation, the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation supports <code class="docutils literal notranslate"><span class="pre">tf.data.AUTOTUNE</span></code> which will delegate the decision about what level of
parallelism to use to the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> runtime.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def mapped_function(s):
    # Do some hard pre-processing
    tf.py_function(lambda: time.sleep(0.03), [], ())
    return s
</pre></div>
</div>
</div>
<div class="section" id="Sequential-mapping">
<h5>Sequential mapping<a class="headerlink" href="#Sequential-mapping" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Start by using the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation without parallelism as a baseline example.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>benchmark(
    ArtificialDataset()
    .map(mapped_function)
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time plot - sequential mapping method" src="https://www.tensorflow.org/guide/images/data_performance/sequential_map.svg" /></p>
<p>As for the <a class="reference external" href="#The-naive-approach">naive approach</a>, here, as the plot shows, the times spent for opening, reading, pre-processing (mapping) and training steps sum together for a single iteration.</p>
</div>
<div class="section" id="Parallel-mapping">
<h5>Parallel mapping<a class="headerlink" href="#Parallel-mapping" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Now, use the same pre-processing function but apply it in parallel on multiple samples.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>benchmark(
    ArtificialDataset()
    .map(
        mapped_function,
        num_parallel_calls=tf.data.AUTOTUNE
    )
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time - parallel mapping" src="https://www.tensorflow.org/guide/images/data_performance/parallel_map.svg" /></p>
<p>As the data plot demonstrates, the pre-processing steps overlap, reducing the overall time for a single iteration.</p>
</div>
</div>
<div class="section" id="Caching">
<h4>Caching<a class="headerlink" href="#Caching" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.cache</span></code> transformation can cache a dataset, either in memory or on local storage. This will save some operations (like file opening and data reading) from being executed during each epoch.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>benchmark(
    ArtificialDataset()
    .map(  # Apply time consuming operations before cache
        mapped_function
    ).cache(
    ),
    5
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time - cached dataset method" src="https://www.tensorflow.org/guide/images/data_performance/cached_dataset.svg" /></p>
<p>Here, the data execution time plot shows that when you cache a dataset, the transformations before the <code class="docutils literal notranslate"><span class="pre">cache</span></code> one (like the file opening and data reading) are executed only during the first epoch. The next epochs will reuse the data cached by the<code class="docutils literal notranslate"><span class="pre">cache</span></code> transformation.</p>
<p>If the user-defined function passed into the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation is expensive, apply the <code class="docutils literal notranslate"><span class="pre">cache</span></code> transformation after the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation as long as the resulting dataset can still fit into memory or local storage. If the user-defined function increases the space required to store the dataset beyond the cache capacity, either apply it after the <code class="docutils literal notranslate"><span class="pre">cache</span></code> transformation or consider pre-processing your data before your training job to reduce resource usage.</p>
</div>
<div class="section" id="Vectorizing-mapping">
<h4>Vectorizing mapping<a class="headerlink" href="#Vectorizing-mapping" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Invoking a user-defined function passed into the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation has overhead related to scheduling and executing the user-defined function. Vectorize the user-defined function (that is, have it operate over a batch of inputs at once) and apply the <code class="docutils literal notranslate"><span class="pre">batch</span></code> transformation <em>before</em> the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation.</p>
<p>To illustrate this good practice, your artificial dataset is not suitable. The scheduling delay is around 10 microseconds (10e-6 seconds), far less than the tens of milliseconds used in the <code class="docutils literal notranslate"><span class="pre">ArtificialDataset</span></code>, and thus its impact is hard to see.</p>
<p>For this example, use the base <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.range</span></code> function and simplify the training loop to its simplest form.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>fast_dataset = tf.data.Dataset.range(10000)

def fast_benchmark(dataset, num_epochs=2):
    start_time = time.perf_counter()
    for _ in tf.data.Dataset.range(num_epochs):
        for _ in dataset:
            pass
    tf.print(&quot;Execution time:&quot;, time.perf_counter() - start_time)

def increment(x):
    return x+1
</pre></div>
</div>
</div>
<div class="section" id="Scalar-mapping">
<h5>Scalar mapping<a class="headerlink" href="#Scalar-mapping" title="Enlazar permanentemente con este título">¶</a></h5>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>fast_benchmark(
    fast_dataset
    # Apply function one item at a time
    .map(increment)
    # Batch
    .batch(256)
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time - scalar map method" src="https://www.tensorflow.org/guide/images/data_performance/scalar_map.svg" /></p>
<p>The plot above illustrates what is going on (with less samples) using the scalar mapping method. It shows that the mapped function is applied for each sample. While this function is very fast, it has some overhead that impact the time performance.</p>
</div>
<div class="section" id="Vectorized-mapping">
<h5>Vectorized mapping<a class="headerlink" href="#Vectorized-mapping" title="Enlazar permanentemente con este título">¶</a></h5>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>fast_benchmark(
    fast_dataset
    .batch(256)
    # Apply function on a batch of items
    # The tf.Tensor.__add__ method already handle batches
    .map(increment)
)
</pre></div>
</div>
</div>
<p><img alt="Data execution time - vectorized map method" src="https://www.tensorflow.org/guide/images/data_performance/vectorized_map.svg" /></p>
<p>This time, the mapped function is called once and applies to a batch of sample. As the data execution time plot shows, while the function could takes more time to execute, the overhead appear only once, improving the overall time performance.</p>
</div>
</div>
<div class="section" id="Reducing-memory-footprint">
<h4>Reducing memory footprint<a class="headerlink" href="#Reducing-memory-footprint" title="Enlazar permanentemente con este título">¶</a></h4>
<p>A number of transformations, including <code class="docutils literal notranslate"><span class="pre">interleave</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, and <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, maintain an internal buffer of elements. If the user-defined function passed into the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation changes the size of the elements, then the ordering of the map transformation and the transformations that buffer elements affects the memory usage. In general, choose the order that results in lower memory footprint, unless different ordering is desirable for performance.</p>
<div class="section" id="Caching-partial-computations">
<h5>Caching partial computations<a class="headerlink" href="#Caching-partial-computations" title="Enlazar permanentemente con este título">¶</a></h5>
<p>It is recommended to cache the dataset after the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation except if this transformation makes the data too big to fit in memory. A trade-off can be achieved if your mapped function can be split in two parts: a time consuming one and a memory consuming part. In this case, you can chain your transformations like below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">time_consuming_mapping</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">memory_consuming_mapping</span><span class="p">)</span>
</pre></div>
</div>
<p>This way, the time consuming part is only executed during the first epoch, and you avoid using too much cache space.</p>
</div>
</div>
</div>
<div class="section" id="Best-practice-summary">
<h3>Best practice summary<a class="headerlink" href="#Best-practice-summary" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Here is a summary of the best practices for designing performant TensorFlow input pipelines:</p>
<ul class="simple">
<li><p><cite>Use the ``prefetch`</cite> transformation &lt;#Pipelining&gt;`__ to overlap the work of a producer and consumer</p></li>
<li><p><a class="reference external" href="#Parallelizing-data-extraction">Parallelize the data reading transformation</a> using the <code class="docutils literal notranslate"><span class="pre">interleave</span></code> transformation</p></li>
<li><p><cite>Parallelize the ``map`</cite> transformation &lt;#Parallelizing-data-transformation&gt;`__ by setting the <code class="docutils literal notranslate"><span class="pre">num_parallel_calls</span></code> argument</p></li>
<li><p><cite>Use the ``cache`</cite> transformation &lt;#Caching&gt;`__ to cache data in memory during the first epoch</p></li>
<li><p><a class="reference external" href="#Map-and-batch">Vectorize user-defined functions</a> passed in to the <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation</p></li>
<li><p><a class="reference external" href="#Reducing-memory-footprint">Reduce memory usage</a> when applying the <code class="docutils literal notranslate"><span class="pre">interleave</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, and <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> transformations</p></li>
</ul>
</div>
<div class="section" id="Reproducing-the-figures">
<h3>Reproducing the figures<a class="headerlink" href="#Reproducing-the-figures" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Note: The rest of this notebook is about how to reproduce the above figures. Feel free to play around with this code, but understanding it is not an essential part of this tutorial.</p>
<p>To go deeper in the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> API understanding, you can play with your own pipelines. Below is the code used to plot the images from this guide. It can be a good starting point, showing some workarounds for common difficulties such as:</p>
<ul class="simple">
<li><p>Execution time reproducibility</p></li>
<li><p>Mapped functions eager execution</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">interleave</span></code> transformation callable</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import itertools
from collections import defaultdict

import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h4>The dataset<a class="headerlink" href="#id9" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Similar to the <code class="docutils literal notranslate"><span class="pre">ArtificialDataset</span></code> you can build a dataset returning the time spent in each step.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class TimeMeasuredDataset(tf.data.Dataset):
    # OUTPUT: (steps, timings, counters)
    OUTPUT_TYPES = (tf.dtypes.string, tf.dtypes.float32, tf.dtypes.int32)
    OUTPUT_SHAPES = ((2, 1), (2, 2), (2, 3))

    _INSTANCES_COUNTER = itertools.count()  # Number of datasets generated
    _EPOCHS_COUNTER = defaultdict(itertools.count)  # Number of epochs done for each dataset

    def _generator(instance_idx, num_samples):
        epoch_idx = next(TimeMeasuredDataset._EPOCHS_COUNTER[instance_idx])

        # Opening the file
        open_enter = time.perf_counter()
        time.sleep(0.03)
        open_elapsed = time.perf_counter() - open_enter

        for sample_idx in range(num_samples):
            # Reading data (line, record) from the file
            read_enter = time.perf_counter()
            time.sleep(0.015)
            read_elapsed = time.perf_counter() - read_enter

            yield (
                [(&quot;Open&quot;,), (&quot;Read&quot;,)],
                [(open_enter, open_elapsed), (read_enter, read_elapsed)],
                [(instance_idx, epoch_idx, -1), (instance_idx, epoch_idx, sample_idx)]
            )
            open_enter, open_elapsed = -1., -1.  # Negative values will be filtered


    def __new__(cls, num_samples=3):
        return tf.data.Dataset.from_generator(
            cls._generator,
            output_types=cls.OUTPUT_TYPES,
            output_shapes=cls.OUTPUT_SHAPES,
            args=(next(cls._INSTANCES_COUNTER), num_samples)
        )
</pre></div>
</div>
</div>
<p>This dataset provides samples of shape <code class="docutils literal notranslate"><span class="pre">[[2,</span> <span class="pre">1],</span> <span class="pre">[2,</span> <span class="pre">2],</span> <span class="pre">[2,</span> <span class="pre">3]]</span></code> and of type <code class="docutils literal notranslate"><span class="pre">[tf.dtypes.string,</span> <span class="pre">tf.dtypes.float32,</span> <span class="pre">tf.dtypes.int32]</span></code>. Each sample is:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(
  [(&quot;Open&quot;), (&quot;Read&quot;)],
  [(t0, d), (t0, d)],
  [(i, e, -1), (i, e, s)]
)
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Open</span></code> and <code class="docutils literal notranslate"><span class="pre">Read</span></code> are steps identifiers</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">t0</span></code> is the timestamp when the corresponding step started</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">d</span></code> is the time spent in the corresponding step</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">i</span></code> is the instance index</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">e</span></code> is the epoch index (number of times the dataset has been iterated)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">s</span></code> is the sample index</p></li>
</ul>
</div>
<div class="section" id="The-iteration-loop">
<h4>The iteration loop<a class="headerlink" href="#The-iteration-loop" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Make the iteration loop a little bit more complicated to aggregate all timings. This will only work with datasets generating samples as detailed above.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def timelined_benchmark(dataset, num_epochs=2):
    # Initialize accumulators
    steps_acc = tf.zeros([0, 1], dtype=tf.dtypes.string)
    times_acc = tf.zeros([0, 2], dtype=tf.dtypes.float32)
    values_acc = tf.zeros([0, 3], dtype=tf.dtypes.int32)

    start_time = time.perf_counter()
    for epoch_num in range(num_epochs):
        epoch_enter = time.perf_counter()
        for (steps, times, values) in dataset:
            # Record dataset preparation informations
            steps_acc = tf.concat((steps_acc, steps), axis=0)
            times_acc = tf.concat((times_acc, times), axis=0)
            values_acc = tf.concat((values_acc, values), axis=0)

            # Simulate training time
            train_enter = time.perf_counter()
            time.sleep(0.01)
            train_elapsed = time.perf_counter() - train_enter

            # Record training informations
            steps_acc = tf.concat((steps_acc, [[&quot;Train&quot;]]), axis=0)
            times_acc = tf.concat((times_acc, [(train_enter, train_elapsed)]), axis=0)
            values_acc = tf.concat((values_acc, [values[-1]]), axis=0)

        epoch_elapsed = time.perf_counter() - epoch_enter
        # Record epoch informations
        steps_acc = tf.concat((steps_acc, [[&quot;Epoch&quot;]]), axis=0)
        times_acc = tf.concat((times_acc, [(epoch_enter, epoch_elapsed)]), axis=0)
        values_acc = tf.concat((values_acc, [[-1, epoch_num, -1]]), axis=0)
        time.sleep(0.001)

    tf.print(&quot;Execution time:&quot;, time.perf_counter() - start_time)
    return {&quot;steps&quot;: steps_acc, &quot;times&quot;: times_acc, &quot;values&quot;: values_acc}
</pre></div>
</div>
</div>
</div>
<div class="section" id="The-plotting-method">
<h4>The plotting method<a class="headerlink" href="#The-plotting-method" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Finally, define a function able to plot a timeline given the values returned by the <code class="docutils literal notranslate"><span class="pre">timelined_benchmark</span></code> function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def draw_timeline(timeline, title, width=0.5, annotate=False, save=False):
    # Remove invalid entries (negative times, or empty steps) from the timelines
    invalid_mask = np.logical_and(timeline[&#39;times&#39;] &gt; 0, timeline[&#39;steps&#39;] != b&#39;&#39;)[:,0]
    steps = timeline[&#39;steps&#39;][invalid_mask].numpy()
    times = timeline[&#39;times&#39;][invalid_mask].numpy()
    values = timeline[&#39;values&#39;][invalid_mask].numpy()

    # Get a set of different steps, ordered by the first time they are encountered
    step_ids, indices = np.stack(np.unique(steps, return_index=True))
    step_ids = step_ids[np.argsort(indices)]

    # Shift the starting time to 0 and compute the maximal time value
    min_time = times[:,0].min()
    times[:,0] = (times[:,0] - min_time)
    end = max(width, (times[:,0]+times[:,1]).max() + 0.01)

    cmap = mpl.cm.get_cmap(&quot;plasma&quot;)
    plt.close()
    fig, axs = plt.subplots(len(step_ids), sharex=True, gridspec_kw={&#39;hspace&#39;: 0})
    fig.suptitle(title)
    fig.set_size_inches(17.0, len(step_ids))
    plt.xlim(-0.01, end)

    for i, step in enumerate(step_ids):
        step_name = step.decode()
        ax = axs[i]
        ax.set_ylabel(step_name)
        ax.set_ylim(0, 1)
        ax.set_yticks([])
        ax.set_xlabel(&quot;time (s)&quot;)
        ax.set_xticklabels([])
        ax.grid(which=&quot;both&quot;, axis=&quot;x&quot;, color=&quot;k&quot;, linestyle=&quot;:&quot;)

        # Get timings and annotation for the given step
        entries_mask = np.squeeze(steps==step)
        serie = np.unique(times[entries_mask], axis=0)
        annotations = values[entries_mask]

        ax.broken_barh(serie, (0, 1), color=cmap(i / len(step_ids)), linewidth=1, alpha=0.66)
        if annotate:
            for j, (start, width) in enumerate(serie):
                annotation = &quot;\n&quot;.join([f&quot;{l}: {v}&quot; for l,v in zip((&quot;i&quot;, &quot;e&quot;, &quot;s&quot;), annotations[j])])
                ax.text(start + 0.001 + (0.001 * (j % 2)), 0.55 - (0.1 * (j % 2)), annotation,
                        horizontalalignment=&#39;left&#39;, verticalalignment=&#39;center&#39;)
    if save:
        plt.savefig(title.lower().translate(str.maketrans(&quot; &quot;, &quot;_&quot;)) + &quot;.svg&quot;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Use-wrappers-for-mapped-function">
<h4>Use wrappers for mapped function<a class="headerlink" href="#Use-wrappers-for-mapped-function" title="Enlazar permanentemente con este título">¶</a></h4>
<p>To run mapped function in an eager context, you have to wrap them inside a <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code> call.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def map_decorator(func):
    def wrapper(steps, times, values):
        # Use a tf.py_function to prevent auto-graph from compiling the method
        return tf.py_function(
            func,
            inp=(steps, times, values),
            Tout=(steps.dtype, times.dtype, values.dtype)
        )
    return wrapper
</pre></div>
</div>
</div>
</div>
<div class="section" id="Pipelines-comparison">
<h4>Pipelines comparison<a class="headerlink" href="#Pipelines-comparison" title="Enlazar permanentemente con este título">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>_batch_map_num_items = 50

def dataset_generator_fun(*args):
    return TimeMeasuredDataset(num_samples=_batch_map_num_items)
</pre></div>
</div>
</div>
<div class="section" id="Naive">
<h5>Naive<a class="headerlink" href="#Naive" title="Enlazar permanentemente con este título">¶</a></h5>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@map_decorator
def naive_map(steps, times, values):
    map_enter = time.perf_counter()
    time.sleep(0.001)  # Time consuming step
    time.sleep(0.0001)  # Memory consuming step
    map_elapsed = time.perf_counter() - map_enter

    return (
        tf.concat((steps, [[&quot;Map&quot;]]), axis=0),
        tf.concat((times, [[map_enter, map_elapsed]]), axis=0),
        tf.concat((values, [values[-1]]), axis=0)
    )

naive_timeline = timelined_benchmark(
    tf.data.Dataset.range(2)
    .flat_map(dataset_generator_fun)
    .map(naive_map)
    .batch(_batch_map_num_items, drop_remainder=True)
    .unbatch(),
    5
)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Optimized">
<h4>Optimized<a class="headerlink" href="#Optimized" title="Enlazar permanentemente con este título">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@map_decorator
def time_consuming_map(steps, times, values):
    map_enter = time.perf_counter()
    time.sleep(0.001 * values.shape[0])  # Time consuming step
    map_elapsed = time.perf_counter() - map_enter

    return (
        tf.concat((steps, tf.tile([[[&quot;1st map&quot;]]], [steps.shape[0], 1, 1])), axis=1),
        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),
        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)
    )


@map_decorator
def memory_consuming_map(steps, times, values):
    map_enter = time.perf_counter()
    time.sleep(0.0001 * values.shape[0])  # Memory consuming step
    map_elapsed = time.perf_counter() - map_enter

    # Use tf.tile to handle batch dimension
    return (
        tf.concat((steps, tf.tile([[[&quot;2nd map&quot;]]], [steps.shape[0], 1, 1])), axis=1),
        tf.concat((times, tf.tile([[[map_enter, map_elapsed]]], [times.shape[0], 1, 1])), axis=1),
        tf.concat((values, tf.tile([[values[:][-1][0]]], [values.shape[0], 1, 1])), axis=1)
    )


optimized_timeline = timelined_benchmark(
    tf.data.Dataset.range(2)
    .interleave(  # Parallelize data reading
        dataset_generator_fun,
        num_parallel_calls=tf.data.AUTOTUNE
    )
    .batch(  # Vectorize your mapped function
        _batch_map_num_items,
        drop_remainder=True)
    .map(  # Parallelize map transformation
        time_consuming_map,
        num_parallel_calls=tf.data.AUTOTUNE
    )
    .cache()  # Cache data
    .map(  # Reduce memory usage
        memory_consuming_map,
        num_parallel_calls=tf.data.AUTOTUNE
    )
    .prefetch(  # Overlap producer and consumer works
        tf.data.AUTOTUNE
    )
    .unbatch(),
    5
)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>draw_timeline(naive_timeline, &quot;Naive&quot;, 15)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>draw_timeline(optimized_timeline, &quot;Optimized&quot;, 15)
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>