

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2020 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2020 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow/guide/function.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2020-The-TensorFlow-Authors.">
<h1>Copyright 2020 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2020-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="Better-performance-with-tf.function">
<h2>Better performance with tf.function<a class="headerlink" href="#Better-performance-with-tf.function" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>43df398f79104b3dbd5dbdf0fb49b90a|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>3247d3acbe784ba3854ce04882a66b7e|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>cce84c4699e345f487a2293295b873ce|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>c650bf2bd1c74ee69518fe8f2b84c86d|Download notebook</p>
</td></table><p>In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability.</p>
<p>You can use <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs out of your Python code. This will help you create performant and portable models, and it is required to use <code class="docutils literal notranslate"><span class="pre">SavedModel</span></code>.</p>
<p>This guide will help you conceptualize how <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> works under the hood so you can use it effectively.</p>
<p>The main takeaways and recommendations are:</p>
<ul class="simple">
<li><p>Debug in eager mode, then decorate with <code class="docutils literal notranslate"><span class="pre">&#64;tf.function</span></code>.</p></li>
<li><p>Don’t rely on Python side effects like object mutation or list appends.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.function</span></code> works best with TensorFlow ops; NumPy and Python calls are converted to constants.</p></li>
</ul>
<div class="section" id="Setup">
<h3>Setup<a class="headerlink" href="#Setup" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import tensorflow as tf
</pre></div>
</div>
</div>
<p>Define a helper function to demonstrate the kinds of errors you might encounter:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import traceback
import contextlib

# Some helper code to demonstrate the kinds of errors you might encounter.
@contextlib.contextmanager
def assert_raises(error_class):
  try:
    yield
  except error_class as e:
    print(&#39;Caught expected exception \n  {}:&#39;.format(error_class))
    traceback.print_exc(limit=2)
  except Exception as e:
    raise e
  else:
    raise Exception(&#39;Expected {} to be raised but no error was raised!&#39;.format(
        error_class))
</pre></div>
</div>
</div>
</div>
<div class="section" id="Basics">
<h3>Basics<a class="headerlink" href="#Basics" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Usage">
<h4>Usage<a class="headerlink" href="#Usage" title="Enlazar permanentemente con este título">¶</a></h4>
<p>A <code class="docutils literal notranslate"><span class="pre">Function</span></code> you define (for example by applying the <code class="docutils literal notranslate"><span class="pre">&#64;tf.function</span></code> decorator) is just like a core TensorFlow operation: You can execute it eagerly; you can compute gradients; and so on.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function  # The decorator converts `add` into a `Function`.
def add(a, b):
  return a + b

add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>v = tf.Variable(1.0)
with tf.GradientTape() as tape:
  result = add(v, 1.0)
tape.gradient(result, v)
</pre></div>
</div>
</div>
<p>You can use <code class="docutils literal notranslate"><span class="pre">Function</span></code>s inside other <code class="docutils literal notranslate"><span class="pre">Function</span></code>s.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def dense_layer(x, w, b):
  return add(tf.matmul(x, w), b)

dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Function</span></code>s can be faster than eager code, especially for graphs with many small ops. But for graphs with a few expensive ops (like convolutions), you may not see much speedup.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import timeit
conv_layer = tf.keras.layers.Conv2D(100, 3)

@tf.function
def conv_fn(image):
  return conv_layer(image)

image = tf.zeros([1, 200, 200, 100])
# warm up
conv_layer(image); conv_fn(image)
print(&quot;Eager conv:&quot;, timeit.timeit(lambda: conv_layer(image), number=10))
print(&quot;Function conv:&quot;, timeit.timeit(lambda: conv_fn(image), number=10))
print(&quot;Note how there&#39;s not much difference in performance for convolutions&quot;)

</pre></div>
</div>
</div>
</div>
<div class="section" id="Tracing">
<h4>Tracing<a class="headerlink" href="#Tracing" title="Enlazar permanentemente con este título">¶</a></h4>
<p>This section exposes how <code class="docutils literal notranslate"><span class="pre">Function</span></code> works under the hood, including implementation details <em>which may change in the future</em>. However, once you understand why and when tracing happens, it’s much easier to use <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> effectively!</p>
<div class="section" id="What-is-“tracing”?">
<h5>What is “tracing”?<a class="headerlink" href="#What-is-“tracing”?" title="Enlazar permanentemente con este título">¶</a></h5>
<p>A <code class="docutils literal notranslate"><span class="pre">Function</span></code> runs your program in a <a class="reference external" href="https://www.tensorflow.org/guide/intro_to_graphs#what_are_graphs">TensorFlow Graph</a>. However, a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> cannot represent all the things that you’d write in an eager TensorFlow program. For instance, Python supports polymorphism, but <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> requires its inputs to have a specified data type and dimension. Or you may perform side tasks like reading command-line arguments, raising an error, or working with a more complex Python object; none of
these things can run in a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">Function</span></code> bridges this gap by separating your code in two stages:</p>
<ol class="arabic simple">
<li><p>In the first stage, referred to as “<strong>tracing</strong>”, <code class="docutils literal notranslate"><span class="pre">Function</span></code> creates a new <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>. Python code runs normally, but all TensorFlow operations (like adding two Tensors) are <em>deferred</em>: they are captured by the <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> and not run.</p></li>
<li><p>In the second stage, a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> which contains everything that was deferred in the first stage is run. This stage is much faster than the tracing stage.</p></li>
</ol>
<p>Depending on its inputs, <code class="docutils literal notranslate"><span class="pre">Function</span></code> will not always run the first stage when it is called. See <a class="reference external" href="#rules_of_tracing">“Rules of tracing”</a> below to get a better sense of how it makes that determination. Skipping the first stage and only executing the second stage is what gives you TensorFlow’s high performance.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">Function</span></code> does decide to trace, the tracing stage is immediately followed by the second stage, so calling the <code class="docutils literal notranslate"><span class="pre">Function</span></code> both creates and runs the <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>. Later you will see how you can run only the tracing stage with <code class="docutils literal notranslate"><span class="pre">`get_concrete_function</span></code> &lt;#obtaining_concrete_functions&gt;`__.</p>
<p>When we pass arguments of different types into a <code class="docutils literal notranslate"><span class="pre">Function</span></code>, both stages are run:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def double(a):
  print(&quot;Tracing with&quot;, a)
  return a + a

print(double(tf.constant(1)))
print()
print(double(tf.constant(1.1)))
print()
print(double(tf.constant(&quot;a&quot;)))
print()

</pre></div>
</div>
</div>
<p>Note that if you repeatedly call a <code class="docutils literal notranslate"><span class="pre">Function</span></code> with the same argument type, TensorFlow will skip the tracing stage and reuse a previously traced graph, as the generated graph would be identical.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># This doesn&#39;t print &#39;Tracing with ...&#39;
print(double(tf.constant(&quot;b&quot;)))
</pre></div>
</div>
</div>
<p>You can use <code class="docutils literal notranslate"><span class="pre">pretty_printed_concrete_signatures()</span></code> to see all of the available traces:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(double.pretty_printed_concrete_signatures())
</pre></div>
</div>
</div>
<p>So far, you’ve seen that <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> creates a cached, dynamic dispatch layer over TensorFlow’s graph tracing logic. To be more specific about the terminology:</p>
<ul class="simple">
<li><p>A <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> is the raw, language-agnostic, portable representation of a TensorFlow computation.</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code> wraps a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>.</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">Function</span></code> manages a cache of <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code>s and picks the right one for your inputs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.function</span></code> wraps a Python function, returning a <code class="docutils literal notranslate"><span class="pre">Function</span></code> object.</p></li>
<li><p><strong>Tracing</strong> creates a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> and wraps it in a <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code>, also known as a <strong>trace.</strong></p></li>
</ul>
</div>
<div class="section" id="Rules-of-tracing">
<h5>Rules of tracing<a class="headerlink" href="#Rules-of-tracing" title="Enlazar permanentemente con este título">¶</a></h5>
<p>A <code class="docutils literal notranslate"><span class="pre">Function</span></code> determines whether to reuse a traced <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code> by computing a <strong>cache key</strong> from an input’s args and kwargs. A <strong>cache key</strong> is a key that identifies a <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code> based on the input args and kwargs of the <code class="docutils literal notranslate"><span class="pre">Function</span></code> call, according to the following rules (which may change):</p>
<ul class="simple">
<li><p>The key generated for a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> is its shape and dtype.</p></li>
<li><p>The key generated for a <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> is a unique variable id.</p></li>
<li><p>The key generated for a Python primitive (like <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code>) is its value.</p></li>
<li><p>The key generated for nested <code class="docutils literal notranslate"><span class="pre">dict</span></code>s, <code class="docutils literal notranslate"><span class="pre">list</span></code>s, <code class="docutils literal notranslate"><span class="pre">tuple</span></code>s, <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code>s, and <code class="docutils literal notranslate"><span class="pre">`attr</span></code> &lt;<a class="reference external" href="https://www.attrs.org/en/stable/">https://www.attrs.org/en/stable/</a>&gt;`__s is the flattened tuple of leaf-keys (see <code class="docutils literal notranslate"><span class="pre">nest.flatten</span></code>). (As a result of this flattening, calling a concrete function with a different nesting structure than the one used during tracing will result in a TypeError).</p></li>
<li><p>For all other Python types the key is unique to the object. This way a function or method is traced independently for each instance it is called with.</p></li>
</ul>
<p>Note: Cache keys are based on the <code class="docutils literal notranslate"><span class="pre">Function</span></code> input parameters so changes to global and <a class="reference external" href="https://docs.python.org/3/reference/executionmodel.html#binding-of-names">free variables</a> alone will not create a new trace. See <a class="reference external" href="#depending_on_python_global_and_free_variables">this section</a> for recommended practices when dealing with Python global and free variables.</p>
</div>
<div class="section" id="Controlling-retracing">
<h5>Controlling retracing<a class="headerlink" href="#Controlling-retracing" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Retracing, which is when your <code class="docutils literal notranslate"><span class="pre">Function</span></code> creates more than one trace, helps ensures that TensorFlow generates correct graphs for each set of inputs. However, tracing is an expensive operation! If your <code class="docutils literal notranslate"><span class="pre">Function</span></code> retraces a new graph for every call, you’ll find that your code executes more slowly than if you didn’t use <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>.</p>
<p>To control the tracing behavior, you can use the following techniques:</p>
<ul class="simple">
<li><p>Specify <code class="docutils literal notranslate"><span class="pre">input_signature</span></code> in <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> to limit tracing.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))
def next_collatz(x):
  print(&quot;Tracing with&quot;, x)
  return tf.where(x % 2 == 0, x // 2, 3 * x + 1)

print(next_collatz(tf.constant([1, 2])))
# We specified a 1-D tensor in the input signature, so this should fail.
with assert_raises(ValueError):
  next_collatz(tf.constant([[1, 2], [3, 4]]))

# We specified an int32 dtype in the input signature, so this should fail.
with assert_raises(ValueError):
  next_collatz(tf.constant([1.0, 2.0]))

</pre></div>
</div>
</div>
<ul>
<li><p>Specify a [None] dimension in <code class="docutils literal notranslate"><span class="pre">tf.TensorSpec</span></code> to allow for flexibility in trace reuse.</p>
<p>Since TensorFlow matches tensors based on their shape, using a <code class="docutils literal notranslate"><span class="pre">None</span></code> dimension as a wildcard will allow <code class="docutils literal notranslate"><span class="pre">Function</span></code>s to reuse traces for variably-sized input. Variably-sized input can occur if you have sequences of different length, or images of different sizes for each batch (See <a class="reference external" href="../tutorials/text/transformer.ipynb">Transformer</a> and <a class="reference external" href="../tutorials/generative/deepdream.ipynb">Deep Dream</a> tutorials for example).</p>
</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))
def g(x):
  print(&#39;Tracing with&#39;, x)
  return x

# No retrace!
print(g(tf.constant([1, 2, 3])))
print(g(tf.constant([1, 2, 3, 4, 5])))

</pre></div>
</div>
</div>
<ul>
<li><p>Cast Python arguments to Tensors to reduce retracing.</p>
<p>Often, Python arguments are used to control hyperparameters and graph constructions - for example, <code class="docutils literal notranslate"><span class="pre">num_layers=10</span></code> or <code class="docutils literal notranslate"><span class="pre">training=True</span></code> or <code class="docutils literal notranslate"><span class="pre">nonlinearity='relu'</span></code>. So if the Python argument changes, it makes sense that you’d have to retrace the graph.</p>
<p>However, it’s possible that a Python argument is not being used to control graph construction. In these cases, a change in the Python value can trigger needless retracing. Take, for example, this training loop, which AutoGraph will dynamically unroll. Despite the multiple traces, the generated graph is actually identical, so retracing is unnecessary.</p>
</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def train_one_step():
  pass

@tf.function
def train(num_steps):
  print(&quot;Tracing with num_steps = &quot;, num_steps)
  tf.print(&quot;Executing with num_steps = &quot;, num_steps)
  for _ in tf.range(num_steps):
    train_one_step()

print(&quot;Retracing occurs for different Python arguments.&quot;)
train(num_steps=10)
train(num_steps=20)

print()
print(&quot;Traces are reused for Tensor arguments.&quot;)
train(num_steps=tf.constant(10))
train(num_steps=tf.constant(20))
</pre></div>
</div>
</div>
<p>If you need to force retracing, create a new <code class="docutils literal notranslate"><span class="pre">Function</span></code>. Separate <code class="docutils literal notranslate"><span class="pre">Function</span></code> objects are guaranteed not to share traces.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def f():
  print(&#39;Tracing!&#39;)
  tf.print(&#39;Executing&#39;)

tf.function(f)()
tf.function(f)()
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Obtaining-concrete-functions">
<h4>Obtaining concrete functions<a class="headerlink" href="#Obtaining-concrete-functions" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Every time a function is traced, a new concrete function is created. You can directly obtain a concrete function, by using <code class="docutils literal notranslate"><span class="pre">get_concrete_function</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Obtaining concrete trace&quot;)
double_strings = double.get_concrete_function(tf.constant(&quot;a&quot;))
print(&quot;Executing traced function&quot;)
print(double_strings(tf.constant(&quot;a&quot;)))
print(double_strings(a=tf.constant(&quot;b&quot;)))

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># You can also call get_concrete_function on an InputSpec
double_strings_from_inputspec = double.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.string))
print(double_strings_from_inputspec(tf.constant(&quot;c&quot;)))
</pre></div>
</div>
</div>
<p>Printing a <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code> displays a summary of its input arguments (with types) and its output type.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(double_strings)
</pre></div>
</div>
</div>
<p>You can also directly retrieve a concrete function’s signature.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(double_strings.structured_input_signature)
print(double_strings.structured_outputs)
</pre></div>
</div>
</div>
<p>Using a concrete trace with incompatible types will throw an error</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>with assert_raises(tf.errors.InvalidArgumentError):
  double_strings(tf.constant(1))
</pre></div>
</div>
</div>
<p>You may notice that Python arguments are given special treatment in a concrete function’s input signature. Prior to TensorFlow 2.3, Python arguments were simply removed from the concrete function’s signature. Starting with TensorFlow 2.3, Python arguments remain in the signature, but are constrained to take the value set during tracing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def pow(a, b):
  return a ** b

square = pow.get_concrete_function(a=tf.TensorSpec(None, tf.float32), b=2)
print(square)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>assert square(tf.constant(10.0)) == 100

with assert_raises(TypeError):
  square(tf.constant(10.0), b=3)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Obtaining-graphs">
<h4>Obtaining graphs<a class="headerlink" href="#Obtaining-graphs" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Each concrete function is a callable wrapper around a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>. Although retrieving the actual <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> object is not something you’ll normally need to do, you can obtain it easily from any concrete function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>graph = double_strings.graph
for node in graph.as_graph_def().node:
  print(f&#39;{node.input} -&gt; {node.name}&#39;)

</pre></div>
</div>
</div>
</div>
<div class="section" id="Debugging">
<h4>Debugging<a class="headerlink" href="#Debugging" title="Enlazar permanentemente con este título">¶</a></h4>
<p>In general, debugging code is easier in eager mode than inside <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>. You should ensure that your code executes error-free in eager mode before decorating with <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>. To assist in the debugging process, you can call <code class="docutils literal notranslate"><span class="pre">tf.config.run_functions_eagerly(True)</span></code> to globally disable and reenable <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>.</p>
<p>When tracking down issues that only appear within <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>, here are some tips: - Plain old Python <code class="docutils literal notranslate"><span class="pre">print</span></code> calls only execute during tracing, helping you track down when your function gets (re)traced. - <code class="docutils literal notranslate"><span class="pre">tf.print</span></code> calls will execute every time, and can help you track down intermediate values during execution. - <code class="docutils literal notranslate"><span class="pre">tf.debugging.enable_check_numerics</span></code> is an easy way to track down where NaNs and Inf are created. - <code class="docutils literal notranslate"><span class="pre">pdb</span></code> can help you understand what’s going on during tracing. (Caveat:
PDB will drop you into AutoGraph-transformed source code.)</p>
</div>
</div>
<div class="section" id="AutoGraph-Transformations">
<h3>AutoGraph Transformations<a class="headerlink" href="#AutoGraph-Transformations" title="Enlazar permanentemente con este título">¶</a></h3>
<p>AutoGraph is a library that is on by default in <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>, and transforms a subset of Python eager code into graph-compatible TensorFlow ops. This includes control flow like <code class="docutils literal notranslate"><span class="pre">if</span></code>, <code class="docutils literal notranslate"><span class="pre">for</span></code>, <code class="docutils literal notranslate"><span class="pre">while</span></code>.</p>
<p>TensorFlow ops like <code class="docutils literal notranslate"><span class="pre">tf.cond</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code> continue to work, but control flow is often easier to write and understand when written in Python.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Simple loop

@tf.function
def f(x):
  while tf.reduce_sum(x) &gt; 1:
    tf.print(x)
    x = tf.tanh(x)
  return x

f(tf.random.uniform([5]))
</pre></div>
</div>
</div>
<p>If you’re curious you can inspect the code autograph generates.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(tf.autograph.to_code(f.python_function))
</pre></div>
</div>
</div>
<div class="section" id="Conditionals">
<h4>Conditionals<a class="headerlink" href="#Conditionals" title="Enlazar permanentemente con este título">¶</a></h4>
<p>AutoGraph will convert some <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">&lt;condition&gt;</span></code> statements into the equivalent <code class="docutils literal notranslate"><span class="pre">tf.cond</span></code> calls. This substitution is made if <code class="docutils literal notranslate"><span class="pre">&lt;condition&gt;</span></code> is a Tensor. Otherwise, the <code class="docutils literal notranslate"><span class="pre">if</span></code> statement is executed as a Python conditional.</p>
<p>A Python conditional executes during tracing, so exactly one branch of the conditional will be added to the graph. Without AutoGraph, this traced graph would be unable to take the alternate branch if there is data-dependent control flow.</p>
<p><code class="docutils literal notranslate"><span class="pre">tf.cond</span></code> traces and adds both branches of the conditional to the graph, dynamically selecting a branch at execution time. Tracing can have unintended side effects; see <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#effects-of-the-tracing-process">AutoGraph tracing effects</a> for more.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def fizzbuzz(n):
  for i in tf.range(1, n + 1):
    print(&#39;Tracing for loop&#39;)
    if i % 15 == 0:
      print(&#39;Tracing fizzbuzz branch&#39;)
      tf.print(&#39;fizzbuzz&#39;)
    elif i % 3 == 0:
      print(&#39;Tracing fizz branch&#39;)
      tf.print(&#39;fizz&#39;)
    elif i % 5 == 0:
      print(&#39;Tracing buzz branch&#39;)
      tf.print(&#39;buzz&#39;)
    else:
      print(&#39;Tracing default branch&#39;)
      tf.print(i)

fizzbuzz(tf.constant(5))
fizzbuzz(tf.constant(20))
</pre></div>
</div>
</div>
<p>See the <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#if-statements">reference documentation</a> for additional restrictions on AutoGraph-converted if statements.</p>
</div>
<div class="section" id="Loops">
<h4>Loops<a class="headerlink" href="#Loops" title="Enlazar permanentemente con este título">¶</a></h4>
<p>AutoGraph will convert some <code class="docutils literal notranslate"><span class="pre">for</span></code> and <code class="docutils literal notranslate"><span class="pre">while</span></code> statements into the equivalent TensorFlow looping ops, like <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code>. If not converted, the <code class="docutils literal notranslate"><span class="pre">for</span></code> or <code class="docutils literal notranslate"><span class="pre">while</span></code> loop is executed as a Python loop.</p>
<p>This substitution is made in the following situations:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">y</span></code>: if <code class="docutils literal notranslate"><span class="pre">y</span></code> is a Tensor, convert to <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code>. In the special case where <code class="docutils literal notranslate"><span class="pre">y</span></code> is a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code>, a combination of <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> ops are generated.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">while</span> <span class="pre">&lt;condition&gt;</span></code>: if <code class="docutils literal notranslate"><span class="pre">&lt;condition&gt;</span></code> is a Tensor, convert to <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code>.</p></li>
</ul>
<p>A Python loop executes during tracing, adding additional ops to the <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> for every iteration of the loop.</p>
<p>A TensorFlow loop traces the body of the loop, and dynamically selects how many iterations to run at execution time. The loop body only appears once in the generated <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>.</p>
<p>See the <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements">reference documentation</a> for additional restrictions on AutoGraph-converted <code class="docutils literal notranslate"><span class="pre">for</span></code> and <code class="docutils literal notranslate"><span class="pre">while</span></code> statements.</p>
<div class="section" id="Looping-over-Python-data">
<h5>Looping over Python data<a class="headerlink" href="#Looping-over-Python-data" title="Enlazar permanentemente con este título">¶</a></h5>
<p>A common pitfall is to loop over Python/Numpy data within a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>. This loop will execute during the tracing process, adding a copy of your model to the <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> for each iteration of the loop.</p>
<p>If you want to wrap the entire training loop in <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>, the safest way to do this is to wrap your data as a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> so that AutoGraph will dynamically unroll the training loop.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def measure_graph_size(f, *args):
  g = f.get_concrete_function(*args).graph
  print(&quot;{}({}) contains {} nodes in its graph&quot;.format(
      f.__name__, &#39;, &#39;.join(map(str, args)), len(g.as_graph_def().node)))

@tf.function
def train(dataset):
  loss = tf.constant(0)
  for x, y in dataset:
    loss += tf.abs(y - x) # Some dummy computation.
  return loss

small_data = [(1, 1)] * 3
big_data = [(1, 1)] * 10
measure_graph_size(train, small_data)
measure_graph_size(train, big_data)

measure_graph_size(train, tf.data.Dataset.from_generator(
    lambda: small_data, (tf.int32, tf.int32)))
measure_graph_size(train, tf.data.Dataset.from_generator(
    lambda: big_data, (tf.int32, tf.int32)))
</pre></div>
</div>
</div>
<p>When wrapping Python/Numpy data in a Dataset, be mindful of <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_generator</span></code> versus <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensors</span></code>. The former will keep the data in Python and fetch it via <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code> which can have performance implications, whereas the latter will bundle a copy of the data as one large <code class="docutils literal notranslate"><span class="pre">tf.constant()</span></code> node in the graph, which can have memory implications.</p>
<p>Reading data from files via TFRecordDataset/CsvDataset/etc. is the most effective way to consume data, as then TensorFlow itself can manage the asynchronous loading and prefetching of data, without having to involve Python. To learn more, see the <a class="reference external" href="../../guide/data">tf.data guide</a>.</p>
</div>
<div class="section" id="Accumulating-values-in-a-loop">
<h5>Accumulating values in a loop<a class="headerlink" href="#Accumulating-values-in-a-loop" title="Enlazar permanentemente con este título">¶</a></h5>
<p>A common pattern is to accumulate intermediate values from a loop. Normally, this is accomplished by appending to a Python list or adding entries to a Python dictionary. However, as these are Python side effects, they will not work as expected in a dynamically unrolled loop. Use <code class="docutils literal notranslate"><span class="pre">tf.TensorArray</span></code> to accumulate results from a dynamically unrolled loop.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>batch_size = 2
seq_len = 3
feature_size = 4

def rnn_step(inp, state):
  return inp + state

@tf.function
def dynamic_rnn(rnn_step, input_data, initial_state):
  # [batch, time, features] -&gt; [time, batch, features]
  input_data = tf.transpose(input_data, [1, 0, 2])
  max_seq_len = input_data.shape[0]

  states = tf.TensorArray(tf.float32, size=max_seq_len)
  state = initial_state
  for i in tf.range(max_seq_len):
    state = rnn_step(input_data[i], state)
    states = states.write(i, state)
  return tf.transpose(states.stack(), [1, 0, 2])

dynamic_rnn(rnn_step,
            tf.random.uniform([batch_size, seq_len, feature_size]),
            tf.zeros([batch_size, feature_size]))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Limitations">
<h3>Limitations<a class="headerlink" href="#Limitations" title="Enlazar permanentemente con este título">¶</a></h3>
<p>TensorFlow <code class="docutils literal notranslate"><span class="pre">Function</span></code> has a few limitations by design that you should be aware of when converting a Python function to a <code class="docutils literal notranslate"><span class="pre">Function</span></code>.</p>
<div class="section" id="Executing-Python-side-effects">
<h4>Executing Python side effects<a class="headerlink" href="#Executing-Python-side-effects" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Side effects, like printing, appending to lists, and mutating globals, can behave unexpectedly inside a <code class="docutils literal notranslate"><span class="pre">Function</span></code>, sometimes executing twice or not all. They only happen the first time you call a <code class="docutils literal notranslate"><span class="pre">Function</span></code> with a set of inputs. Afterwards, the traced <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> is reexecuted, without executing the Python code.</p>
<p>The general rule of thumb is to avoid relying on Python side effects in your logic and only use them to debug your traces. Otherwise, TensorFlow APIs like <code class="docutils literal notranslate"><span class="pre">tf.data</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.print</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.summary</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.Variable.assign</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.TensorArray</span></code> are the best way to ensure your code will be executed by the TensorFlow runtime with each call.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def f(x):
  print(&quot;Traced with&quot;, x)
  tf.print(&quot;Executed with&quot;, x)

f(1)
f(1)
f(2)

</pre></div>
</div>
</div>
<p>If you would like to execute Python code during each invocation of a <code class="docutils literal notranslate"><span class="pre">Function</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code> is an exit hatch. The drawback of <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code> is that it’s not portable or particularly performant, cannot be saved with SavedModel, and does not work well in distributed (multi-GPU, TPU) setups. Also, since <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code> has to be wired into the graph, it casts all inputs/outputs to tensors.</p>
<div class="section" id="Changing-Python-global-and-free-variables">
<h5>Changing Python global and free variables<a class="headerlink" href="#Changing-Python-global-and-free-variables" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Changing Python global and <a class="reference external" href="https://docs.python.org/3/reference/executionmodel.html#binding-of-names">free variables</a> counts as a Python side effect, so it only happens during tracing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>external_list = []

@tf.function
def side_effect(x):
  print(&#39;Python side effect&#39;)
  external_list.append(x)

side_effect(1)
side_effect(1)
side_effect(1)
# The list append only happened once!
assert len(external_list) == 1
</pre></div>
</div>
</div>
<p>You should avoid mutating containers like lists, dicts, other objects that live outside the <code class="docutils literal notranslate"><span class="pre">Function</span></code>. Instead, use arguments and TF objects. For example, the section <a class="reference external" href="#accumulating_values_in_a_loop">“Accumulating values in a loop”</a> has one example of how list-like operations can be implemented.</p>
<p>You can, in some cases, capture and manipulate state if it is a <code class="docutils literal notranslate"><span class="pre">`tf.Variable</span></code> &lt;<a class="reference external" href="https://www.tensorflow.org/guide/variable">https://www.tensorflow.org/guide/variable</a>&gt;`__. This is how the weights of Keras models are updated with repeated calls to the same <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code>.</p>
</div>
<div class="section" id="Using-Python-iterators-and-generators">
<h5>Using Python iterators and generators<a class="headerlink" href="#Using-Python-iterators-and-generators" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Many Python features, such as generators and iterators, rely on the Python runtime to keep track of state. In general, while these constructs work as expected in eager mode, they are examples of Python side effects and therefore only happen during tracing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def buggy_consume_next(iterator):
  tf.print(&quot;Value:&quot;, next(iterator))

iterator = iter([1, 2, 3])
buggy_consume_next(iterator)
# This reuses the first value from the iterator, rather than consuming the next value.
buggy_consume_next(iterator)
buggy_consume_next(iterator)

</pre></div>
</div>
</div>
<p>Just like how TensorFlow has a specialized <code class="docutils literal notranslate"><span class="pre">tf.TensorArray</span></code> for list constructs, it has a specialized <code class="docutils literal notranslate"><span class="pre">tf.data.Iterator</span></code> for iteration constructs. See the section on <a class="reference external" href="#autograph_transformations">AutoGraph Transformations</a> for an overview. Also, the <code class="docutils literal notranslate"><span class="pre">`tf.data</span></code> &lt;<a class="reference external" href="https://www.tensorflow.org/guide/data">https://www.tensorflow.org/guide/data</a>&gt;`__ API can help implement generator patterns:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def good_consume_next(iterator):
  # This is ok, iterator is a tf.data.Iterator
  tf.print(&quot;Value:&quot;, next(iterator))

ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])
iterator = iter(ds)
good_consume_next(iterator)
good_consume_next(iterator)
good_consume_next(iterator)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Deleting-tf.Variables-between-Function-calls">
<h4>Deleting tf.Variables between <code class="docutils literal notranslate"><span class="pre">Function</span></code> calls<a class="headerlink" href="#Deleting-tf.Variables-between-Function-calls" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Another error you may encounter is a garbage-collected variable. <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code>s only retain <a class="reference external" href="https://docs.python.org/3/library/weakref.html">WeakRefs</a> to the variables they close over, so you must retain a reference to any variables.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>external_var = tf.Variable(3)
@tf.function
def f(x):
  return x * external_var

traced_f = f.get_concrete_function(4)
print(&quot;Calling concrete function...&quot;)
print(traced_f(4))

# The original variable object gets garbage collected, since there are no more
# references to it.
external_var = tf.Variable(4)
print()
print(&quot;Calling concrete function after garbage collecting its closed Variable...&quot;)
with assert_raises(tf.errors.FailedPreconditionError):
  traced_f(4)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Known-Issues">
<h3>Known Issues<a class="headerlink" href="#Known-Issues" title="Enlazar permanentemente con este título">¶</a></h3>
<p>If your <code class="docutils literal notranslate"><span class="pre">Function</span></code> is not evaluating correctly, the error may be explained by these known issues which are planned to be fixed in the future.</p>
<div class="section" id="Depending-on-Python-global-and-free-variables">
<h4>Depending on Python global and free variables<a class="headerlink" href="#Depending-on-Python-global-and-free-variables" title="Enlazar permanentemente con este título">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Function</span></code> creates a new <code class="docutils literal notranslate"><span class="pre">ConcreteFunction</span></code> when called with a new value of a Python argument. However, it does not do that for the Python closure, globals, or nonlocals of that <code class="docutils literal notranslate"><span class="pre">Function</span></code>. If their value changes in between calls to the <code class="docutils literal notranslate"><span class="pre">Function</span></code>, the <code class="docutils literal notranslate"><span class="pre">Function</span></code> will still use the values they had when it was traced. This is different from how regular Python functions work.</p>
<p>For that reason, we recommend a functional programming style that uses arguments instead of closing over outer names.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def buggy_add():
  return 1 + foo

@tf.function
def recommended_add(foo):
  return 1 + foo

foo = 1
print(&quot;Buggy:&quot;, buggy_add())
print(&quot;Correct:&quot;, recommended_add(foo))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Updating the value of `foo` to 100!&quot;)
foo = 100
print(&quot;Buggy:&quot;, buggy_add())  # Did not change!
print(&quot;Correct:&quot;, recommended_add(foo))
</pre></div>
</div>
</div>
<p>You can close over outer names, as long as you don’t update their values.</p>
<div class="section" id="Depending-on-Python-objects">
<h5>Depending on Python objects<a class="headerlink" href="#Depending-on-Python-objects" title="Enlazar permanentemente con este título">¶</a></h5>
<p>The recommendation to pass Python objects as arguments into <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> has a number of known issues, that are expected to be fixed in the future. In general, you can rely on consistent tracing if you use a Python primitive or <code class="docutils literal notranslate"><span class="pre">tf.nest</span></code>-compatible structure as an argument or pass in a <em>different</em> instance of an object into a <code class="docutils literal notranslate"><span class="pre">Function</span></code>. However, <code class="docutils literal notranslate"><span class="pre">Function</span></code> will <em>not</em> create a new trace when you pass <strong>the same object and only change its attributes</strong>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class SimpleModel(tf.Module):
  def __init__(self):
    # These values are *not* tf.Variables.
    self.bias = 0.
    self.weight = 2.

@tf.function
def evaluate(model, x):
  return model.weight * x + model.bias

simple_model = SimpleModel()
x = tf.constant(10.)
print(evaluate(simple_model, x))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Adding bias!&quot;)
simple_model.bias += 5.0
print(evaluate(simple_model, x))  # Didn&#39;t change :(
</pre></div>
</div>
</div>
<p>Using the same <code class="docutils literal notranslate"><span class="pre">Function</span></code> to evaluate the updated instance of the model will be buggy since the updated model has the <a class="reference external" href="#rules_of_tracing">same cache key</a> as the original model.</p>
<p>For that reason, we recommend that you write your <code class="docutils literal notranslate"><span class="pre">Function</span></code> to avoid depending on mutable object attributes or create new objects.</p>
<p>If that is not possible, one workaround is to make new <code class="docutils literal notranslate"><span class="pre">Function</span></code>s each time you modify your object to force retracing:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def evaluate(model, x):
  return model.weight * x + model.bias

new_model = SimpleModel()
evaluate_no_bias = tf.function(evaluate).get_concrete_function(new_model, x)
# Don&#39;t pass in `new_model`, `Function` already captured its state during tracing.
print(evaluate_no_bias(x))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>

<span></span>print(&quot;Adding bias!&quot;)
new_model.bias += 5.0
# Create new Function and ConcreteFunction since you modified new_model.
evaluate_with_bias = tf.function(evaluate).get_concrete_function(new_model, x)
print(evaluate_with_bias(x)) # Don&#39;t pass in `new_model`.
</pre></div>
</div>
</div>
<p>As <a class="reference external" href="https://www.tensorflow.org/guide/intro_to_graphs#tracing_and_performance">retracing can be expensive</a>, you can use <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code>s as object attributes, which can be mutated (but not changed, careful!) for a similar effect without needing a retrace.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class BetterModel:

  def __init__(self):
    self.bias = tf.Variable(0.)
    self.weight = tf.Variable(2.)

@tf.function
def evaluate(model, x):
  return model.weight * x + model.bias

better_model = BetterModel()
print(evaluate(better_model, x))

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Adding bias!&quot;)
better_model.bias.assign_add(5.0)  # Note: instead of better_model.bias += 5
print(evaluate(better_model, x))  # This works!
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Creating-tf.Variables">
<h4>Creating tf.Variables<a class="headerlink" href="#Creating-tf.Variables" title="Enlazar permanentemente con este título">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Function</span></code> only supports creating variables once, when first called, and then reusing them. You cannot create <code class="docutils literal notranslate"><span class="pre">tf.Variables</span></code> in new traces. Creating new variables in subsequent calls is currently not allowed, but will be in the future.</p>
<p>Example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def f(x):
  v = tf.Variable(1.0)
  return v

with assert_raises(ValueError):
  f(1.0)
</pre></div>
</div>
</div>
<p>You can create variables inside a <code class="docutils literal notranslate"><span class="pre">Function</span></code> as long as those variables are only created the first time the function is executed.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class Count(tf.Module):
  def __init__(self):
    self.count = None

  @tf.function
  def __call__(self):
    if self.count is None:
      self.count = tf.Variable(0)
    return self.count.assign_add(1)

c = Count()
print(c())
print(c())
</pre></div>
</div>
</div>
<div class="section" id="Using-with-multiple-Keras-optimizers">
<h5>Using with multiple Keras optimizers<a class="headerlink" href="#Using-with-multiple-Keras-optimizers" title="Enlazar permanentemente con este título">¶</a></h5>
<p>You may encounter <code class="docutils literal notranslate"><span class="pre">ValueError:</span> <span class="pre">tf.function-decorated</span> <span class="pre">function</span> <span class="pre">tried</span> <span class="pre">to</span> <span class="pre">create</span> <span class="pre">variables</span> <span class="pre">on</span> <span class="pre">non-first</span> <span class="pre">call.</span></code> when using more than one Keras optimizer with a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>. This error occurs because optimizers internally create <code class="docutils literal notranslate"><span class="pre">tf.Variables</span></code> when they apply gradients for the first time.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)
opt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)

@tf.function
def train_step(w, x, y, optimizer):
   with tf.GradientTape() as tape:
       L = tf.reduce_sum(tf.square(w*x - y))
   gradients = tape.gradient(L, [w])
   optimizer.apply_gradients(zip(gradients, [w]))

w = tf.Variable(2.)
x = tf.constant([-1.])
y = tf.constant([2.])

train_step(w, x, y, opt1)
print(&quot;Calling `train_step` with different optimizer...&quot;)
with assert_raises(ValueError):
  train_step(w, x, y, opt2)
</pre></div>
</div>
</div>
<p>If you need to change the optimizer during training, a workaround is to create a new <code class="docutils literal notranslate"><span class="pre">Function</span></code> for each optimizer, calling the <code class="docutils literal notranslate"><span class="pre">`ConcreteFunction</span></code> &lt;#obtaining_concrete_functions&gt;`__ directly.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)
opt2 = tf.keras.optimizers.Adam(learning_rate = 1e-3)

# Not a tf.function.
def train_step(w, x, y, optimizer):
   with tf.GradientTape() as tape:
       L = tf.reduce_sum(tf.square(w*x - y))
   gradients = tape.gradient(L, [w])
   optimizer.apply_gradients(zip(gradients, [w]))

w = tf.Variable(2.)
x = tf.constant([-1.])
y = tf.constant([2.])

# Make a new Function and ConcreteFunction for each optimizer.
train_step_1 = tf.function(train_step).get_concrete_function(w, x, y, opt1)
train_step_2 = tf.function(train_step).get_concrete_function(w, x, y, opt2)
for i in range(10):
  if i % 2 == 0:
    train_step_1(w, x, y) # `opt1` is not used as a parameter.
  else:
    train_step_2(w, x, y) # `opt2` is not used as a parameter.
</pre></div>
</div>
</div>
</div>
<div class="section" id="Using-with-multiple-Keras-models">
<h5>Using with multiple Keras models<a class="headerlink" href="#Using-with-multiple-Keras-models" title="Enlazar permanentemente con este título">¶</a></h5>
<p>You may also encounter <code class="docutils literal notranslate"><span class="pre">ValueError:</span> <span class="pre">tf.function-decorated</span> <span class="pre">function</span> <span class="pre">tried</span> <span class="pre">to</span> <span class="pre">create</span> <span class="pre">variables</span> <span class="pre">on</span> <span class="pre">non-first</span> <span class="pre">call.</span></code> when passing different model instances to the same <code class="docutils literal notranslate"><span class="pre">Function</span></code>.</p>
<p>This error occurs because Keras models (which <a class="reference external" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models#best_practice_deferring_weight_creation_until_the_shape_of_the_inputs_is_known">do not have their input shape defined</a>) and Keras layers create <code class="docutils literal notranslate"><span class="pre">tf.Variables</span></code>s when they are first called. You may be attempting to initialize those variables inside a <code class="docutils literal notranslate"><span class="pre">Function</span></code>, which has already been called. To avoid this error, try calling <code class="docutils literal notranslate"><span class="pre">model.build(input_shape)</span></code> to initialize all the
weights before training the model.</p>
</div>
</div>
</div>
<div class="section" id="Further-reading">
<h3>Further reading<a class="headerlink" href="#Further-reading" title="Enlazar permanentemente con este título">¶</a></h3>
<p>To learn about how to export and load a <code class="docutils literal notranslate"><span class="pre">Function</span></code>, see the <a class="reference external" href="../../guide/saved_model">SavedModel guide</a>. To learn more about graph optimizations that are performed after tracing, see the <a class="reference external" href="../../guide/graph_optimization">Grappler guide</a>. To learn how to optimize your data pipeline and profile your model, see the <a class="reference external" href="../../guide/profiler.md">Profiler guide</a>.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>