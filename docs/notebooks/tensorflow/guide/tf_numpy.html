

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2020 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2020 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow/guide/tf_numpy.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2020-The-TensorFlow-Authors.">
<h1>Copyright 2020 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2020-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="NumPy-API-on-TensorFlow">
<h2>NumPy API on TensorFlow<a class="headerlink" href="#NumPy-API-on-TensorFlow" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>b3c5312b06604ceaa961279523187a46|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>916ed3f6f8fe4737930f9e44270d4f31|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>16722f0385be43e68ec79daf4a1e93e9|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>15d73da932db4d458b00b4819cc4e527|Download notebook</p>
</td></table><div class="section" id="Overview">
<h3>Overview<a class="headerlink" href="#Overview" title="Enlazar permanentemente con este título">¶</a></h3>
<p>TensorFlow implements a subset of the <a class="reference external" href="https://numpy.org/doc/1.16">NumPy API</a>, available as <code class="docutils literal notranslate"><span class="pre">tf.experimental.numpy</span></code>. This allows running NumPy code, accelerated by TensorFlow, while also allowing access to all of TensorFlow’s APIs.</p>
<p>Note: This guide is using <code class="docutils literal notranslate"><span class="pre">tf-nightly</span></code> and experimental features.</p>
</div>
<div class="section" id="Setup">
<h3>Setup<a class="headerlink" href="#Setup" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>!pip install -q tf-nightly
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import tensorflow.experimental.numpy as tnp
import timeit

print(&quot;Using TensorFlow version %s&quot; % tf.__version__)
</pre></div>
</div>
</div>
<div class="section" id="Enabling-NumPy-behavior">
<h4>Enabling NumPy behavior<a class="headerlink" href="#Enabling-NumPy-behavior" title="Enlazar permanentemente con este título">¶</a></h4>
<p>In order to use <code class="docutils literal notranslate"><span class="pre">tnp</span></code> as NumPy, enable NumPy behavior for TensorFlow:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>tnp.experimental_enable_numpy_behavior()
</pre></div>
</div>
</div>
<p>This call enables type promotion in TensorFlow and also changes type inference, when converting literals to tensors, to more strictly follow the NumPy standard.</p>
<p>Note: This call will change the behavior of entire TensorFlow, not just the <code class="docutils literal notranslate"><span class="pre">tf.experimental.numpy</span></code> module.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">tensorflow.experimental.numpy.experimental_enable_numpy_behavior</span></code> only exists in <code class="docutils literal notranslate"><span class="pre">tf-nightly</span></code>.</p>
</div>
</div>
<div class="section" id="TensorFlow-NumPy-ND-array">
<h3>TensorFlow NumPy ND array<a class="headerlink" href="#TensorFlow-NumPy-ND-array" title="Enlazar permanentemente con este título">¶</a></h3>
<p>An instance of <code class="docutils literal notranslate"><span class="pre">tf.experimental.numpy.ndarray</span></code>, called <strong>ND Array</strong>, represents a multidimensional dense array of a given <code class="docutils literal notranslate"><span class="pre">dtype</span></code> placed on a certain device. It is an alias to <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>. Check out the ND array class for useful methods like <code class="docutils literal notranslate"><span class="pre">ndarray.T</span></code>, <code class="docutils literal notranslate"><span class="pre">ndarray.reshape</span></code>, <code class="docutils literal notranslate"><span class="pre">ndarray.ravel</span></code> and others.</p>
<p>First create an ND array object, and then invoke different methods.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Create an ND array and check out different attributes.
ones = tnp.ones([5, 3], dtype=tnp.float32)
print(&quot;Created ND array with shape = %s, rank = %s, &quot;
      &quot;dtype = %s on device = %s\n&quot; % (
          ones.shape, ones.ndim, ones.dtype, ones.device))

# `ndarray` is just an alias to `tf.Tensor`.
print(&quot;Is `ones` an instance of tf.Tensor: %s\n&quot; % isinstance(ones, tf.Tensor))

# Try commonly used member functions.
print(&quot;ndarray.T has shape %s&quot; % str(ones.T.shape))
print(&quot;narray.reshape(-1) has shape %s&quot; % ones.reshape(-1).shape)
</pre></div>
</div>
</div>
<div class="section" id="Type-promotion">
<h4>Type promotion<a class="headerlink" href="#Type-promotion" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow NumPy APIs have well-defined semantics for converting literals to ND array, as well as for performing type promotion on ND array inputs. Please see <code class="docutils literal notranslate"><span class="pre">`np.result_type</span></code> &lt;<a class="reference external" href="https://numpy.org/doc/1.16/reference/generated/numpy.result_type.html">https://numpy.org/doc/1.16/reference/generated/numpy.result_type.html</a>&gt;`__ for more details.</p>
<p>TensorFlow APIs leave <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> inputs unchanged and do not perform type promotion on them, while TensorFlow NumPy APIs promote all inputs according to NumPy type promotion rules. In the next example, you will perform type promotion. First, run addition on ND array inputs of different types and note the output types. None of these type promotions would be allowed by TensorFlow APIs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Type promotion for operations&quot;)
values = [tnp.asarray(1, dtype=d) for d in
          (tnp.int32, tnp.int64, tnp.float32, tnp.float64)]
for i, v1 in enumerate(values):
  for v2 in values[i + 1:]:
    print(&quot;%s + %s =&gt; %s&quot; %
          (v1.dtype.name, v2.dtype.name, (v1 + v2).dtype.name))
</pre></div>
</div>
</div>
<p>Finally, convert literals to ND array using <code class="docutils literal notranslate"><span class="pre">ndarray.asarray</span></code> and note the resulting type.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Type inference during array creation&quot;)
print(&quot;tnp.asarray(1).dtype == tnp.%s&quot; % tnp.asarray(1).dtype.name)
print(&quot;tnp.asarray(1.).dtype == tnp.%s\n&quot; % tnp.asarray(1.).dtype.name)
</pre></div>
</div>
</div>
<p>When converting literals to ND array, NumPy prefers wide types like <code class="docutils literal notranslate"><span class="pre">tnp.int64</span></code> and <code class="docutils literal notranslate"><span class="pre">tnp.float64</span></code>. In contrast, <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code> prefers <code class="docutils literal notranslate"><span class="pre">tf.int32</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code> types for converting constants to <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>. TensorFlow NumPy APIs adhere to the NumPy behavior for integers. As for floats, the <code class="docutils literal notranslate"><span class="pre">prefer_float32</span></code> argument of <code class="docutils literal notranslate"><span class="pre">experimental_enable_numpy_behavior</span></code> lets you control whether to prefer <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code> over <code class="docutils literal notranslate"><span class="pre">tf.float64</span></code> (default to <code class="docutils literal notranslate"><span class="pre">False</span></code>). For example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>tnp.experimental_enable_numpy_behavior(prefer_float32=True)
print(&quot;When prefer_float32 is True:&quot;)
print(&quot;tnp.asarray(1.).dtype == tnp.%s&quot; % tnp.asarray(1.).dtype.name)
print(&quot;tnp.add(1., 2.).dtype == tnp.%s&quot; % tnp.add(1., 2.).dtype.name)

tnp.experimental_enable_numpy_behavior(prefer_float32=False)
print(&quot;When prefer_float32 is False:&quot;)
print(&quot;tnp.asarray(1.).dtype == tnp.%s&quot; % tnp.asarray(1.).dtype.name)
print(&quot;tnp.add(1., 2.).dtype == tnp.%s&quot; % tnp.add(1., 2.).dtype.name)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Broadcasting">
<h4>Broadcasting<a class="headerlink" href="#Broadcasting" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Similar to TensorFlow, NumPy defines rich semantics for “broadcasting” values. You can check out the <a class="reference external" href="https://numpy.org/doc/1.16/user/basics.broadcasting.html">NumPy broadcasting guide</a> for more information and compare this with <a class="reference external" href="https://www.tensorflow.org/guide/tensor#broadcasting">TensorFlow broadcasting semantics</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x = tnp.ones([2, 3])
y = tnp.ones([3])
z = tnp.ones([1, 2, 1])
print(&quot;Broadcasting shapes %s, %s and %s gives shape %s&quot; % (
    x.shape, y.shape, z.shape, (x + y + z).shape))
</pre></div>
</div>
</div>
</div>
<div class="section" id="Indexing">
<h4>Indexing<a class="headerlink" href="#Indexing" title="Enlazar permanentemente con este título">¶</a></h4>
<p>NumPy defines very sophisticated indexing rules. See the <a class="reference external" href="https://numpy.org/doc/1.16/reference/arrays.indexing.html">NumPy Indexing guide</a>. Note the use of ND arrays as indices below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x = tnp.arange(24).reshape(2, 3, 4)

print(&quot;Basic indexing&quot;)
print(x[1, tnp.newaxis, 1:3, ...], &quot;\n&quot;)

print(&quot;Boolean indexing&quot;)
print(x[:, (True, False, True)], &quot;\n&quot;)

print(&quot;Advanced indexing&quot;)
print(x[1, (0, 0, 1), tnp.asarray([0, 1, 1])])
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Mutation is currently not supported
try:
  tnp.arange(6)[1] = -1
except TypeError:
  print(&quot;Currently, TensorFlow NumPy does not support mutation.&quot;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Example-Model">
<h4>Example Model<a class="headerlink" href="#Example-Model" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Next, you can see how to create a model and run inference on it. This simple model applies a relu layer followed by a linear projection. Later sections will show how to compute gradients for this model using TensorFlow’s <code class="docutils literal notranslate"><span class="pre">GradientTape</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class Model(object):
  &quot;&quot;&quot;Model with a dense and a linear layer.&quot;&quot;&quot;

  def __init__(self):
    self.weights = None

  def predict(self, inputs):
    if self.weights is None:
      size = inputs.shape[1]
      # Note that type `tnp.float32` is used for performance.
      stddev = tnp.sqrt(size).astype(tnp.float32)
      w1 = tnp.random.randn(size, 64).astype(tnp.float32) / stddev
      bias = tnp.random.randn(64).astype(tnp.float32)
      w2 = tnp.random.randn(64, 2).astype(tnp.float32) / 8
      self.weights = (w1, bias, w2)
    else:
      w1, bias, w2 = self.weights
    y = tnp.matmul(inputs, w1) + bias
    y = tnp.maximum(y, 0)  # Relu
    return tnp.matmul(y, w2)  # Linear projection

model = Model()
# Create input data and compute predictions.
print(model.predict(tnp.ones([2, 32], dtype=tnp.float32)))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="TensorFlow-NumPy-and-NumPy">
<h3>TensorFlow NumPy and NumPy<a class="headerlink" href="#TensorFlow-NumPy-and-NumPy" title="Enlazar permanentemente con este título">¶</a></h3>
<p>TensorFlow NumPy implements a subset of the full NumPy spec. While more symbols will be added over time, there are systematic features that will not be supported in the near future. These include NumPy C API support, Swig integration, Fortran storage order, views and <code class="docutils literal notranslate"><span class="pre">stride_tricks</span></code>, and some <code class="docutils literal notranslate"><span class="pre">dtype</span></code>s (like <code class="docutils literal notranslate"><span class="pre">np.recarray</span></code> and <code class="docutils literal notranslate"><span class="pre">np.object</span></code>). For more details, please see the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/experimental/numpy">TensorFlow NumPy API Documentation</a>.</p>
<div class="section" id="NumPy-interoperability">
<h4>NumPy interoperability<a class="headerlink" href="#NumPy-interoperability" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow ND arrays can interoperate with NumPy functions. These objects implement the <code class="docutils literal notranslate"><span class="pre">__array__</span></code> interface. NumPy uses this interface to convert function arguments to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> values before processing them.</p>
<p>Similarly, TensorFlow NumPy functions can accept inputs of different types including <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code>. These inputs are converted to an ND array by calling <code class="docutils literal notranslate"><span class="pre">ndarray.asarray</span></code> on them.</p>
<p>Conversion of the ND array to and from <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> may trigger actual data copies. Please see the section on <a class="reference external" href="#buffer-copies">buffer copies</a> for more details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># ND array passed into NumPy function.
np_sum = np.sum(tnp.ones([2, 3]))
print(&quot;sum = %s. Class: %s&quot; % (float(np_sum), np_sum.__class__))

# `np.ndarray` passed into TensorFlow NumPy function.
tnp_sum = tnp.sum(np.ones([2, 3]))
print(&quot;sum = %s. Class: %s&quot; % (float(tnp_sum), tnp_sum.__class__))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># It is easy to plot ND arrays, given the __array__ interface.
labels = 15 + 2 * tnp.random.randn(1, 1000)
_ = plt.hist(labels)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Buffer-copies">
<h4>Buffer copies<a class="headerlink" href="#Buffer-copies" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Intermixing TensorFlow NumPy with NumPy code may trigger data copies. This is because TensorFlow NumPy has stricter requirements on memory alignment than those of NumPy.</p>
<p>When a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> is passed to TensorFlow NumPy, it will check for alignment requirements and trigger a copy if needed. When passing an ND array CPU buffer to NumPy, generally the buffer will satisfy alignment requirements and NumPy will not need to create a copy.</p>
<p>ND arrays can refer to buffers placed on devices other than the local CPU memory. In such cases, invoking a NumPy function will trigger copies across the network or device as needed.</p>
<p>Given this, intermixing with NumPy API calls should generally be done with caution and the user should watch out for overheads of copying data. Interleaving TensorFlow NumPy calls with TensorFlow calls is generally safe and avoids copying data. See the section on <a class="reference external" href="#tensorflow-interoperability">TensorFlow interoperability</a> for more details.</p>
</div>
<div class="section" id="Operator-precedence">
<h4>Operator precedence<a class="headerlink" href="#Operator-precedence" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow NumPy defines an <code class="docutils literal notranslate"><span class="pre">__array_priority__</span></code> higher than NumPy’s. This means that for operators involving both ND array and <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code>, the former will take precedence, i.e., <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> input will get converted to an ND array and the TensorFlow NumPy implementation of the operator will get invoked.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x = tnp.ones([2]) + np.ones([2])
print(&quot;x = %s\nclass = %s&quot; % (x, x.__class__))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="TF-NumPy-and-TensorFlow">
<h3>TF NumPy and TensorFlow<a class="headerlink" href="#TF-NumPy-and-TensorFlow" title="Enlazar permanentemente con este título">¶</a></h3>
<p>TensorFlow NumPy is built on top of TensorFlow and hence interoperates seamlessly with TensorFlow.</p>
<div class="section" id="tf.Tensor-and-ND-array">
<h4><code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> and ND array<a class="headerlink" href="#tf.Tensor-and-ND-array" title="Enlazar permanentemente con este título">¶</a></h4>
<p>ND array is an alias to <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>, so obviously they can be intermixed without triggering actual data copies.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>x = tf.constant([1, 2])
print(x)

# `asarray` and `convert_to_tensor` here are no-ops.
tnp_x = tnp.asarray(x)
print(tnp_x)
print(tf.convert_to_tensor(tnp_x))

# Note that tf.Tensor.numpy() will continue to return `np.ndarray`.
print(x.numpy(), x.numpy().__class__)
</pre></div>
</div>
</div>
</div>
<div class="section" id="TensorFlow-interoperability">
<h4>TensorFlow interoperability<a class="headerlink" href="#TensorFlow-interoperability" title="Enlazar permanentemente con este título">¶</a></h4>
<p>An ND array can be passed to TensorFlow APIs, since ND array is just an alias to <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>. As mentioned earlier, such interoperation does not do data copies, even for data placed on accelerators or remote devices.</p>
<p>Conversely, <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> objects can be passed to <code class="docutils literal notranslate"><span class="pre">tf.experimental.numpy</span></code> APIs, without performing data copies.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># ND array passed into TensorFlow function.
tf_sum = tf.reduce_sum(tnp.ones([2, 3], tnp.float32))
print(&quot;Output = %s&quot; % tf_sum)

# `tf.Tensor` passed into TensorFlow NumPy function.
tnp_sum = tnp.sum(tf.ones([2, 3]))
print(&quot;Output = %s&quot; % tnp_sum)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Gradients-and-Jacobians:-tf.GradientTape">
<h4>Gradients and Jacobians: tf.GradientTape<a class="headerlink" href="#Gradients-and-Jacobians:-tf.GradientTape" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow’s GradientTape can be used for backpropagation through TensorFlow and TensorFlow NumPy code.</p>
<p>Use the model created in <a class="reference external" href="#example-model">Example Model</a> section, and compute gradients and jacobians.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def create_batch(batch_size=32):
  &quot;&quot;&quot;Creates a batch of input and labels.&quot;&quot;&quot;
  return (tnp.random.randn(batch_size, 32).astype(tnp.float32),
          tnp.random.randn(batch_size, 2).astype(tnp.float32))

def compute_gradients(model, inputs, labels):
  &quot;&quot;&quot;Computes gradients of squared loss between model prediction and labels.&quot;&quot;&quot;
  with tf.GradientTape() as tape:
    assert model.weights is not None
    # Note that `model.weights` need to be explicitly watched since they
    # are not tf.Variables.
    tape.watch(model.weights)
    # Compute prediction and loss
    prediction = model.predict(inputs)
    loss = tnp.sum(tnp.square(prediction - labels))
  # This call computes the gradient through the computation above.
  return tape.gradient(loss, model.weights)

inputs, labels = create_batch()
gradients = compute_gradients(model, inputs, labels)

# Inspect the shapes of returned gradients to verify they match the
# parameter shapes.
print(&quot;Parameter shapes:&quot;, [w.shape for w in model.weights])
print(&quot;Gradient shapes:&quot;, [g.shape for g in gradients])
# Verify that gradients are of type ND array.
assert isinstance(gradients[0], tnp.ndarray)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Computes a batch of jacobians. Each row is the jacobian of an element in the
# batch of outputs w.r.t. the corresponding input batch element.
def prediction_batch_jacobian(inputs):
  with tf.GradientTape() as tape:
    tape.watch(inputs)
    prediction = model.predict(inputs)
  return prediction, tape.batch_jacobian(prediction, inputs)

inp_batch = tnp.ones([16, 32], tnp.float32)
output, batch_jacobian = prediction_batch_jacobian(inp_batch)
# Note how the batch jacobian shape relates to the input and output shapes.
print(&quot;Output shape: %s, input shape: %s&quot; % (output.shape, inp_batch.shape))
print(&quot;Batch jacobian shape:&quot;, batch_jacobian.shape)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Trace-compilation:-tf.function">
<h4>Trace compilation: tf.function<a class="headerlink" href="#Trace-compilation:-tf.function" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow’s <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> works by “trace compiling” the code and then optimizing these traces for much faster performance. See the <a class="reference internal" href="intro_to_graphs.html"><span class="doc">Introduction to Graphs and Functions</span></a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">tf.function</span></code> can be used to optimize TensorFlow NumPy code as well. Here is a simple example to demonstrate the speedups. Note that the body of <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> code includes calls to TensorFlow NumPy APIs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>inputs, labels = create_batch(512)
print(&quot;Eager performance&quot;)
compute_gradients(model, inputs, labels)
print(timeit.timeit(lambda: compute_gradients(model, inputs, labels),
                    number=10) * 100, &quot;ms&quot;)

print(&quot;\ntf.function compiled performance&quot;)
compiled_compute_gradients = tf.function(compute_gradients)
compiled_compute_gradients(model, inputs, labels)  # warmup
print(timeit.timeit(lambda: compiled_compute_gradients(model, inputs, labels),
                    number=10) * 100, &quot;ms&quot;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Vectorization:-tf.vectorized_map">
<h4>Vectorization: tf.vectorized_map<a class="headerlink" href="#Vectorization:-tf.vectorized_map" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow has inbuilt support for vectorizing parallel loops, which allows speedups of one to two orders of magnitude. These speedups are accessible via the <code class="docutils literal notranslate"><span class="pre">tf.vectorized_map</span></code> API and apply to TensorFlow NumPy code as well.</p>
<p>It is sometimes useful to compute the gradient of each output in a batch w.r.t. the corresponding input batch element. Such computation can be done efficiently using <code class="docutils literal notranslate"><span class="pre">tf.vectorized_map</span></code> as shown below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>@tf.function
def vectorized_per_example_gradients(inputs, labels):
  def single_example_gradient(arg):
    inp, label = arg
    return compute_gradients(model,
                             tnp.expand_dims(inp, 0),
                             tnp.expand_dims(label, 0))
  # Note that a call to `tf.vectorized_map` semantically maps
  # `single_example_gradient` over each row of `inputs` and `labels`.
  # The interface is similar to `tf.map_fn`.
  # The underlying machinery vectorizes away this map loop which gives
  # nice speedups.
  return tf.vectorized_map(single_example_gradient, (inputs, labels))

batch_size = 128
inputs, labels = create_batch(batch_size)

per_example_gradients = vectorized_per_example_gradients(inputs, labels)
for w, p in zip(model.weights, per_example_gradients):
  print(&quot;Weight shape: %s, batch size: %s, per example gradient shape: %s &quot; % (
      w.shape, batch_size, p.shape))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Benchmark the vectorized computation above and compare with
# unvectorized sequential computation using `tf.map_fn`.
@tf.function
def unvectorized_per_example_gradients(inputs, labels):
  def single_example_gradient(arg):
    inp, label = arg
    return compute_gradients(model,
                             tnp.expand_dims(inp, 0),
                             tnp.expand_dims(label, 0))

  return tf.map_fn(single_example_gradient, (inputs, labels),
                   fn_output_signature=(tf.float32, tf.float32, tf.float32))

print(&quot;Running vectorized computation&quot;)
print(timeit.timeit(lambda: vectorized_per_example_gradients(inputs, labels),
                    number=10) * 100, &quot;ms&quot;)

print(&quot;\nRunning unvectorized computation&quot;)
per_example_gradients = unvectorized_per_example_gradients(inputs, labels)
print(timeit.timeit(lambda: unvectorized_per_example_gradients(inputs, labels),
                    number=10) * 100, &quot;ms&quot;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Device-placement">
<h4>Device placement<a class="headerlink" href="#Device-placement" title="Enlazar permanentemente con este título">¶</a></h4>
<p>TensorFlow NumPy can place operations on CPUs, GPUs, TPUs and remote devices. It uses standard TensorFlow mechanisms for device placement. Below a simple example shows how to list all devices and then place some computation on a particular device.</p>
<p>TensorFlow also has APIs for replicating computation across devices and performing collective reductions which will not be covered here.</p>
<div class="section" id="List-devices">
<h5>List devices<a class="headerlink" href="#List-devices" title="Enlazar permanentemente con este título">¶</a></h5>
<p><code class="docutils literal notranslate"><span class="pre">tf.config.list_logical_devices</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.config.list_physical_devices</span></code> can be used to find what devices to use.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;All logical devices:&quot;, tf.config.list_logical_devices())
print(&quot;All physical devices:&quot;, tf.config.list_physical_devices())

# Try to get the GPU device. If unavailable, fallback to CPU.
try:
  device = tf.config.list_logical_devices(device_type=&quot;GPU&quot;)[0]
except IndexError:
  device = &quot;/device:CPU:0&quot;
</pre></div>
</div>
</div>
</div>
<div class="section" id="Placing-operations:-``tf.device``">
<h5>Placing operations: <strong>``tf.device``</strong><a class="headerlink" href="#Placing-operations:-``tf.device``" title="Enlazar permanentemente con este título">¶</a></h5>
<p>Operations can be placed on a device by calling it in a <code class="docutils literal notranslate"><span class="pre">tf.device</span></code> scope.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Using device: %s&quot; % str(device))
# Run operations in the `tf.device` scope.
# If a GPU is available, these operations execute on the GPU and outputs are
# placed on the GPU memory.
with tf.device(device):
  prediction = model.predict(create_batch(5)[0])

print(&quot;prediction is placed on %s&quot; % prediction.device)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Copying-ND-arrays-across-devices:-``tnp.copy``">
<h5>Copying ND arrays across devices: <strong>``tnp.copy``</strong><a class="headerlink" href="#Copying-ND-arrays-across-devices:-``tnp.copy``" title="Enlazar permanentemente con este título">¶</a></h5>
<p>A call to <code class="docutils literal notranslate"><span class="pre">tnp.copy</span></code>, placed in a certain device scope, will copy the data to that device, unless the data is already on that device.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>with tf.device(&quot;/device:CPU:0&quot;):
  prediction_cpu = tnp.copy(prediction)
print(prediction.device)
print(prediction_cpu.device)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Performance-comparisons">
<h3>Performance comparisons<a class="headerlink" href="#Performance-comparisons" title="Enlazar permanentemente con este título">¶</a></h3>
<p>TensorFlow NumPy uses highly optimized TensorFlow kernels that can be dispatched on CPUs, GPUs and TPUs. TensorFlow also performs many compiler optimizations, like operation fusion, which translate to performance and memory improvements. See <a class="reference internal" href="graph_optimization.html"><span class="doc">TensorFlow graph optimization with Grappler</span></a> to learn more.</p>
<p>However TensorFlow has higher overheads for dispatching operations compared to NumPy. For workloads composed of small operations (less than about 10 microseconds), these overheads can dominate the runtime and NumPy could provide better performance. For other cases, TensorFlow should generally provide better performance.</p>
<p>Run the benchmark below to compare NumPy and TensorFlow NumPy performance for different input sizes.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def benchmark(f, inputs, number=30, force_gpu_sync=False):
  &quot;&quot;&quot;Utility to benchmark `f` on each value in `inputs`.&quot;&quot;&quot;
  times = []
  for inp in inputs:
    def _g():
      if force_gpu_sync:
        one = tnp.asarray(1)
      f(inp)
      if force_gpu_sync:
        with tf.device(&quot;CPU:0&quot;):
          tnp.copy(one)  # Force a sync for GPU case

    _g()  # warmup
    t = timeit.timeit(_g, number=number)
    times.append(t * 1000. / number)
  return times


def plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu):
  &quot;&quot;&quot;Plot the different runtimes.&quot;&quot;&quot;
  plt.xlabel(&quot;size&quot;)
  plt.ylabel(&quot;time (ms)&quot;)
  plt.title(&quot;Sigmoid benchmark: TF NumPy vs NumPy&quot;)
  plt.plot(sizes, np_times, label=&quot;NumPy&quot;)
  plt.plot(sizes, tnp_times, label=&quot;TF NumPy (CPU)&quot;)
  plt.plot(sizes, compiled_tnp_times, label=&quot;Compiled TF NumPy (CPU)&quot;)
  if has_gpu:
    plt.plot(sizes, tnp_times_gpu, label=&quot;TF NumPy (GPU)&quot;)
  plt.legend()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Define a simple implementation of `sigmoid`, and benchmark it using
# NumPy and TensorFlow NumPy for different input sizes.

def np_sigmoid(y):
  return 1. / (1. + np.exp(-y))

def tnp_sigmoid(y):
  return 1. / (1. + tnp.exp(-y))

@tf.function
def compiled_tnp_sigmoid(y):
  return tnp_sigmoid(y)

sizes = (2 ** 0, 2 ** 5, 2 ** 10, 2 ** 15, 2 ** 20)
np_inputs = [np.random.randn(size).astype(np.float32) for size in sizes]
np_times = benchmark(np_sigmoid, np_inputs)

with tf.device(&quot;/device:CPU:0&quot;):
  tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]
  tnp_times = benchmark(tnp_sigmoid, tnp_inputs)
  compiled_tnp_times = benchmark(compiled_tnp_sigmoid, tnp_inputs)

has_gpu = len(tf.config.list_logical_devices(&quot;GPU&quot;))
if has_gpu:
  with tf.device(&quot;/device:GPU:0&quot;):
    tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]
    tnp_times_gpu = benchmark(compiled_tnp_sigmoid, tnp_inputs, 100, True)
else:
  tnp_times_gpu = None
plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Further-reading">
<h3>Further reading<a class="headerlink" href="#Further-reading" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_Numpy_Distributed_Image_Classification.ipynb">TensorFlow NumPy: Distributed Image Classification Tutorial</a></p></li>
<li><p><a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/g3doc/TensorFlow_NumPy_Keras_and_Distribution_Strategy.ipynb">TensorFlow NumPy: Keras and Distribution Strategy</a></p></li>
<li><p><a class="reference external" href="https://github.com/google/trax/blob/master/trax/tf_numpy_and_keras.ipynb">Sentiment Analysis with Trax and TensorFlow NumPy</a></p></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>