

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2018 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2018 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow/guide/data.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2018-The-TensorFlow-Authors.">
<h1>Copyright 2018 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2018-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<p>Licensed under the Apache License, Version 2.0 (the “License”);</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); { display-mode: &quot;form&quot; }
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="tf.data:-Build-TensorFlow-input-pipelines">
<h2>tf.data: Build TensorFlow input pipelines<a class="headerlink" href="#tf.data:-Build-TensorFlow-input-pipelines" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>f679d646517045548584810655d5067b|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>7e3306c0a6eb4e2c8fc9ebe0a879f025|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>42d8906f74134a9b85213b6a04714180|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>8ef16bda1d834f39a5af167bcaa203e0|Download notebook</p>
</td></table><p>The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API enables you to build complex input pipelines from simple, reusable pieces. For example, the pipeline for an image model might aggregate data from files in a distributed file system, apply random perturbations to each image, and merge randomly selected images into a batch for training. The pipeline for a text model might involve extracting symbols from raw text data, converting them to embedding identifiers with a lookup table, and batching together sequences of different
lengths. The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API introduces a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> abstraction that represents a sequence of elements, in which each element consists of one or more components. For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label.</p>
<p>There are two distinct ways to create a dataset:</p>
<ul class="simple">
<li><p>A data <strong>source</strong> constructs a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> from data stored in memory or in one or more files.</p></li>
<li><p>A data <strong>transformation</strong> constructs a dataset from one or more <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> objects.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import tensorflow as tf
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import pathlib
import os
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

np.set_printoptions(precision=4)
</pre></div>
</div>
</div>
<div class="section" id="Basic-mechanics">
<h3>Basic mechanics<a class="headerlink" href="#Basic-mechanics" title="Enlazar permanentemente con este título">¶</a></h3>
<p>To create an input pipeline, you must start with a data <em>source</em>. For example, to construct a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> from data in memory, you can use <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensors()</span></code> or <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensor_slices()</span></code>. Alternatively, if your input data is stored in a file in the recommended TFRecord format, you can use <code class="docutils literal notranslate"><span class="pre">tf.data.TFRecordDataset()</span></code>.</p>
<p>Once you have a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object, you can <em>transform</em> it into a new <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> by chaining method calls on the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> object. For example, you can apply per-element transformations such as <code class="docutils literal notranslate"><span class="pre">Dataset.map()</span></code>, and multi-element transformations such as <code class="docutils literal notranslate"><span class="pre">Dataset.batch()</span></code>. See the documentation for <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> for a complete list of transformations.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object is a Python iterable. This makes it possible to consume its elements using a for loop:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])
dataset
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for elem in dataset:
  print(elem.numpy())
</pre></div>
</div>
</div>
<p>Or by explicitly creating a Python iterator using <code class="docutils literal notranslate"><span class="pre">iter</span></code> and consuming its elements using <code class="docutils literal notranslate"><span class="pre">next</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>it = iter(dataset)

print(next(it).numpy())
</pre></div>
</div>
</div>
<p>Alternatively, dataset elements can be consumed using the <code class="docutils literal notranslate"><span class="pre">reduce</span></code> transformation, which reduces all elements to produce a single result. The following example illustrates how to use the <code class="docutils literal notranslate"><span class="pre">reduce</span></code> transformation to compute the sum of a dataset of integers.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(dataset.reduce(0, lambda state, value: state + value).numpy())
</pre></div>
</div>
</div>
  <!-- TODO(jsimsa): Talk about `tf.function` support. -->

### Dataset structure<p>A dataset produces a sequence of <em>elements</em>, where each element is the same (nested) structure of <em>components</em>. Individual components of the structure can be of any type representable by <code class="docutils literal notranslate"><span class="pre">tf.TypeSpec</span></code>, including <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.sparse.SparseTensor</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.TensorArray</span></code>, or <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code>.</p>
<p>The Python constructs that can be used to express the (nested) structure of elements include <code class="docutils literal notranslate"><span class="pre">tuple</span></code>, <code class="docutils literal notranslate"><span class="pre">dict</span></code>, <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code>, and <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>. In particular, <code class="docutils literal notranslate"><span class="pre">list</span></code> is not a valid construct for expressing the structure of dataset elements. This is because early tf.data users felt strongly about <code class="docutils literal notranslate"><span class="pre">list</span></code> inputs (e.g. passed to <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensors</span></code>) being automatically packed as tensors and <code class="docutils literal notranslate"><span class="pre">list</span></code> outputs (e.g. return values of user-defined functions) being coerced into a
<code class="docutils literal notranslate"><span class="pre">tuple</span></code>. As a consequence, if you would like a <code class="docutils literal notranslate"><span class="pre">list</span></code> input to be treated as a structure, you need to convert it into <code class="docutils literal notranslate"><span class="pre">tuple</span></code> and if you would like a <code class="docutils literal notranslate"><span class="pre">list</span></code> output to be a single component, then you need to explicitly pack it using <code class="docutils literal notranslate"><span class="pre">tf.stack</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset.element_spec</span></code> property allows you to inspect the type of each element component. The property returns a <em>nested structure</em> of <code class="docutils literal notranslate"><span class="pre">tf.TypeSpec</span></code> objects, matching the structure of the element, which may be a single component a tuple of components, or a nested tuple of components. For example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))

dataset1.element_spec
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset2 = tf.data.Dataset.from_tensor_slices(
   (tf.random.uniform([4]),
    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))

dataset2.element_spec
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset3 = tf.data.Dataset.zip((dataset1, dataset2))

dataset3.element_spec
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Dataset containing a sparse tensor.
dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4]))

dataset4.element_spec
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Use value_type to see the type of value represented by the element spec
dataset4.element_spec.value_type
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> transformations support datasets of any structure. When using the <code class="docutils literal notranslate"><span class="pre">Dataset.map()</span></code>, and <code class="docutils literal notranslate"><span class="pre">Dataset.filter()</span></code> transformations, which apply a function to each element, the element structure determines the arguments of the function:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset1 = tf.data.Dataset.from_tensor_slices(
    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))

dataset1
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for z in dataset1:
  print(z.numpy())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset2 = tf.data.Dataset.from_tensor_slices(
   (tf.random.uniform([4]),
    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))

dataset2
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset3 = tf.data.Dataset.zip((dataset1, dataset2))

dataset3
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for a, (b,c) in dataset3:
  print(&#39;shapes: {a.shape}, {b.shape}, {c.shape}&#39;.format(a=a, b=b, c=c))
</pre></div>
</div>
</div>
</div>
<div class="section" id="Reading-input-data">
<h3>Reading input data<a class="headerlink" href="#Reading-input-data" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Consuming-NumPy-arrays">
<h4>Consuming NumPy arrays<a class="headerlink" href="#Consuming-NumPy-arrays" title="Enlazar permanentemente con este título">¶</a></h4>
<p>See <a class="reference external" href="../tutorials/load_data/numpy.ipynb">Loading NumPy arrays</a> for more examples.</p>
<p>If all of your input data fits in memory, the simplest way to create a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> from them is to convert them to <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> objects and use <code class="docutils literal notranslate"><span class="pre">Dataset.from_tensor_slices()</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train, test = tf.keras.datasets.fashion_mnist.load_data()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>images, labels = train
images = images/255

dataset = tf.data.Dataset.from_tensor_slices((images, labels))
dataset
</pre></div>
</div>
</div>
<p>Note: The above code snippet will embed the <code class="docutils literal notranslate"><span class="pre">features</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code> arrays in your TensorFlow graph as <code class="docutils literal notranslate"><span class="pre">tf.constant()</span></code> operations. This works well for a small dataset, but wastes memory—because the contents of the array will be copied multiple times—and can run into the 2GB limit for the <code class="docutils literal notranslate"><span class="pre">tf.GraphDef</span></code> protocol buffer.</p>
</div>
<div class="section" id="Consuming-Python-generators">
<h4>Consuming Python generators<a class="headerlink" href="#Consuming-Python-generators" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Another common data source that can easily be ingested as a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> is the python generator.</p>
<p>Caution: While this is a convienient approach it has limited portability and scalibility. It must run in the same python process that created the generator, and is still subject to the Python <a class="reference external" href="https://en.wikipedia.org/wiki/Global_interpreter_lock">GIL</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def count(stop):
  i = 0
  while i&lt;stop:
    yield i
    i += 1
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for n in count(5):
  print(n)
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset.from_generator</span></code> constructor converts the python generator to a fully functional <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code>.</p>
<p>The constructor takes a callable as input, not an iterator. This allows it to restart the generator when it reaches the end. It takes an optional <code class="docutils literal notranslate"><span class="pre">args</span></code> argument, which is passed as the callable’s arguments.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">output_types</span></code> argument is required because <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> builds a <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code> internally, and graph edges require a <code class="docutils literal notranslate"><span class="pre">tf.dtype</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>ds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes = (), )
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for count_batch in ds_counter.repeat().batch(10).take(10):
  print(count_batch.numpy())
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">output_shapes</span></code> argument is not <em>required</em> but is highly recomended as many tensorflow operations do not support tensors with unknown rank. If the length of a particular axis is unknown or variable, set it as <code class="docutils literal notranslate"><span class="pre">None</span></code> in the <code class="docutils literal notranslate"><span class="pre">output_shapes</span></code>.</p>
<p>It’s also important to note that the <code class="docutils literal notranslate"><span class="pre">output_shapes</span></code> and <code class="docutils literal notranslate"><span class="pre">output_types</span></code> follow the same nesting rules as other dataset methods.</p>
<p>Here is an example generator that demonstrates both aspects, it returns tuples of arrays, where the second array is a vector with unknown length.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def gen_series():
  i = 0
  while True:
    size = np.random.randint(0, 10)
    yield i, np.random.normal(size=(size,))
    i += 1
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for i, series in gen_series():
  print(i, &quot;:&quot;, str(series))
  if i &gt; 5:
    break
</pre></div>
</div>
</div>
<p>The first output is an <code class="docutils literal notranslate"><span class="pre">int32</span></code> the second is a <code class="docutils literal notranslate"><span class="pre">float32</span></code>.</p>
<p>The first item is a scalar, shape <code class="docutils literal notranslate"><span class="pre">()</span></code>, and the second is a vector of unknown length, shape <code class="docutils literal notranslate"><span class="pre">(None,)</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>ds_series = tf.data.Dataset.from_generator(
    gen_series,
    output_types=(tf.int32, tf.float32),
    output_shapes=((), (None,)))

ds_series
</pre></div>
</div>
</div>
<p>Now it can be used like a regular <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code>. Note that when batching a dataset with a variable shape, you need to use <code class="docutils literal notranslate"><span class="pre">Dataset.padded_batch</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>ds_series_batch = ds_series.shuffle(20).padded_batch(10)

ids, sequence_batch = next(iter(ds_series_batch))
print(ids.numpy())
print()
print(sequence_batch.numpy())
</pre></div>
</div>
</div>
<p>For a more realistic example, try wrapping <code class="docutils literal notranslate"><span class="pre">preprocessing.image.ImageDataGenerator</span></code> as a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code>.</p>
<p>First download the data:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>flowers = tf.keras.utils.get_file(
    &#39;flower_photos&#39;,
    &#39;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&#39;,
    untar=True)
</pre></div>
</div>
</div>
<p>Create the <code class="docutils literal notranslate"><span class="pre">image.ImageDataGenerator</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>images, labels = next(img_gen.flow_from_directory(flowers))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(images.dtype, images.shape)
print(labels.dtype, labels.shape)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>ds = tf.data.Dataset.from_generator(
    lambda: img_gen.flow_from_directory(flowers),
    output_types=(tf.float32, tf.float32),
    output_shapes=([32,256,256,3], [32,5])
)

ds.element_spec
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for images, label in ds.take(1):
  print(&#39;images.shape: &#39;, images.shape)
  print(&#39;labels.shape: &#39;, labels.shape)

</pre></div>
</div>
</div>
</div>
<div class="section" id="Consuming-TFRecord-data">
<h4>Consuming TFRecord data<a class="headerlink" href="#Consuming-TFRecord-data" title="Enlazar permanentemente con este título">¶</a></h4>
<p>See <a class="reference external" href="../tutorials/load_data/tfrecord.ipynb">Loading TFRecords</a> for an end-to-end example.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API supports a variety of file formats so that you can process large datasets that do not fit in memory. For example, the TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data. The <code class="docutils literal notranslate"><span class="pre">tf.data.TFRecordDataset</span></code> class enables you to stream over the contents of one or more TFRecord files as part of an input pipeline.</p>
<p>Here is an example using the test file from the French Street Name Signs (FSNS).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Creates a dataset that reads all of the examples from two files.
fsns_test_file = tf.keras.utils.get_file(&quot;fsns.tfrec&quot;, &quot;https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001&quot;)
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">filenames</span></code> argument to the <code class="docutils literal notranslate"><span class="pre">TFRecordDataset</span></code> initializer can either be a string, a list of strings, or a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of strings. Therefore if you have two sets of files for training and validation purposes, you can create a factory method that produces the dataset, taking filenames as an input argument:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])
dataset
</pre></div>
</div>
</div>
<p>Many TensorFlow projects use serialized <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code> records in their TFRecord files. These need to be decoded before they can be inspected:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>raw_example = next(iter(dataset))
parsed = tf.train.Example.FromString(raw_example.numpy())

parsed.features.feature[&#39;image/text&#39;]
</pre></div>
</div>
</div>
</div>
<div class="section" id="Consuming-text-data">
<h4>Consuming text data<a class="headerlink" href="#Consuming-text-data" title="Enlazar permanentemente con este título">¶</a></h4>
<p>See <a class="reference external" href="../tutorials/load_data/text.ipynb">Loading Text</a> for an end to end example.</p>
<p>Many datasets are distributed as one or more text files. The <code class="docutils literal notranslate"><span class="pre">tf.data.TextLineDataset</span></code> provides an easy way to extract lines from one or more text files. Given one or more filenames, a <code class="docutils literal notranslate"><span class="pre">TextLineDataset</span></code> will produce one string-valued element per line of those files.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>directory_url = &#39;https://storage.googleapis.com/download.tensorflow.org/data/illiad/&#39;
file_names = [&#39;cowper.txt&#39;, &#39;derby.txt&#39;, &#39;butler.txt&#39;]

file_paths = [
    tf.keras.utils.get_file(file_name, directory_url + file_name)
    for file_name in file_names
]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset = tf.data.TextLineDataset(file_paths)
</pre></div>
</div>
</div>
<p>Here are the first few lines of the first file:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for line in dataset.take(5):
  print(line.numpy())
</pre></div>
</div>
</div>
<p>To alternate lines between files use <code class="docutils literal notranslate"><span class="pre">Dataset.interleave</span></code>. This makes it easier to shuffle files together. Here are the first, second and third lines from each translation:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>files_ds = tf.data.Dataset.from_tensor_slices(file_paths)
lines_ds = files_ds.interleave(tf.data.TextLineDataset, cycle_length=3)

for i, line in enumerate(lines_ds.take(9)):
  if i % 3 == 0:
    print()
  print(line.numpy())
</pre></div>
</div>
</div>
<p>By default, a <code class="docutils literal notranslate"><span class="pre">TextLineDataset</span></code> yields <em>every</em> line of each file, which may not be desirable, for example, if the file starts with a header line, or contains comments. These lines can be removed using the <code class="docutils literal notranslate"><span class="pre">Dataset.skip()</span></code> or <code class="docutils literal notranslate"><span class="pre">Dataset.filter()</span></code> transformations. Here, you skip the first line, then filter to find only survivors.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_file = tf.keras.utils.get_file(&quot;train.csv&quot;, &quot;https://storage.googleapis.com/tf-datasets/titanic/train.csv&quot;)
titanic_lines = tf.data.TextLineDataset(titanic_file)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for line in titanic_lines.take(10):
  print(line.numpy())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def survived(line):
  return tf.not_equal(tf.strings.substr(line, 0, 1), &quot;0&quot;)

survivors = titanic_lines.skip(1).filter(survived)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for line in survivors.take(10):
  print(line.numpy())
</pre></div>
</div>
</div>
</div>
<div class="section" id="Consuming-CSV-data">
<h4>Consuming CSV data<a class="headerlink" href="#Consuming-CSV-data" title="Enlazar permanentemente con este título">¶</a></h4>
<p>See <a class="reference external" href="../tutorials/load_data/csv.ipynb">Loading CSV Files</a>, and <a class="reference external" href="../tutorials/load_data/pandas.ipynb">Loading Pandas DataFrames</a> for more examples.</p>
<p>The CSV file format is a popular format for storing tabular data in plain text.</p>
<p>For example:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_file = tf.keras.utils.get_file(&quot;train.csv&quot;, &quot;https://storage.googleapis.com/tf-datasets/titanic/train.csv&quot;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>df = pd.read_csv(titanic_file)
df.head()
</pre></div>
</div>
</div>
<p>If your data fits in memory the same <code class="docutils literal notranslate"><span class="pre">Dataset.from_tensor_slices</span></code> method works on dictionaries, allowing this data to be easily imported:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_slices = tf.data.Dataset.from_tensor_slices(dict(df))

for feature_batch in titanic_slices.take(1):
  for key, value in feature_batch.items():
    print(&quot;  {!r:20s}: {}&quot;.format(key, value))
</pre></div>
</div>
</div>
<p>A more scalable approach is to load from disk as necessary.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> module provides methods to extract records from one or more CSV files that comply with <a class="reference external" href="https://tools.ietf.org/html/rfc4180">RFC 4180</a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">experimental.make_csv_dataset</span></code> function is the high level interface for reading sets of csv files. It supports column type inference and many other features, like batching and shuffling, to make usage simple.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_batches = tf.data.experimental.make_csv_dataset(
    titanic_file, batch_size=4,
    label_name=&quot;survived&quot;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for feature_batch, label_batch in titanic_batches.take(1):
  print(&quot;&#39;survived&#39;: {}&quot;.format(label_batch))
  print(&quot;features:&quot;)
  for key, value in feature_batch.items():
    print(&quot;  {!r:20s}: {}&quot;.format(key, value))
</pre></div>
</div>
</div>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">select_columns</span></code> argument if you only need a subset of columns.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_batches = tf.data.experimental.make_csv_dataset(
    titanic_file, batch_size=4,
    label_name=&quot;survived&quot;, select_columns=[&#39;class&#39;, &#39;fare&#39;, &#39;survived&#39;])
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for feature_batch, label_batch in titanic_batches.take(1):
  print(&quot;&#39;survived&#39;: {}&quot;.format(label_batch))
  for key, value in feature_batch.items():
    print(&quot;  {!r:20s}: {}&quot;.format(key, value))
</pre></div>
</div>
</div>
<p>There is also a lower-level <code class="docutils literal notranslate"><span class="pre">experimental.CsvDataset</span></code> class which provides finer grained control. It does not support column type inference. Instead you must specify the type of each column.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_types  = [tf.int32, tf.string, tf.float32, tf.int32, tf.int32, tf.float32, tf.string, tf.string, tf.string, tf.string]
dataset = tf.data.experimental.CsvDataset(titanic_file, titanic_types , header=True)

for line in dataset.take(10):
  print([item.numpy() for item in line])
</pre></div>
</div>
</div>
<p>If some columns are empty, this low-level interface allows you to provide default values instead of column types.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%%writefile missing.csv
1,2,3,4
,2,3,4
1,,3,4
1,2,,4
1,2,3,
,,,
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Creates a dataset that reads all of the records from two CSV files, each with
# four float columns which may have missing values.

record_defaults = [999,999,999,999]
dataset = tf.data.experimental.CsvDataset(&quot;missing.csv&quot;, record_defaults)
dataset = dataset.map(lambda *items: tf.stack(items))
dataset
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for line in dataset:
  print(line.numpy())
</pre></div>
</div>
</div>
<p>By default, a <code class="docutils literal notranslate"><span class="pre">CsvDataset</span></code> yields <em>every</em> column of <em>every</em> line of the file, which may not be desirable, for example if the file starts with a header line that should be ignored, or if some columns are not required in the input. These lines and fields can be removed with the <code class="docutils literal notranslate"><span class="pre">header</span></code> and <code class="docutils literal notranslate"><span class="pre">select_cols</span></code> arguments respectively.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Creates a dataset that reads all of the records from two CSV files with
# headers, extracting float data from columns 2 and 4.
record_defaults = [999, 999] # Only provide defaults for the selected columns
dataset = tf.data.experimental.CsvDataset(&quot;missing.csv&quot;, record_defaults, select_cols=[1, 3])
dataset = dataset.map(lambda *items: tf.stack(items))
dataset
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for line in dataset:
  print(line.numpy())
</pre></div>
</div>
</div>
</div>
<div class="section" id="Consuming-sets-of-files">
<h4>Consuming sets of files<a class="headerlink" href="#Consuming-sets-of-files" title="Enlazar permanentemente con este título">¶</a></h4>
<p>There are many datasets distributed as a set of files, where each file is an example.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>flowers_root = tf.keras.utils.get_file(
    &#39;flower_photos&#39;,
    &#39;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&#39;,
    untar=True)
flowers_root = pathlib.Path(flowers_root)

</pre></div>
</div>
</div>
<p>Note: these images are licensed CC-BY, see LICENSE.txt for details.</p>
<p>The root directory contains a directory for each class:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for item in flowers_root.glob(&quot;*&quot;):
  print(item.name)
</pre></div>
</div>
</div>
<p>The files in each class directory are examples:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>list_ds = tf.data.Dataset.list_files(str(flowers_root/&#39;*/*&#39;))

for f in list_ds.take(5):
  print(f.numpy())
</pre></div>
</div>
</div>
<p>Read the data using the <code class="docutils literal notranslate"><span class="pre">tf.io.read_file</span></code> function and extract the label from the path, returning <code class="docutils literal notranslate"><span class="pre">(image,</span> <span class="pre">label)</span></code> pairs:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def process_path(file_path):
  label = tf.strings.split(file_path, os.sep)[-2]
  return tf.io.read_file(file_path), label

labeled_ds = list_ds.map(process_path)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for image_raw, label_text in labeled_ds.take(1):
  print(repr(image_raw.numpy()[:100]))
  print()
  print(label_text.numpy())
</pre></div>
</div>
</div>
<!--
TODO(mrry): Add this section.

### Handling text data with unusual sizes
--></div>
</div>
<div class="section" id="Batching-dataset-elements">
<h3>Batching dataset elements<a class="headerlink" href="#Batching-dataset-elements" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Simple-batching">
<h4>Simple batching<a class="headerlink" href="#Simple-batching" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The simplest form of batching stacks <code class="docutils literal notranslate"><span class="pre">n</span></code> consecutive elements of a dataset into a single element. The <code class="docutils literal notranslate"><span class="pre">Dataset.batch()</span></code> transformation does exactly this, with the same constraints as the <code class="docutils literal notranslate"><span class="pre">tf.stack()</span></code> operator, applied to each component of the elements: i.e. for each component <em>i</em>, all elements must have a tensor of the exact same shape.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>inc_dataset = tf.data.Dataset.range(100)
dec_dataset = tf.data.Dataset.range(0, -100, -1)
dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))
batched_dataset = dataset.batch(4)

for batch in batched_dataset.take(4):
  print([arr.numpy() for arr in batch])
</pre></div>
</div>
</div>
<p>While <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> tries to propagate shape information, the default settings of <code class="docutils literal notranslate"><span class="pre">Dataset.batch</span></code> result in an unknown batch size because the last batch may not be full. Note the <code class="docutils literal notranslate"><span class="pre">None</span></code>s in the shape:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>batched_dataset
</pre></div>
</div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">drop_remainder</span></code> argument to ignore that last batch, and get full shape propagation:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>batched_dataset = dataset.batch(7, drop_remainder=True)
batched_dataset
</pre></div>
</div>
</div>
</div>
<div class="section" id="Batching-tensors-with-padding">
<h4>Batching tensors with padding<a class="headerlink" href="#Batching-tensors-with-padding" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The above recipe works for tensors that all have the same size. However, many models (e.g. sequence models) work with input data that can have varying size (e.g. sequences of different lengths). To handle this case, the <code class="docutils literal notranslate"><span class="pre">Dataset.padded_batch</span></code> transformation enables you to batch tensors of different shape by specifying one or more dimensions in which they may be padded.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset = tf.data.Dataset.range(100)
dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))
dataset = dataset.padded_batch(4, padded_shapes=(None,))

for batch in dataset.take(2):
  print(batch.numpy())
  print()

</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset.padded_batch</span></code> transformation allows you to set different padding for each dimension of each component, and it may be variable-length (signified by <code class="docutils literal notranslate"><span class="pre">None</span></code> in the example above) or constant-length. It is also possible to override the padding value, which defaults to 0.</p>
<!--
TODO(mrry): Add this section.

### Dense ragged -> tf.SparseTensor
--></div>
</div>
<div class="section" id="Training-workflows">
<h3>Training workflows<a class="headerlink" href="#Training-workflows" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Processing-multiple-epochs">
<h4>Processing multiple epochs<a class="headerlink" href="#Processing-multiple-epochs" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API offers two main ways to process multiple epochs of the same data.</p>
<p>The simplest way to iterate over a dataset in multiple epochs is to use the <code class="docutils literal notranslate"><span class="pre">Dataset.repeat()</span></code> transformation. First, create a dataset of titanic data:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_file = tf.keras.utils.get_file(&quot;train.csv&quot;, &quot;https://storage.googleapis.com/tf-datasets/titanic/train.csv&quot;)
titanic_lines = tf.data.TextLineDataset(titanic_file)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def plot_batch_sizes(ds):
  batch_sizes = [batch.shape[0] for batch in ds]
  plt.bar(range(len(batch_sizes)), batch_sizes)
  plt.xlabel(&#39;Batch number&#39;)
  plt.ylabel(&#39;Batch size&#39;)
</pre></div>
</div>
</div>
<p>Applying the <code class="docutils literal notranslate"><span class="pre">Dataset.repeat()</span></code> transformation with no arguments will repeat the input indefinitely.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset.repeat</span></code> transformation concatenates its arguments without signaling the end of one epoch and the beginning of the next epoch. Because of this a <code class="docutils literal notranslate"><span class="pre">Dataset.batch</span></code> applied after <code class="docutils literal notranslate"><span class="pre">Dataset.repeat</span></code> will yield batches that straddle epoch boundaries:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_batches = titanic_lines.repeat(3).batch(128)
plot_batch_sizes(titanic_batches)
</pre></div>
</div>
</div>
<p>If you need clear epoch separation, put <code class="docutils literal notranslate"><span class="pre">Dataset.batch</span></code> before the repeat:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>titanic_batches = titanic_lines.batch(128).repeat(3)

plot_batch_sizes(titanic_batches)
</pre></div>
</div>
</div>
<p>If you would like to perform a custom computation (e.g. to collect statistics) at the end of each epoch then it’s simplest to restart the dataset iteration on each epoch:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>epochs = 3
dataset = titanic_lines.batch(128)

for epoch in range(epochs):
  for batch in dataset:
    print(batch.shape)
  print(&quot;End of epoch: &quot;, epoch)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Randomly-shuffling-input-data">
<h4>Randomly shuffling input data<a class="headerlink" href="#Randomly-shuffling-input-data" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset.shuffle()</span></code> transformation maintains a fixed-size buffer and chooses the next element uniformly at random from that buffer.</p>
<p>Note: While large buffer_sizes shuffle more thoroughly, they can take a lot of memory, and significant time to fill. Consider using <code class="docutils literal notranslate"><span class="pre">Dataset.interleave</span></code> across files if this becomes a problem.</p>
<p>Add an index to the dataset so you can see the effect:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>lines = tf.data.TextLineDataset(titanic_file)
counter = tf.data.experimental.Counter()

dataset = tf.data.Dataset.zip((counter, lines))
dataset = dataset.shuffle(buffer_size=100)
dataset = dataset.batch(20)
dataset
</pre></div>
</div>
</div>
<p>Since the <code class="docutils literal notranslate"><span class="pre">buffer_size</span></code> is 100, and the batch size is 20, the first batch contains no elements with an index over 120.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>n,line_batch = next(iter(dataset))
print(n.numpy())
</pre></div>
</div>
</div>
<p>As with <code class="docutils literal notranslate"><span class="pre">Dataset.batch</span></code> the order relative to <code class="docutils literal notranslate"><span class="pre">Dataset.repeat</span></code> matters.</p>
<p><code class="docutils literal notranslate"><span class="pre">Dataset.shuffle</span></code> doesn’t signal the end of an epoch until the shuffle buffer is empty. So a shuffle placed before a repeat will show every element of one epoch before moving to the next:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset = tf.data.Dataset.zip((counter, lines))
shuffled = dataset.shuffle(buffer_size=100).batch(10).repeat(2)

print(&quot;Here are the item ID&#39;s near the epoch boundary:\n&quot;)
for n, line_batch in shuffled.skip(60).take(5):
  print(n.numpy())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>shuffle_repeat = [n.numpy().mean() for n, line_batch in shuffled]
plt.plot(shuffle_repeat, label=&quot;shuffle().repeat()&quot;)
plt.ylabel(&quot;Mean item ID&quot;)
plt.legend()
</pre></div>
</div>
</div>
<p>But a repeat before a shuffle mixes the epoch boundaries together:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dataset = tf.data.Dataset.zip((counter, lines))
shuffled = dataset.repeat(2).shuffle(buffer_size=100).batch(10)

print(&quot;Here are the item ID&#39;s near the epoch boundary:\n&quot;)
for n, line_batch in shuffled.skip(55).take(15):
  print(n.numpy())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>repeat_shuffle = [n.numpy().mean() for n, line_batch in shuffled]

plt.plot(shuffle_repeat, label=&quot;shuffle().repeat()&quot;)
plt.plot(repeat_shuffle, label=&quot;repeat().shuffle()&quot;)
plt.ylabel(&quot;Mean item ID&quot;)
plt.legend()
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Preprocessing-data">
<h3>Preprocessing data<a class="headerlink" href="#Preprocessing-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset.map(f)</span></code> transformation produces a new dataset by applying a given function <code class="docutils literal notranslate"><span class="pre">f</span></code> to each element of the input dataset. It is based on the <code class="docutils literal notranslate"><span class="pre">`map()</span></code> &lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Map_(higher-order_function)">https://en.wikipedia.org/wiki/Map_(higher-order_function)</a>&gt;`__ function that is commonly applied to lists (and other structures) in functional programming languages. The function <code class="docutils literal notranslate"><span class="pre">f</span></code> takes the <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> objects that represent a single element in the input, and returns the <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> objects that will represent a single
element in the new dataset. Its implementation uses standard TensorFlow operations to transform one element into another.</p>
<p>This section covers common examples of how to use <code class="docutils literal notranslate"><span class="pre">Dataset.map()</span></code>.</p>
<div class="section" id="Decoding-image-data-and-resizing-it">
<h4>Decoding image data and resizing it<a class="headerlink" href="#Decoding-image-data-and-resizing-it" title="Enlazar permanentemente con este título">¶</a></h4>
<!-- TODO(markdaoust): link to image augmentation when it exists --><p>When training a neural network on real-world image data, it is often necessary to convert images of different sizes to a common size, so that they may be batched into a fixed size.</p>
<p>Rebuild the flower filenames dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>list_ds = tf.data.Dataset.list_files(str(flowers_root/&#39;*/*&#39;))
</pre></div>
</div>
</div>
<p>Write a function that manipulates the dataset elements.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Reads an image from a file, decodes it into a dense tensor, and resizes it
# to a fixed shape.
def parse_image(filename):
  parts = tf.strings.split(filename, os.sep)
  label = parts[-2]

  image = tf.io.read_file(filename)
  image = tf.image.decode_jpeg(image)
  image = tf.image.convert_image_dtype(image, tf.float32)
  image = tf.image.resize(image, [128, 128])
  return image, label
</pre></div>
</div>
</div>
<p>Test that it works.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>file_path = next(iter(list_ds))
image, label = parse_image(file_path)

def show(image, label):
  plt.figure()
  plt.imshow(image)
  plt.title(label.numpy().decode(&#39;utf-8&#39;))
  plt.axis(&#39;off&#39;)

show(image, label)
</pre></div>
</div>
</div>
<p>Map it over the dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>images_ds = list_ds.map(parse_image)

for image, label in images_ds.take(2):
  show(image, label)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Applying-arbitrary-Python-logic">
<h4>Applying arbitrary Python logic<a class="headerlink" href="#Applying-arbitrary-Python-logic" title="Enlazar permanentemente con este título">¶</a></h4>
<p>For performance reasons, use TensorFlow operations for preprocessing your data whenever possible. However, it is sometimes useful to call external Python libraries when parsing your input data. You can use the <code class="docutils literal notranslate"><span class="pre">tf.py_function()</span></code> operation in a <code class="docutils literal notranslate"><span class="pre">Dataset.map()</span></code> transformation.</p>
<p>For example, if you want to apply a random rotation, the <code class="docutils literal notranslate"><span class="pre">tf.image</span></code> module only has <code class="docutils literal notranslate"><span class="pre">tf.image.rot90</span></code>, which is not very useful for image augmentation.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">tensorflow_addons</span></code> has a TensorFlow compatible <code class="docutils literal notranslate"><span class="pre">rotate</span></code> in <code class="docutils literal notranslate"><span class="pre">tensorflow_addons.image.rotate</span></code>.</p>
<p>To demonstrate <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code>, try using the <code class="docutils literal notranslate"><span class="pre">scipy.ndimage.rotate</span></code> function instead:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import scipy.ndimage as ndimage

def random_rotate_image(image):
  image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)
  return image
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>image, label = next(iter(images_ds))
image = random_rotate_image(image)
show(image, label)
</pre></div>
</div>
</div>
<p>To use this function with <code class="docutils literal notranslate"><span class="pre">Dataset.map</span></code> the same caveats apply as with <code class="docutils literal notranslate"><span class="pre">Dataset.from_generator</span></code>, you need to describe the return shapes and types when you apply the function:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def tf_random_rotate_image(image, label):
  im_shape = image.shape
  [image,] = tf.py_function(random_rotate_image, [image], [tf.float32])
  image.set_shape(im_shape)
  return image, label
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>rot_ds = images_ds.map(tf_random_rotate_image)

for image, label in rot_ds.take(2):
  show(image, label)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Parsing-tf.Example-protocol-buffer-messages">
<h4>Parsing <code class="docutils literal notranslate"><span class="pre">tf.Example</span></code> protocol buffer messages<a class="headerlink" href="#Parsing-tf.Example-protocol-buffer-messages" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Many input pipelines extract <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code> protocol buffer messages from a TFRecord format. Each <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code> record contains one or more “features”, and the input pipeline typically converts these features into tensors.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>fsns_test_file = tf.keras.utils.get_file(&quot;fsns.tfrec&quot;, &quot;https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001&quot;)
dataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])
dataset
</pre></div>
</div>
</div>
<p>You can work with <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code> protos outside of a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> to understand the data:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>raw_example = next(iter(dataset))
parsed = tf.train.Example.FromString(raw_example.numpy())

feature = parsed.features.feature
raw_img = feature[&#39;image/encoded&#39;].bytes_list.value[0]
img = tf.image.decode_png(raw_img)
plt.imshow(img)
plt.axis(&#39;off&#39;)
_ = plt.title(feature[&quot;image/text&quot;].bytes_list.value[0])
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>raw_example = next(iter(dataset))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def tf_parse(eg):
  example = tf.io.parse_example(
      eg[tf.newaxis], {
          &#39;image/encoded&#39;: tf.io.FixedLenFeature(shape=(), dtype=tf.string),
          &#39;image/text&#39;: tf.io.FixedLenFeature(shape=(), dtype=tf.string)
      })
  return example[&#39;image/encoded&#39;][0], example[&#39;image/text&#39;][0]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>img, txt = tf_parse(raw_example)
print(txt.numpy())
print(repr(img.numpy()[:20]), &quot;...&quot;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>decoded = dataset.map(tf_parse)
decoded
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>image_batch, text_batch = next(iter(decoded.batch(10)))
image_batch.shape
</pre></div>
</div>
</div>
</div>
<div class="section" id="Time-series-windowing">
<h4>Time series windowing<a class="headerlink" href="#Time-series-windowing" title="Enlazar permanentemente con este título">¶</a></h4>
<p>For an end to end time series example see: <a class="reference external" href="../../tutorials/structured_data/time_series.ipynb">Time series forecasting</a>.</p>
<p>Time series data is often organized with the time axis intact.</p>
<p>Use a simple <code class="docutils literal notranslate"><span class="pre">Dataset.range</span></code> to demonstrate:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>range_ds = tf.data.Dataset.range(100000)
</pre></div>
</div>
</div>
<p>Typically, models based on this sort of data will want a contiguous time slice.</p>
<p>The simplest approach would be to batch the data:</p>
<div class="section" id="Using-batch">
<h5>Using <code class="docutils literal notranslate"><span class="pre">batch</span></code><a class="headerlink" href="#Using-batch" title="Enlazar permanentemente con este título">¶</a></h5>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>batches = range_ds.batch(10, drop_remainder=True)

for batch in batches.take(5):
  print(batch.numpy())
</pre></div>
</div>
</div>
<p>Or to make dense predictions one step into the future, you might shift the features and labels by one step relative to each other:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def dense_1_step(batch):
  # Shift features and labels one step relative to each other.
  return batch[:-1], batch[1:]

predict_dense_1_step = batches.map(dense_1_step)

for features, label in predict_dense_1_step.take(3):
  print(features.numpy(), &quot; =&gt; &quot;, label.numpy())
</pre></div>
</div>
</div>
<p>To predict a whole window instead of a fixed offset you can split the batches into two parts:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>batches = range_ds.batch(15, drop_remainder=True)

def label_next_5_steps(batch):
  return (batch[:-5],   # Take the first 5 steps
          batch[-5:])   # take the remainder

predict_5_steps = batches.map(label_next_5_steps)

for features, label in predict_5_steps.take(3):
  print(features.numpy(), &quot; =&gt; &quot;, label.numpy())
</pre></div>
</div>
</div>
<p>To allow some overlap between the features of one batch and the labels of another, use <code class="docutils literal notranslate"><span class="pre">Dataset.zip</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>feature_length = 10
label_length = 3

features = range_ds.batch(feature_length, drop_remainder=True)
labels = range_ds.batch(feature_length).skip(1).map(lambda labels: labels[:label_length])

predicted_steps = tf.data.Dataset.zip((features, labels))

for features, label in predicted_steps.take(5):
  print(features.numpy(), &quot; =&gt; &quot;, label.numpy())
</pre></div>
</div>
</div>
</div>
<div class="section" id="Using-window">
<h5>Using <code class="docutils literal notranslate"><span class="pre">window</span></code><a class="headerlink" href="#Using-window" title="Enlazar permanentemente con este título">¶</a></h5>
<p>While using <code class="docutils literal notranslate"><span class="pre">Dataset.batch</span></code> works, there are situations where you may need finer control. The <code class="docutils literal notranslate"><span class="pre">Dataset.window</span></code> method gives you complete control, but requires some care: it returns a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> of <code class="docutils literal notranslate"><span class="pre">Datasets</span></code>. See <a class="reference external" href="#dataset_structure">Dataset structure</a> for details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>window_size = 5

windows = range_ds.window(window_size, shift=1)
for sub_ds in windows.take(5):
  print(sub_ds)
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Dataset.flat_map</span></code> method can take a dataset of datasets and flatten it into a single dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span> for x in windows.flat_map(lambda x: x).take(30):
   print(x.numpy(), end=&#39; &#39;)
</pre></div>
</div>
</div>
<p>In nearly all cases, you will want to <code class="docutils literal notranslate"><span class="pre">.batch</span></code> the dataset first:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def sub_to_batch(sub):
  return sub.batch(window_size, drop_remainder=True)

for example in windows.flat_map(sub_to_batch).take(5):
  print(example.numpy())
</pre></div>
</div>
</div>
<p>Now, you can see that the <code class="docutils literal notranslate"><span class="pre">shift</span></code> argument controls how much each window moves over.</p>
<p>Putting this together you might write this function:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def make_window_dataset(ds, window_size=5, shift=1, stride=1):
  windows = ds.window(window_size, shift=shift, stride=stride)

  def sub_to_batch(sub):
    return sub.batch(window_size, drop_remainder=True)

  windows = windows.flat_map(sub_to_batch)
  return windows

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>ds = make_window_dataset(range_ds, window_size=10, shift = 5, stride=3)

for example in ds.take(10):
  print(example.numpy())
</pre></div>
</div>
</div>
<p>Then it’s easy to extract labels, as before:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>dense_labels_ds = ds.map(dense_1_step)

for inputs,labels in dense_labels_ds.take(3):
  print(inputs.numpy(), &quot;=&gt;&quot;, labels.numpy())
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Resampling">
<h4>Resampling<a class="headerlink" href="#Resampling" title="Enlazar permanentemente con este título">¶</a></h4>
<p>When working with a dataset that is very class-imbalanced, you may want to resample the dataset. <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> provides two methods to do this. The credit card fraud dataset is a good example of this sort of problem.</p>
<p>Note: See <a class="reference external" href="../tutorials/keras/imbalanced_data.ipynb">Imbalanced Data</a> for a full tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>zip_path = tf.keras.utils.get_file(
    origin=&#39;https://storage.googleapis.com/download.tensorflow.org/data/creditcard.zip&#39;,
    fname=&#39;creditcard.zip&#39;,
    extract=True)

csv_path = zip_path.replace(&#39;.zip&#39;, &#39;.csv&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>creditcard_ds = tf.data.experimental.make_csv_dataset(
    csv_path, batch_size=1024, label_name=&quot;Class&quot;,
    # Set the column types: 30 floats and an int.
    column_defaults=[float()]*30+[int()])
</pre></div>
</div>
</div>
<p>Now, check the distribution of classes, it is highly skewed:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def count(counts, batch):
  features, labels = batch
  class_1 = labels == 1
  class_1 = tf.cast(class_1, tf.int32)

  class_0 = labels == 0
  class_0 = tf.cast(class_0, tf.int32)

  counts[&#39;class_0&#39;] += tf.reduce_sum(class_0)
  counts[&#39;class_1&#39;] += tf.reduce_sum(class_1)

  return counts
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>counts = creditcard_ds.take(10).reduce(
    initial_state={&#39;class_0&#39;: 0, &#39;class_1&#39;: 0},
    reduce_func = count)

counts = np.array([counts[&#39;class_0&#39;].numpy(),
                   counts[&#39;class_1&#39;].numpy()]).astype(np.float32)

fractions = counts/counts.sum()
print(fractions)
</pre></div>
</div>
</div>
<p>A common approach to training with an imbalanced dataset is to balance it. <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> includes a few methods which enable this workflow:</p>
<div class="section" id="Datasets-sampling">
<h5>Datasets sampling<a class="headerlink" href="#Datasets-sampling" title="Enlazar permanentemente con este título">¶</a></h5>
<p>One approach to resampling a dataset is to use <code class="docutils literal notranslate"><span class="pre">sample_from_datasets</span></code>. This is more applicable when you have a separate <code class="docutils literal notranslate"><span class="pre">data.Dataset</span></code> for each class.</p>
<p>Here, just use filter to generate them from the credit card fraud data:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>negative_ds = (
  creditcard_ds
    .unbatch()
    .filter(lambda features, label: label==0)
    .repeat())
positive_ds = (
  creditcard_ds
    .unbatch()
    .filter(lambda features, label: label==1)
    .repeat())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for features, label in positive_ds.batch(10).take(1):
  print(label.numpy())
</pre></div>
</div>
</div>
<p>To use <code class="docutils literal notranslate"><span class="pre">tf.data.experimental.sample_from_datasets</span></code> pass the datasets, and the weight for each:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>balanced_ds = tf.data.experimental.sample_from_datasets(
    [negative_ds, positive_ds], [0.5, 0.5]).batch(10)
</pre></div>
</div>
</div>
<p>Now the dataset produces examples of each class with 50/50 probability:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for features, labels in balanced_ds.take(10):
  print(labels.numpy())
</pre></div>
</div>
</div>
</div>
<div class="section" id="Rejection-resampling">
<h5>Rejection resampling<a class="headerlink" href="#Rejection-resampling" title="Enlazar permanentemente con este título">¶</a></h5>
<p>One problem with the above <code class="docutils literal notranslate"><span class="pre">experimental.sample_from_datasets</span></code> approach is that it needs a separate <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> per class. Using <code class="docutils literal notranslate"><span class="pre">Dataset.filter</span></code> works, but results in all the data being loaded twice.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">data.experimental.rejection_resample</span></code> function can be applied to a dataset to rebalance it, while only loading it once. Elements will be dropped from the dataset to achieve balance.</p>
<p><code class="docutils literal notranslate"><span class="pre">data.experimental.rejection_resample</span></code> takes a <code class="docutils literal notranslate"><span class="pre">class_func</span></code> argument. This <code class="docutils literal notranslate"><span class="pre">class_func</span></code> is applied to each dataset element, and is used to determine which class an example belongs to for the purposes of balancing.</p>
<p>The elements of <code class="docutils literal notranslate"><span class="pre">creditcard_ds</span></code> are already <code class="docutils literal notranslate"><span class="pre">(features,</span> <span class="pre">label)</span></code> pairs. So the <code class="docutils literal notranslate"><span class="pre">class_func</span></code> just needs to return those labels:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>def class_func(features, label):
  return label
</pre></div>
</div>
</div>
<p>The resampler also needs a target distribution, and optionally an initial distribution estimate:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>resampler = tf.data.experimental.rejection_resample(
    class_func, target_dist=[0.5, 0.5], initial_dist=fractions)
</pre></div>
</div>
</div>
<p>The resampler deals with individual examples, so you must <code class="docutils literal notranslate"><span class="pre">unbatch</span></code> the dataset before applying the resampler:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>resample_ds = creditcard_ds.unbatch().apply(resampler).batch(10)
</pre></div>
</div>
</div>
<p>The resampler returns creates <code class="docutils literal notranslate"><span class="pre">(class,</span> <span class="pre">example)</span></code> pairs from the output of the <code class="docutils literal notranslate"><span class="pre">class_func</span></code>. In this case, the <code class="docutils literal notranslate"><span class="pre">example</span></code> was already a <code class="docutils literal notranslate"><span class="pre">(feature,</span> <span class="pre">label)</span></code> pair, so use <code class="docutils literal notranslate"><span class="pre">map</span></code> to drop the extra copy of the labels:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>balanced_ds = resample_ds.map(lambda extra_label, features_and_label: features_and_label)
</pre></div>
</div>
</div>
<p>Now the dataset produces examples of each class with 50/50 probability:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for features, labels in balanced_ds.take(10):
  print(labels.numpy())
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Iterator-Checkpointing">
<h3>Iterator Checkpointing<a class="headerlink" href="#Iterator-Checkpointing" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Tensorflow supports <a class="reference external" href="https://www.tensorflow.org/guide/checkpoint">taking checkpoints</a> so that when your training process restarts it can restore the latest checkpoint to recover most of its progress. In addition to checkpointing the model variables, you can also checkpoint the progress of the dataset iterator. This could be useful if you have a large dataset and don’t want to start the dataset from the beginning on each restart. Note however that iterator checkpoints may be large, since
transformations such as <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> and <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> require buffering elements within the iterator.</p>
<p>To include your iterator in a checkpoint, pass the iterator to the <code class="docutils literal notranslate"><span class="pre">tf.train.Checkpoint</span></code> constructor.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>range_ds = tf.data.Dataset.range(20)

iterator = iter(range_ds)
ckpt = tf.train.Checkpoint(step=tf.Variable(0), iterator=iterator)
manager = tf.train.CheckpointManager(ckpt, &#39;/tmp/my_ckpt&#39;, max_to_keep=3)

print([next(iterator).numpy() for _ in range(5)])

save_path = manager.save()

print([next(iterator).numpy() for _ in range(5)])

ckpt.restore(manager.latest_checkpoint)

print([next(iterator).numpy() for _ in range(5)])
</pre></div>
</div>
</div>
<p>Note: It is not possible to checkpoint an iterator which relies on external state such as a <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code>. Attempting to do so will raise an exception complaining about the external state.</p>
</div>
<div class="section" id="Using-tf.data-with-tf.keras">
<h3>Using tf.data with tf.keras<a class="headerlink" href="#Using-tf.data-with-tf.keras" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.keras</span></code> API simplifies many aspects of creating and executing machine learning models. Its <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">.evaluate()</span></code> and <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> APIs support datasets as inputs. Here is a quick dataset and model setup:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>train, test = tf.keras.datasets.fashion_mnist.load_data()

images, labels = train
images = images/255.0
labels = labels.astype(np.int32)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))
fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)

model = tf.keras.Sequential([
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(10)
])

model.compile(optimizer=&#39;adam&#39;,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=[&#39;accuracy&#39;])
</pre></div>
</div>
</div>
<p>Passing a dataset of <code class="docutils literal notranslate"><span class="pre">(feature,</span> <span class="pre">label)</span></code> pairs is all that’s needed for <code class="docutils literal notranslate"><span class="pre">Model.fit</span></code> and <code class="docutils literal notranslate"><span class="pre">Model.evaluate</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model.fit(fmnist_train_ds, epochs=2)
</pre></div>
</div>
</div>
<p>If you pass an infinite dataset, for example by calling <code class="docutils literal notranslate"><span class="pre">Dataset.repeat()</span></code>, you just need to also pass the <code class="docutils literal notranslate"><span class="pre">steps_per_epoch</span></code> argument:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model.fit(fmnist_train_ds.repeat(), epochs=2, steps_per_epoch=20)
</pre></div>
</div>
</div>
<p>For evaluation you can pass the number of evaluation steps:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>loss, accuracy = model.evaluate(fmnist_train_ds)
print(&quot;Loss :&quot;, loss)
print(&quot;Accuracy :&quot;, accuracy)
</pre></div>
</div>
</div>
<p>For long datasets, set the number of steps to evaluate:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>loss, accuracy = model.evaluate(fmnist_train_ds.repeat(), steps=10)
print(&quot;Loss :&quot;, loss)
print(&quot;Accuracy :&quot;, accuracy)
</pre></div>
</div>
</div>
<p>The labels are not required in when calling <code class="docutils literal notranslate"><span class="pre">Model.predict</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>predict_ds = tf.data.Dataset.from_tensor_slices(images).batch(32)
result = model.predict(predict_ds, steps = 10)
print(result.shape)
</pre></div>
</div>
</div>
<p>But the labels are ignored if you do pass a dataset containing them:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>result = model.predict(fmnist_train_ds, steps = 10)
print(result.shape)
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>