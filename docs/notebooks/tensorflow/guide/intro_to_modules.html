

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Copyright 2020 The TensorFlow Authors. &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Copyright 2020 The TensorFlow Authors.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow/guide/intro_to_modules.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Copyright-2020-The-TensorFlow-Authors.">
<h1>Copyright 2020 The TensorFlow Authors.<a class="headerlink" href="#Copyright-2020-The-TensorFlow-Authors." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
</pre></div>
</div>
</div>
<div class="section" id="Introduction-to-modules,-layers,-and-models">
<h2>Introduction to modules, layers, and models<a class="headerlink" href="#Introduction-to-modules,-layers,-and-models" title="Enlazar permanentemente con este título">¶</a></h2>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>eb5a130f49a0429bb4ac5f55f29e51e1|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>629bea2cba4b49e08c697dc4b4d780d5|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>6ff71dcc7021431789d04e0171c2968c|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>f0d60a7290534a8aac34e95385783129|Download notebook</p>
</td></table><p>To do machine learning in TensorFlow, you are likely to need to define, save, and restore a model.</p>
<p>A model is, abstractly:</p>
<ul class="simple">
<li><p>A function that computes something on tensors (a <strong>forward pass</strong>)</p></li>
<li><p>Some variables that can be updated in response to training</p></li>
</ul>
<p>In this guide, you will go below the surface of Keras to see how TensorFlow models are defined. This looks at how TensorFlow collects variables and models, as well as how they are saved and restored.</p>
<p>Note: If you instead want to immediately get started with Keras, please see <a class="reference external" href="./keras/">the collection of Keras guides</a>.</p>
<div class="section" id="Setup">
<h3>Setup<a class="headerlink" href="#Setup" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import tensorflow as tf
from datetime import datetime

%load_ext tensorboard
</pre></div>
</div>
</div>
</div>
<div class="section" id="Defining-models-and-layers-in-TensorFlow">
<h3>Defining models and layers in TensorFlow<a class="headerlink" href="#Defining-models-and-layers-in-TensorFlow" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Most models are made of layers. Layers are functions with a known mathematical structure that can be reused and have trainable variables. In TensorFlow, most high-level implementations of layers and models, such as Keras or <a class="reference external" href="https://github.com/deepmind/sonnet">Sonnet</a>, are built on the same foundational class: <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>.</p>
<p>Here’s an example of a very simple <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> that operates on a scalar tensor:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class SimpleModule(tf.Module):
  def __init__(self, name=None):
    super().__init__(name=name)
    self.a_variable = tf.Variable(5.0, name=&quot;train_me&quot;)
    self.non_trainable_variable = tf.Variable(5.0, trainable=False, name=&quot;do_not_train_me&quot;)
  def __call__(self, x):
    return self.a_variable * x + self.non_trainable_variable

simple_module = SimpleModule(name=&quot;simple&quot;)

simple_module(tf.constant(5.0))
</pre></div>
</div>
</div>
<p>Modules and, by extension, layers are deep-learning terminology for “objects”: they have internal state, and methods that use that state.</p>
<p>There is nothing special about <code class="docutils literal notranslate"><span class="pre">__call__</span></code> except to act like a <a class="reference external" href="https://stackoverflow.com/questions/111234/what-is-a-callable">Python callable</a>; you can invoke your models with whatever functions you wish.</p>
<p>You can set the trainability of variables on and off for any reason, including freezing layers and variables during fine-tuning.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> is the base class for both <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>, so everything you come across here also applies in Keras. For historical compatibility reasons Keras layers do not collect variables from modules, so your models should use only modules or only Keras layers. However, the methods shown below for inspecting variables are the same in either case.</p>
<p>By subclassing <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>, any <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> or <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> instances assigned to this object’s properties are automatically collected. This allows you to save and load variables, and also create collections of <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>s.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># All trainable variables
print(&quot;trainable variables:&quot;, simple_module.trainable_variables)
# Every variable
print(&quot;all variables:&quot;, simple_module.variables)
</pre></div>
</div>
</div>
<p>This is an example of a two-layer linear layer model made out of modules.</p>
<p>First a dense (linear) layer:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class Dense(tf.Module):
  def __init__(self, in_features, out_features, name=None):
    super().__init__(name=name)
    self.w = tf.Variable(
      tf.random.normal([in_features, out_features]), name=&#39;w&#39;)
    self.b = tf.Variable(tf.zeros([out_features]), name=&#39;b&#39;)
  def __call__(self, x):
    y = tf.matmul(x, self.w) + self.b
    return tf.nn.relu(y)
</pre></div>
</div>
</div>
<p>And then the complete model, which makes two layer instances and applies them:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class SequentialModule(tf.Module):
  def __init__(self, name=None):
    super().__init__(name=name)

    self.dense_1 = Dense(in_features=3, out_features=3)
    self.dense_2 = Dense(in_features=3, out_features=2)

  def __call__(self, x):
    x = self.dense_1(x)
    return self.dense_2(x)

# You have made a model!
my_model = SequentialModule(name=&quot;the_model&quot;)

# Call it, with random results
print(&quot;Model results:&quot;, my_model(tf.constant([[2.0, 2.0, 2.0]])))
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> instances will automatically collect, recursively, any <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> or <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> instances assigned to it. This allows you to manage collections of <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>s with a single model instance, and save and load whole models.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(&quot;Submodules:&quot;, my_model.submodules)

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>for var in my_model.variables:
  print(var, &quot;\n&quot;)
</pre></div>
</div>
</div>
<div class="section" id="Waiting-to-create-variables">
<h4>Waiting to create variables<a class="headerlink" href="#Waiting-to-create-variables" title="Enlazar permanentemente con este título">¶</a></h4>
<p>You may have noticed here that you have to define both input and output sizes to the layer. This is so the <code class="docutils literal notranslate"><span class="pre">w</span></code> variable has a known shape and can be allocated.</p>
<p>By deferring variable creation to the first time the module is called with a specific input shape, you do not need specify the input size up front.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class FlexibleDenseModule(tf.Module):
  # Note: No need for `in_features`
  def __init__(self, out_features, name=None):
    super().__init__(name=name)
    self.is_built = False
    self.out_features = out_features

  def __call__(self, x):
    # Create variables on first call.
    if not self.is_built:
      self.w = tf.Variable(
        tf.random.normal([x.shape[-1], self.out_features]), name=&#39;w&#39;)
      self.b = tf.Variable(tf.zeros([self.out_features]), name=&#39;b&#39;)
      self.is_built = True

    y = tf.matmul(x, self.w) + self.b
    return tf.nn.relu(y)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Used in a module
class MySequentialModule(tf.Module):
  def __init__(self, name=None):
    super().__init__(name=name)

    self.dense_1 = FlexibleDenseModule(out_features=3)
    self.dense_2 = FlexibleDenseModule(out_features=2)

  def __call__(self, x):
    x = self.dense_1(x)
    return self.dense_2(x)

my_model = MySequentialModule(name=&quot;the_model&quot;)
print(&quot;Model results:&quot;, my_model(tf.constant([[2.0, 2.0, 2.0]])))
</pre></div>
</div>
</div>
<p>This flexibility is why TensorFlow layers often only need to specify the shape of their outputs, such as in <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Dense</span></code>, rather than both the input and output size.</p>
</div>
</div>
<div class="section" id="Saving-weights">
<h3>Saving weights<a class="headerlink" href="#Saving-weights" title="Enlazar permanentemente con este título">¶</a></h3>
<p>You can save a <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> as both a <a class="reference internal" href="checkpoint.html"><span class="doc">checkpoint</span></a> and a <a class="reference internal" href="saved_model.html"><span class="doc">SavedModel</span></a>.</p>
<p>Checkpoints are just the weights (that is, the values of the set of variables inside the module and its submodules):</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>chkp_path = &quot;my_checkpoint&quot;
checkpoint = tf.train.Checkpoint(model=my_model)
checkpoint.write(chkp_path)
</pre></div>
</div>
</div>
<p>Checkpoints consist of two kinds of files: the data itself and an index file for metadata. The index file keeps track of what is actually saved and the numbering of checkpoints, while the checkpoint data contains the variable values and their attribute lookup paths.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>!ls my_checkpoint*
</pre></div>
</div>
</div>
<p>You can look inside a checkpoint to be sure the whole collection of variables is saved, sorted by the Python object that contains them.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>tf.train.list_variables(chkp_path)
</pre></div>
</div>
</div>
<p>During distributed (multi-machine) training they can be sharded, which is why they are numbered (e.g., ‘00000-of-00001’). In this case, though, there is only have one shard.</p>
<p>When you load models back in, you overwrite the values in your Python object.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>new_model = MySequentialModule()
new_checkpoint = tf.train.Checkpoint(model=new_model)
new_checkpoint.restore(&quot;my_checkpoint&quot;)

# Should be the same result as above
new_model(tf.constant([[2.0, 2.0, 2.0]]))
</pre></div>
</div>
</div>
<p>Note: As checkpoints are at the heart of long training workflows <code class="docutils literal notranslate"><span class="pre">tf.checkpoint.CheckpointManager</span></code> is a helper class that makes checkpoint management much easier. Refer to the <a class="reference internal" href="checkpoint.html"><span class="doc">Training checkpoints guide</span></a> for more details.</p>
</div>
<div class="section" id="Saving-functions">
<h3>Saving functions<a class="headerlink" href="#Saving-functions" title="Enlazar permanentemente con este título">¶</a></h3>
<p>TensorFlow can run models without the original Python objects, as demonstrated by <a class="reference external" href="https://tensorflow.org/tfx">TensorFlow Serving</a> and <a class="reference external" href="https://tensorflow.org/lite">TensorFlow Lite</a>, even when you download a trained model from <a class="reference external" href="https://tensorflow.org/hub">TensorFlow Hub</a>.</p>
<p>TensorFlow needs to know how to do the computations described in Python, but <strong>without the original code</strong>. To do this, you can make a <strong>graph</strong>, which is described in the <a class="reference internal" href="intro_to_graphs.html"><span class="doc">Introduction to graphs and functions guide</span></a>.</p>
<p>This graph contains operations, or <em>ops</em>, that implement the function.</p>
<p>You can define a graph in the model above by adding the <code class="docutils literal notranslate"><span class="pre">&#64;tf.function</span></code> decorator to indicate that this code should run as a graph.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class MySequentialModule(tf.Module):
  def __init__(self, name=None):
    super().__init__(name=name)

    self.dense_1 = Dense(in_features=3, out_features=3)
    self.dense_2 = Dense(in_features=3, out_features=2)

  @tf.function
  def __call__(self, x):
    x = self.dense_1(x)
    return self.dense_2(x)

# You have made a model with a graph!
my_model = MySequentialModule(name=&quot;the_model&quot;)
</pre></div>
</div>
</div>
<p>The module you have made works exactly the same as before. Each unique signature passed into the function creates a separate graph. Check the <a class="reference internal" href="intro_to_graphs.html"><span class="doc">Introduction to graphs and functions guide</span></a> for details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(my_model([[2.0, 2.0, 2.0]]))
print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))
</pre></div>
</div>
</div>
<p>You can visualize the graph by tracing it within a TensorBoard summary.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Set up logging.
stamp = datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;)
logdir = &quot;logs/func/%s&quot; % stamp
writer = tf.summary.create_file_writer(logdir)

# Create a new model to get a fresh trace
# Otherwise the summary will not see the graph.
new_model = MySequentialModule()

# Bracket the function call with
# tf.summary.trace_on() and tf.summary.trace_export().
tf.summary.trace_on(graph=True)
tf.profiler.experimental.start(logdir)
# Call only one tf.function when tracing.
z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))
with writer.as_default():
  tf.summary.trace_export(
      name=&quot;my_func_trace&quot;,
      step=0,
      profiler_outdir=logdir)
</pre></div>
</div>
</div>
<p>Launch TensorBoard to view the resulting trace:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#docs_infra: no_execute
%tensorboard --logdir logs/func
</pre></div>
</div>
</div>
<p><img alt="A screenshot of the graph in TensorBoard" src="../../../_images/tensorboard_graph.png" /></p>
<div class="section" id="Creating-a-SavedModel">
<h4>Creating a <code class="docutils literal notranslate"><span class="pre">SavedModel</span></code><a class="headerlink" href="#Creating-a-SavedModel" title="Enlazar permanentemente con este título">¶</a></h4>
<p>The recommended way of sharing completely trained models is to use <code class="docutils literal notranslate"><span class="pre">SavedModel</span></code>. <code class="docutils literal notranslate"><span class="pre">SavedModel</span></code> contains both a collection of functions and a collection of weights.</p>
<p>You can save the model you have just trained as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>tf.saved_model.save(my_model, &quot;the_saved_model&quot;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Inspect the SavedModel in the directory
!ls -l the_saved_model
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># The variables/ directory contains a checkpoint of the variables
!ls -l the_saved_model/variables
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">saved_model.pb</span></code> file is a <a class="reference external" href="https://developers.google.com/protocol-buffers">protocol buffer</a> describing the functional <code class="docutils literal notranslate"><span class="pre">tf.Graph</span></code>.</p>
<p>Models and layers can be loaded from this representation without actually making an instance of the class that created it. This is desired in situations where you do not have (or want) a Python interpreter, such as serving at scale or on an edge device, or in situations where the original Python code is not available or practical to use.</p>
<p>You can load the model as new object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>new_model = tf.saved_model.load(&quot;the_saved_model&quot;)
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">new_model</span></code>, created from loading a saved model, is an internal TensorFlow user object without any of the class knowledge. It is not of type <code class="docutils literal notranslate"><span class="pre">SequentialModule</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>isinstance(new_model, SequentialModule)
</pre></div>
</div>
</div>
<p>This new model works on the already-defined input signatures. You can’t add more signatures to a model restored like this.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(my_model([[2.0, 2.0, 2.0]]))
print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))
</pre></div>
</div>
</div>
<p>Thus, using <code class="docutils literal notranslate"><span class="pre">SavedModel</span></code>, you are able to save TensorFlow weights and graphs using <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>, and then load them again.</p>
</div>
</div>
<div class="section" id="Keras-models-and-layers">
<h3>Keras models and layers<a class="headerlink" href="#Keras-models-and-layers" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Note that up until this point, there is no mention of Keras. You can build your own high-level API on top of <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>, and people have.</p>
<p>In this section, you will examine how Keras uses <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>. A complete user guide to Keras models can be found in the <a class="reference external" href="keras/sequential_model.ipynb">Keras guide</a>.</p>
<div class="section" id="Keras-layers">
<h4>Keras layers<a class="headerlink" href="#Keras-layers" title="Enlazar permanentemente con este título">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code> is the base class of all Keras layers, and it inherits from <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>.</p>
<p>You can convert a module into a Keras layer just by swapping out the parent and then changing <code class="docutils literal notranslate"><span class="pre">__call__</span></code> to <code class="docutils literal notranslate"><span class="pre">call</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class MyDense(tf.keras.layers.Layer):
  # Adding **kwargs to support base Keras layer arguments
  def __init__(self, in_features, out_features, **kwargs):
    super().__init__(**kwargs)

    # This will soon move to the build step; see below
    self.w = tf.Variable(
      tf.random.normal([in_features, out_features]), name=&#39;w&#39;)
    self.b = tf.Variable(tf.zeros([out_features]), name=&#39;b&#39;)
  def call(self, x):
    y = tf.matmul(x, self.w) + self.b
    return tf.nn.relu(y)

simple_layer = MyDense(name=&quot;simple&quot;, in_features=3, out_features=3)
</pre></div>
</div>
</div>
<p>Keras layers have their own <code class="docutils literal notranslate"><span class="pre">__call__</span></code> that does some bookkeeping described in the next section and then calls <code class="docutils literal notranslate"><span class="pre">call()</span></code>. You should notice no change in functionality.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>simple_layer([[2.0, 2.0, 2.0]])
</pre></div>
</div>
</div>
</div>
<div class="section" id="The-build-step">
<h4>The <code class="docutils literal notranslate"><span class="pre">build</span></code> step<a class="headerlink" href="#The-build-step" title="Enlazar permanentemente con este título">¶</a></h4>
<p>As noted, it’s convenient in many cases to wait to create variables until you are sure of the input shape.</p>
<p>Keras layers come with an extra lifecycle step that allows you more flexibility in how you define your layers. This is defined in the <code class="docutils literal notranslate"><span class="pre">build</span></code> function.</p>
<p><code class="docutils literal notranslate"><span class="pre">build</span></code> is called exactly once, and it is called with the shape of the input. It’s usually used to create variables (weights).</p>
<p>You can rewrite <code class="docutils literal notranslate"><span class="pre">MyDense</span></code> layer above to be flexible to the size of its inputs:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class FlexibleDense(tf.keras.layers.Layer):
  # Note the added `**kwargs`, as Keras supports many arguments
  def __init__(self, out_features, **kwargs):
    super().__init__(**kwargs)
    self.out_features = out_features

  def build(self, input_shape):  # Create the state of the layer (weights)
    self.w = tf.Variable(
      tf.random.normal([input_shape[-1], self.out_features]), name=&#39;w&#39;)
    self.b = tf.Variable(tf.zeros([self.out_features]), name=&#39;b&#39;)

  def call(self, inputs):  # Defines the computation from inputs to outputs
    return tf.matmul(inputs, self.w) + self.b

# Create the instance of the layer
flexible_dense = FlexibleDense(out_features=3)
</pre></div>
</div>
</div>
<p>At this point, the model has not been built, so there are no variables:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>flexible_dense.variables
</pre></div>
</div>
</div>
<p>Calling the function allocates appropriately-sized variables:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Call it, with predictably random results
print(&quot;Model results:&quot;, flexible_dense(tf.constant([[2.0, 2.0, 2.0], [3.0, 3.0, 3.0]])))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>flexible_dense.variables
</pre></div>
</div>
</div>
<p>Since <code class="docutils literal notranslate"><span class="pre">build</span></code> is only called once, inputs will be rejected if the input shape is not compatible with the layer’s variables:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>try:
  print(&quot;Model results:&quot;, flexible_dense(tf.constant([[2.0, 2.0, 2.0, 2.0]])))
except tf.errors.InvalidArgumentError as e:
  print(&quot;Failed:&quot;, e)
</pre></div>
</div>
</div>
<p>Keras layers have a lot more extra features including:</p>
<ul class="simple">
<li><p>Optional losses</p></li>
<li><p>Support for metrics</p></li>
<li><p>Built-in support for an optional <code class="docutils literal notranslate"><span class="pre">training</span></code> argument to differentiate between training and inference use</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_config</span></code> and <code class="docutils literal notranslate"><span class="pre">from_config</span></code> methods that allow you to accurately store configurations to allow model cloning in Python</p></li>
</ul>
<p>Read about them in the <a class="reference external" href="./keras/custom_layers_and_models.ipynb">full guide</a> to custom layers and models.</p>
</div>
<div class="section" id="Keras-models">
<h4>Keras models<a class="headerlink" href="#Keras-models" title="Enlazar permanentemente con este título">¶</a></h4>
<p>You can define your model as nested Keras layers.</p>
<p>However, Keras also provides a full-featured model class called <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>. It inherits from <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code>, so a Keras model can be used, nested, and saved in the same way as Keras layers. Keras models come with extra functionality that makes them easy to train, evaluate, load, save, and even train on multiple machines.</p>
<p>You can define the <code class="docutils literal notranslate"><span class="pre">SequentialModule</span></code> from above with nearly identical code, again converting <code class="docutils literal notranslate"><span class="pre">__call__</span></code> to <code class="docutils literal notranslate"><span class="pre">call()</span></code> and changing the parent:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>class MySequentialModel(tf.keras.Model):
  def __init__(self, name=None, **kwargs):
    super().__init__(**kwargs)

    self.dense_1 = FlexibleDense(out_features=3)
    self.dense_2 = FlexibleDense(out_features=2)
  def call(self, x):
    x = self.dense_1(x)
    return self.dense_2(x)

# You have made a Keras model!
my_sequential_model = MySequentialModel(name=&quot;the_model&quot;)

# Call it on a tensor, with random results
print(&quot;Model results:&quot;, my_sequential_model(tf.constant([[2.0, 2.0, 2.0]])))

</pre></div>
</div>
</div>
<p>All the same features are available, including tracking variables and submodules.</p>
<p>Note: To emphasize the note above, a raw <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> nested inside a Keras layer or model will not get its variables collected for training or saving. Instead, nest Keras layers inside of Keras layers.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>my_sequential_model.variables
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>my_sequential_model.submodules
</pre></div>
</div>
</div>
<p>Overriding <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> is a very Pythonic approach to building TensorFlow models. If you are migrating models from other frameworks, this can be very straightforward.</p>
<p>If you are constructing models that are simple assemblages of existing layers and inputs, you can save time and space by using the <a class="reference external" href="./keras/functional.ipynb">functional API</a>, which comes with additional features around model reconstruction and architecture.</p>
<p>Here is the same model with the functional API:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>inputs = tf.keras.Input(shape=[3,])

x = FlexibleDense(3)(inputs)
x = FlexibleDense(2)(x)

my_functional_model = tf.keras.Model(inputs=inputs, outputs=x)

my_functional_model.summary()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>my_functional_model(tf.constant([[2.0, 2.0, 2.0]]))
</pre></div>
</div>
</div>
<p>The major difference here is that the input shape is specified up front as part of the functional construction process. The <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> argument in this case does not have to be completely specified; you can leave some dimensions as <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p>Note: You do not need to specify <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> or an <code class="docutils literal notranslate"><span class="pre">InputLayer</span></code> in a subclassed model; these arguments and layers will be ignored.</p>
</div>
</div>
<div class="section" id="Saving-Keras-models">
<h3>Saving Keras models<a class="headerlink" href="#Saving-Keras-models" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Keras models can be checkpointed, and that will look the same as <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>.</p>
<p>Keras models can also be saved with <code class="docutils literal notranslate"><span class="pre">tf.saved_models.save()</span></code>, as they are modules. However, Keras models have convenience methods and other functionality:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>my_sequential_model.save(&quot;exname_of_file&quot;)
</pre></div>
</div>
</div>
<p>Just as easily, they can be loaded back in:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>reconstructed_model = tf.keras.models.load_model(&quot;exname_of_file&quot;)
</pre></div>
</div>
</div>
<p>Keras <code class="docutils literal notranslate"><span class="pre">SavedModels</span></code> also save metric, loss, and optimizer states.</p>
<p>This reconstructed model can be used and will produce the same result when called on the same data:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>reconstructed_model(tf.constant([[2.0, 2.0, 2.0]]))
</pre></div>
</div>
</div>
<p>There is more to know about saving and serialization of Keras models, including providing configuration methods for custom layers for feature support. Check out the <a class="reference external" href="keras/save_and_serialize">guide to saving and serialization</a>.</p>
</div>
</div>
<div class="section" id="What’s-next">
<h2>What’s next<a class="headerlink" href="#What’s-next" title="Enlazar permanentemente con este título">¶</a></h2>
<p>If you want to know more details about Keras, you can follow the existing Keras guides <a class="reference external" href="./keras/">here</a>.</p>
<p>Another example of a high-level API built on <code class="docutils literal notranslate"><span class="pre">tf.module</span></code> is Sonnet from DeepMind, which is covered on <a class="reference external" href="https://github.com/deepmind/sonnet">their site</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>