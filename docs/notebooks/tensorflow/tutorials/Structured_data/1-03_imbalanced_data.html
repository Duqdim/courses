

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Classification on imbalanced data &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" />
    <link rel="next" title="Time series forecasting" href="1-04_time_series.html" />
    <link rel="prev" title="Classify structured data using Keras Preprocessing Layers" href="1-02_preprocessing_layers.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/content.html">Sesiones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/course-info.html">Información del curso</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/programming-labs.html">Laboratorios de programación</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/complement.html">Material Complementario</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a> &raquo;</li>
        
          <li><a href="../../../../redes-neuronales-con-tensorflow/content.html">Sesiones</a> &raquo;</li>
        
      <li>Classification on imbalanced data</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Structured_data/1-03_imbalanced_data.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Classification-on-imbalanced-data">
<h1>Classification on imbalanced data<a class="headerlink" href="#Classification-on-imbalanced-data" title="Enlazar permanentemente con este título">¶</a></h1>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>65b6480d819547ce958d90f4f1b2f376|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>690f46b2e552496f9aab89a06aa0d578|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>86051f4cbead4de9a75acc14821dd7b1|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>700e86fa85d547259a5135cd3431e88f|Download notebook</p>
</td></table><p>This tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the <a class="reference external" href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Credit Card Fraud Detection</a> dataset hosted on Kaggle. The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. You will use <a class="reference external" href="../../guide/keras/overview.ipynb">Keras</a> to define the model and <a class="reference external" href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model">class
weights</a> to help the model learn from the imbalanced data. .</p>
<p>This tutorial contains complete code to:</p>
<ul class="simple">
<li><p>Load a CSV file using Pandas.</p></li>
<li><p>Create train, validation, and test sets.</p></li>
<li><p>Define and train a model using Keras (including setting class weights).</p></li>
<li><p>Evaluate the model using various metrics (including precision and recall).</p></li>
<li><p>Try common techniques for dealing with imbalanced data like:</p>
<ul>
<li><p>Class weighting</p></li>
<li><p>Oversampling</p></li>
</ul>
</li>
</ul>
<div class="section" id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.prop_cycle&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">by_key</span><span class="p">()[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-processing-and-exploration">
<h2>Data processing and exploration<a class="headerlink" href="#Data-processing-and-exploration" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Download-the-Kaggle-Credit-Card-Fraud-data-set">
<h3>Download the Kaggle Credit Card Fraud data set<a class="headerlink" href="#Download-the-Kaggle-Credit-Card-Fraud-data-set" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Pandas is a Python library with many helpful utilities for loading and working with structured data and can be used to download CSVs into a dataframe.</p>
<p>Note: This dataset has been collected and analysed during a research collaboration of Worldline and the <a class="reference external" href="http://mlg.ulb.ac.be">Machine Learning Group</a> of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available <a class="reference external" href="https://www.researchgate.net/project/Fraud-detection-5">here</a> and the page of the
<a class="reference external" href="https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/">DefeatFraud</a> project</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">file</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span>
<span class="n">raw_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv&#39;</span><span class="p">)</span>
<span class="n">raw_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">raw_df</span><span class="p">[[</span><span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="s1">&#39;V1&#39;</span><span class="p">,</span> <span class="s1">&#39;V2&#39;</span><span class="p">,</span> <span class="s1">&#39;V3&#39;</span><span class="p">,</span> <span class="s1">&#39;V4&#39;</span><span class="p">,</span> <span class="s1">&#39;V5&#39;</span><span class="p">,</span> <span class="s1">&#39;V26&#39;</span><span class="p">,</span> <span class="s1">&#39;V27&#39;</span><span class="p">,</span> <span class="s1">&#39;V28&#39;</span><span class="p">,</span> <span class="s1">&#39;Amount&#39;</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Examine-the-class-label-imbalance">
<h3>Examine the class label imbalance<a class="headerlink" href="#Examine-the-class-label-imbalance" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Let’s look at the dataset imbalance:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">raw_df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">])</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">neg</span> <span class="o">+</span> <span class="n">pos</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Examples:</span><span class="se">\n</span><span class="s1">    Total: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">    Positive: </span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.2f}% o</span><span class="s1">f total)</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">total</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">pos</span> <span class="o">/</span> <span class="n">total</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>This shows the small fraction of positive samples.</p>
</div>
<div class="section" id="Clean,-split-and-normalize-the-data">
<h3>Clean, split and normalize the data<a class="headerlink" href="#Clean,-split-and-normalize-the-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The raw data has a few issues. First the <code class="docutils literal notranslate"><span class="pre">Time</span></code> and <code class="docutils literal notranslate"><span class="pre">Amount</span></code> columns are too variable to use directly. Drop the <code class="docutils literal notranslate"><span class="pre">Time</span></code> column (since it’s not clear what it means) and take the log of the <code class="docutils literal notranslate"><span class="pre">Amount</span></code> column to reduce its range.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cleaned_df</span> <span class="o">=</span> <span class="n">raw_df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># You don&#39;t want the `Time` column.</span>
<span class="n">cleaned_df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>

<span class="c1"># The `Amount` column covers a huge range. Convert to log-space.</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1"># 0 =&gt; 0.1¢</span>
<span class="n">cleaned_df</span><span class="p">[</span><span class="s1">&#39;Log Ammount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cleaned_df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;Amount&#39;</span><span class="p">)</span><span class="o">+</span><span class="n">eps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Split the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where
<a class="reference external" href="https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting">overfitting</a> is a significant concern from the lack of training data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Use a utility from sklearn to split and shuffle our dataset.</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cleaned_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">val_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Form np arrays of labels and features.</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">))</span>
<span class="n">bool_train_labels</span> <span class="o">=</span> <span class="n">train_labels</span> <span class="o">!=</span> <span class="mi">0</span>
<span class="n">val_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">))</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">))</span>

<span class="n">train_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
<span class="n">val_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_df</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1.</p>
<p>Note: The <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> is only fit using the <code class="docutils literal notranslate"><span class="pre">train_features</span></code> to be sure the model is not peeking at the validation or test sets.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_features</span><span class="p">)</span>

<span class="n">val_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">val_features</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>

<span class="n">train_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">val_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">val_features</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training labels shape:&#39;</span><span class="p">,</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation labels shape:&#39;</span><span class="p">,</span> <span class="n">val_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test labels shape:&#39;</span><span class="p">,</span> <span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training features shape:&#39;</span><span class="p">,</span> <span class="n">train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation features shape:&#39;</span><span class="p">,</span> <span class="n">val_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test features shape:&#39;</span><span class="p">,</span> <span class="n">test_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

</pre></div>
</div>
</div>
<p>Caution: If you want to deploy a model, it’s critical that you preserve the preprocessing calculations. The easiest way to implement them as layers, and attach them to your model before export.</p>
</div>
<div class="section" id="Look-at-the-data-distribution">
<h3>Look at the data distribution<a class="headerlink" href="#Look-at-the-data-distribution" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Next compare the distributions of the positive and negative examples over a few features. Good questions to ask yourself at this point are:</p>
<ul class="simple">
<li><p>Do these distributions make sense?</p>
<ul>
<li><p>Yes. You’ve normalized the input and these are mostly concentrated in the <code class="docutils literal notranslate"><span class="pre">+/-</span> <span class="pre">2</span></code> range.</p></li>
</ul>
</li>
<li><p>Can you see the difference between the distributions?</p>
<ul>
<li><p>Yes the positive examples contain a much higher rate of extreme values.</p></li>
</ul>
</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pos_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_features</span><span class="p">[</span> <span class="n">bool_train_labels</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">train_df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">neg_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_features</span><span class="p">[</span><span class="o">~</span><span class="n">bool_train_labels</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">train_df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">pos_df</span><span class="p">[</span><span class="s1">&#39;V5&#39;</span><span class="p">],</span> <span class="n">pos_df</span><span class="p">[</span><span class="s1">&#39;V6&#39;</span><span class="p">],</span>
              <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;hex&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Positive distribution&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">neg_df</span><span class="p">[</span><span class="s1">&#39;V5&#39;</span><span class="p">],</span> <span class="n">neg_df</span><span class="p">[</span><span class="s1">&#39;V6&#39;</span><span class="p">],</span>
              <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;hex&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Negative distribution&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Define-the-model-and-metrics">
<h2>Define the model and metrics<a class="headerlink" href="#Define-the-model-and-metrics" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Define a function that creates a simple neural network with a densly connected hidden layer, a <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#dropout_regularization">dropout</a> layer to reduce overfitting, and an output sigmoid layer that returns the probability of a transaction being fraudulent:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">METRICS</span> <span class="o">=</span> <span class="p">[</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">TruePositives</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;tp&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FalsePositives</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fp&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">TrueNegatives</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;tn&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FalseNegatives</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fn&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Precision</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;precision&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Recall</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">AUC</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;auc&#39;</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">AUC</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;prc&#39;</span><span class="p">,</span> <span class="n">curve</span><span class="o">=</span><span class="s1">&#39;PR&#39;</span><span class="p">),</span> <span class="c1"># precision-recall curve</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">make_model</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">METRICS</span><span class="p">,</span> <span class="n">output_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">output_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">output_bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">output_bias</span><span class="p">)</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
          <span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
          <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
      <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span>
                         <span class="n">bias_initializer</span><span class="o">=</span><span class="n">output_bias</span><span class="p">),</span>
  <span class="p">])</span>

  <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
      <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
      <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>
      <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
<div class="section" id="Understanding-useful-metrics">
<h3>Understanding useful metrics<a class="headerlink" href="#Understanding-useful-metrics" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Notice that there are a few metrics defined above that can be computed by the model that will be helpful when evaluating the performance.</p>
<ul class="simple">
<li><p><strong>False</strong> negatives and <strong>false</strong> positives are samples that were <strong>incorrectly</strong> classified</p></li>
<li><p><strong>True</strong> negatives and <strong>true</strong> positives are samples that were <strong>correctly</strong> classified</p></li>
<li><p><strong>Accuracy</strong> is the percentage of examples correctly classified &gt; <span class="math notranslate nohighlight">\(\frac{\text{true samples}}{\text{total samples}}\)</span></p></li>
<li><p><strong>Precision</strong> is the percentage of <strong>predicted</strong> positives that were correctly classified &gt; <span class="math notranslate nohighlight">\(\frac{\text{true positives}}{\text{true positives + false positives}}\)</span></p></li>
<li><p><strong>Recall</strong> is the percentage of <strong>actual</strong> positives that were correctly classified &gt; <span class="math notranslate nohighlight">\(\frac{\text{true positives}}{\text{true positives + false negatives}}\)</span></p></li>
<li><p><strong>AUC</strong> refers to the Area Under the Curve of a Receiver Operating Characteristic curve (ROC-AUC). This metric is equal to the probability that a classifier will rank a random positive sample higher than a random negative sample.</p></li>
<li><p><strong>AUPRC</strong> refers to Area Under the Curve of the Precision-Recall Curve. This metric computes precision-recall pairs for different probability thresholds.</p></li>
</ul>
<p>Note: Accuracy is not a helpful metric for this task. You can 99.8%+ accuracy on this task by predicting False all the time.</p>
<p>Read more: * <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative">True vs. False and Positive vs. Negative</a> * <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/classification/accuracy">Accuracy</a> * <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall">Precision and Recall</a> * <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc">ROC-AUC</a> *
<a class="reference external" href="https://www.biostat.wisc.edu/~page/rocpr.pdf">Relationship between Precision-Recall and ROC Curves</a></p>
</div>
</div>
<div class="section" id="Baseline-model">
<h2>Baseline model<a class="headerlink" href="#Baseline-model" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Build-the-model">
<h3>Build the model<a class="headerlink" href="#Build-the-model" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Now create and train your model using the function that was defined earlier. Notice that the model is fit using a larger than default batch size of 2048, this is important to ensure that each batch has a decent chance of containing a few positive samples. If the batch size was too small, they would likely have no fraudulent transactions to learn from.</p>
<p>Note: this model will not handle the class imbalance well. You will improve it later in this tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">2048</span>

<span class="n">early_stopping</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_prc&#39;</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span>
    <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Test run the model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_features</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Optional:-Set-the-correct-initial-bias.">
<h3>Optional: Set the correct initial bias.<a class="headerlink" href="#Optional:-Set-the-correct-initial-bias." title="Enlazar permanentemente con este título">¶</a></h3>
<p>These initial guesses are not great. You know the dataset is imbalanced. Set the output layer’s bias to reflect that (See: <a class="reference external" href="http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines">A Recipe for Training Neural Networks: “init well”</a>). This can help with initial convergence.</p>
<p>With the default bias initialization the loss should be about <code class="docutils literal notranslate"><span class="pre">math.log(2)</span> <span class="pre">=</span> <span class="pre">0.69314</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss: </span><span class="si">{:0.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<p>The correct bias to set can be derived from:</p>
<div class="math notranslate nohighlight">
\[p_0 = pos/(pos + neg) = 1/(1+e^{-b_0})\]</div>
<div class="math notranslate nohighlight">
\[b_0 = -log_e(1/p_0 - 1)\]</div>
<div class="math notranslate nohighlight">
\[b_0 = log_e(pos/neg)\]</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">initial_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">([</span><span class="n">pos</span><span class="o">/</span><span class="n">neg</span><span class="p">])</span>
<span class="n">initial_bias</span>
</pre></div>
</div>
</div>
<p>Set that as the initial bias, and the model will give much more reasonable initial guesses.</p>
<p>It should be near: <code class="docutils literal notranslate"><span class="pre">pos/total</span> <span class="pre">=</span> <span class="pre">0.0018</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">output_bias</span><span class="o">=</span><span class="n">initial_bias</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_features</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>With this initialization the initial loss should be approximately:</p>
<div class="math notranslate nohighlight">
\[-p_0log(p_0)-(1-p_0)log(1-p_0) = 0.01317\]</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss: </span><span class="si">{:0.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<p>This initial loss is about 50 times less than if would have been with naive initialization.</p>
<p>This way the model doesn’t need to spend the first few epochs just learning that positive examples are unlikely. This also makes it easier to read plots of the loss during training.</p>
</div>
<div class="section" id="Checkpoint-the-initial-weights">
<h3>Checkpoint the initial weights<a class="headerlink" href="#Checkpoint-the-initial-weights" title="Enlazar permanentemente con este título">¶</a></h3>
<p>To make the various training runs more comparable, keep this initial model’s weights in a checkpoint file, and load them into each model before training.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">initial_weights</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">(),</span> <span class="s1">&#39;initial_weights&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Confirm-that-the-bias-fix-helps">
<h3>Confirm that the bias fix helps<a class="headerlink" href="#Confirm-that-the-bias-fix-helps" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Before moving on, confirm quick that the careful bias initialization actually helped.</p>
<p>Train the model for 20 epochs, with and without this careful initialization, and compare the losses:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">assign</span><span class="p">([</span><span class="mf">0.0</span><span class="p">])</span>
<span class="n">zero_bias_history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_features</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
<span class="n">careful_bias_history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_features</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_loss</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
  <span class="c1"># Use a log scale on y-axis to show the wide range of values.</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
               <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train &#39;</span> <span class="o">+</span> <span class="n">label</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span>
               <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val &#39;</span> <span class="o">+</span> <span class="n">label</span><span class="p">,</span>
               <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_loss</span><span class="p">(</span><span class="n">zero_bias_history</span><span class="p">,</span> <span class="s2">&quot;Zero Bias&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">plot_loss</span><span class="p">(</span><span class="n">careful_bias_history</span><span class="p">,</span> <span class="s2">&quot;Careful Bias&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The above figure makes it clear: In terms of validation loss, on this problem, this careful initialization gives a clear advantage.</p>
</div>
<div class="section" id="Train-the-model">
<h3>Train the model<a class="headerlink" href="#Train-the-model" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
<span class="n">baseline_history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_features</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">],</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Check-training-history">
<h3>Check training history<a class="headerlink" href="#Check-training-history" title="Enlazar permanentemente con este título">¶</a></h3>
<p>In this section, you will produce plots of your model’s accuracy and loss on the training and validation set. These are useful to check for overfitting, which you can learn more about in this <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/overfit_and_underfit">tutorial</a>.</p>
<p>Additionally, you can produce these plots for any of the metrics you created above. False negatives are included as an example.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_metrics</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
  <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="s1">&#39;prc&#39;</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="n">metric</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_&#39;</span><span class="o">+</span><span class="n">metric</span><span class="p">],</span>
             <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">()[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;auc&#39;</span><span class="p">:</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_metrics</span><span class="p">(</span><span class="n">baseline_history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note: That the validation curve generally performs better than the training curve. This is mainly caused by the fact that the dropout layer is not active when evaluating the model.</p>
</div>
<div class="section" id="Evaluate-metrics">
<h3>Evaluate metrics<a class="headerlink" href="#Evaluate-metrics" title="Enlazar permanentemente con este título">¶</a></h3>
<p>You can use a <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#confusion_matrix">confusion matrix</a> to summarize the actual vs. predicted labels where the X axis is the predicted label and the Y axis is the actual label.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_predictions_baseline</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">test_predictions_baseline</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_cm</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
  <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">&gt;</span> <span class="n">p</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix @</span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual label&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted label&#39;</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Legitimate Transactions Detected (True Negatives): &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Legitimate Transactions Incorrectly Detected (False Positives): &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fraudulent Transactions Missed (False Negatives): &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fraudulent Transactions Detected (True Positives): &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Fraudulent Transactions: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<p>Evaluate your model on the test dataset and display the results for the metrics you created above.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">baseline_results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span>
                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">baseline_results</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;: &#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">plot_cm</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_baseline</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If the model had predicted everything perfectly, this would be a <a class="reference external" href="https://en.wikipedia.org/wiki/Diagonal_matrix">diagonal matrix</a> where values off the main diagonal, indicating incorrect predictions, would be zero. In this case the matrix shows that you have relatively few false positives, meaning that there were relatively few legitimate transactions that were incorrectly flagged. However, you would likely want to have even fewer false negatives despite the cost of increasing the number of
false positives. This trade off may be preferable because false negatives would allow fraudulent transactions to go through, whereas false positives may cause an email to be sent to a customer to ask them to verify their card activity.</p>
</div>
<div class="section" id="Plot-the-ROC">
<h3>Plot the ROC<a class="headerlink" href="#Plot-the-ROC" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Now plot the <a class="reference external" href="https://developers.google.com/machine-learning/glossary#ROC">ROC</a>. This plot is useful because it shows, at a glance, the range of performance the model can reach just by tuning the output threshold.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_roc</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">fp</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">fp</span><span class="p">,</span> <span class="mi">100</span><span class="o">*</span><span class="n">tp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False positives [%]&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True positives [%]&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">20</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">80</span><span class="p">,</span><span class="mf">100.5</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Train Baseline&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Test Baseline&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id9">
<h3>Plot the ROC<a class="headerlink" href="#id9" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Now plot the <a class="reference external" href="https://developers.google.com/machine-learning/glossary?hl=en#PR_AUC">AUPRC</a>. Area under the interpolated precision-recall curve, obtained by plotting (recall, precision) points for different values of the classification threshold. Depending on how it’s calculated, PR AUC may be equivalent to the average precision of the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_prc</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Train Baseline&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Test Baseline&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>It looks like the precision is relatively high, but the recall and the area under the ROC curve (AUC) aren’t as high as you might like. Classifiers often face challenges when trying to maximize both precision and recall, which is especially true when working with imbalanced datasets. It is important to consider the costs of different types of errors in the context of the problem you care about. In this example, a false negative (a fraudulent transaction is missed) may have a financial cost,
while a false positive (a transaction is incorrectly flagged as fraudulent) may decrease user happiness.</p>
</div>
</div>
<div class="section" id="Class-weights">
<h2>Class weights<a class="headerlink" href="#Class-weights" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Calculate-class-weights">
<h3>Calculate class weights<a class="headerlink" href="#Calculate-class-weights" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The goal is to identify fraudulent transactions, but you don’t have very many of those positive samples to work with, so you would want to have the classifier heavily weight the few examples that are available. You can do this by passing Keras weights for each class through a parameter. These will cause the model to “pay more attention” to examples from an under-represented class.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Scaling by total/2 helps keep the loss to a similar magnitude.</span>
<span class="c1"># The sum of the weights of all examples stays the same.</span>
<span class="n">weight_for_0</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">neg</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">total</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span>
<span class="n">weight_for_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">pos</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">total</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span>

<span class="n">class_weight</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">weight_for_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="n">weight_for_1</span><span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weight for class 0: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_for_0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weight for class 1: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_for_1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Train-a-model-with-class-weights">
<h3>Train a model with class weights<a class="headerlink" href="#Train-a-model-with-class-weights" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Now try re-training and evaluating the model with class weights to see how that affects the predictions.</p>
<p>Note: Using <code class="docutils literal notranslate"><span class="pre">class_weights</span></code> changes the range of the loss. This may affect the stability of the training depending on the optimizer. Optimizers whose step size is dependent on the magnitude of the gradient, like <code class="docutils literal notranslate"><span class="pre">optimizers.SGD</span></code>, may fail. The optimizer used here, <code class="docutils literal notranslate"><span class="pre">optimizers.Adam</span></code>, is unaffected by the scaling change. Also note that because of the weighting, the total losses are not comparable between the two models.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">weighted_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">weighted_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>

<span class="n">weighted_history</span> <span class="o">=</span> <span class="n">weighted_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_features</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">],</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
    <span class="c1"># The class weights go here</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id10">
<h3>Check training history<a class="headerlink" href="#id10" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_metrics</span><span class="p">(</span><span class="n">weighted_history</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id11">
<h3>Evaluate metrics<a class="headerlink" href="#id11" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_predictions_weighted</span> <span class="o">=</span> <span class="n">weighted_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">test_predictions_weighted</span> <span class="o">=</span> <span class="n">weighted_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">weighted_results</span> <span class="o">=</span> <span class="n">weighted_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weighted_model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">weighted_results</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;: &#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">plot_cm</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_weighted</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here you can see that with class weights the accuracy and precision are lower because there are more false positives, but conversely the recall and AUC are higher because the model also found more true positives. Despite having lower accuracy, this model has higher recall (and identifies more fraudulent transactions). Of course, there is a cost to both types of error (you wouldn’t want to bug users by flagging too many legitimate transactions as fraudulent, either). Carefully consider the
trade-offs between these different types of errors for your application.</p>
</div>
<div class="section" id="id12">
<h3>Plot the ROC<a class="headerlink" href="#id12" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Train Baseline&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Test Baseline&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Train Weighted&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Test Weighted&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Plot-the-AUPRC">
<h3>Plot the AUPRC<a class="headerlink" href="#Plot-the-AUPRC" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Train Baseline&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Test Baseline&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Train Weighted&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Test Weighted&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Oversampling">
<h2>Oversampling<a class="headerlink" href="#Oversampling" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Oversample-the-minority-class">
<h3>Oversample the minority class<a class="headerlink" href="#Oversample-the-minority-class" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A related approach would be to resample the dataset by oversampling the minority class.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pos_features</span> <span class="o">=</span> <span class="n">train_features</span><span class="p">[</span><span class="n">bool_train_labels</span><span class="p">]</span>
<span class="n">neg_features</span> <span class="o">=</span> <span class="n">train_features</span><span class="p">[</span><span class="o">~</span><span class="n">bool_train_labels</span><span class="p">]</span>

<span class="n">pos_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">bool_train_labels</span><span class="p">]</span>
<span class="n">neg_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="o">~</span><span class="n">bool_train_labels</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="Using-NumPy">
<h4>Using NumPy<a class="headerlink" href="#Using-NumPy" title="Enlazar permanentemente con este título">¶</a></h4>
<p>You can balance the dataset manually by choosing the right number of random indices from the positive examples:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pos_features</span><span class="p">))</span>
<span class="n">choices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_features</span><span class="p">))</span>

<span class="n">res_pos_features</span> <span class="o">=</span> <span class="n">pos_features</span><span class="p">[</span><span class="n">choices</span><span class="p">]</span>
<span class="n">res_pos_labels</span> <span class="o">=</span> <span class="n">pos_labels</span><span class="p">[</span><span class="n">choices</span><span class="p">]</span>

<span class="n">res_pos_features</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">resampled_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">res_pos_features</span><span class="p">,</span> <span class="n">neg_features</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">resampled_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">res_pos_labels</span><span class="p">,</span> <span class="n">neg_labels</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">resampled_labels</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">order</span><span class="p">)</span>
<span class="n">resampled_features</span> <span class="o">=</span> <span class="n">resampled_features</span><span class="p">[</span><span class="n">order</span><span class="p">]</span>
<span class="n">resampled_labels</span> <span class="o">=</span> <span class="n">resampled_labels</span><span class="p">[</span><span class="n">order</span><span class="p">]</span>

<span class="n">resampled_features</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Using-tf.data">
<h4>Using <code class="docutils literal notranslate"><span class="pre">tf.data</span></code><a class="headerlink" href="#Using-tf.data" title="Enlazar permanentemente con este título">¶</a></h4>
<p>If you’re using <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> the easiest way to produce balanced examples is to start with a <code class="docutils literal notranslate"><span class="pre">positive</span></code> and a <code class="docutils literal notranslate"><span class="pre">negative</span></code> dataset, and merge them. See <a class="reference internal" href="../../guide/data.html"><span class="doc">the tf.data guide</span></a> for more examples.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="k">def</span> <span class="nf">make_ds</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
  <span class="n">ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span><span class="c1">#.cache()</span>
  <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">ds</span>

<span class="n">pos_ds</span> <span class="o">=</span> <span class="n">make_ds</span><span class="p">(</span><span class="n">pos_features</span><span class="p">,</span> <span class="n">pos_labels</span><span class="p">)</span>
<span class="n">neg_ds</span> <span class="o">=</span> <span class="n">make_ds</span><span class="p">(</span><span class="n">neg_features</span><span class="p">,</span> <span class="n">neg_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Each dataset provides <code class="docutils literal notranslate"><span class="pre">(feature,</span> <span class="pre">label)</span></code> pairs:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">pos_ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">features</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
  <span class="nb">print</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label: &quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>Merge the two together using <code class="docutils literal notranslate"><span class="pre">experimental.sample_from_datasets</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">resampled_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">sample_from_datasets</span><span class="p">([</span><span class="n">pos_ds</span><span class="p">,</span> <span class="n">neg_ds</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">resampled_ds</span> <span class="o">=</span> <span class="n">resampled_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">resampled_ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>To use this dataset, you’ll need the number of steps per epoch.</p>
<p>The definition of “epoch” in this case is less clear. Say it’s the number of batches required to see each negative example once:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">resampled_steps_per_epoch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">neg</span><span class="o">/</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">resampled_steps_per_epoch</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Train-on-the-oversampled-data">
<h3>Train on the oversampled data<a class="headerlink" href="#Train-on-the-oversampled-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Now try training the model with the resampled data set instead of using class weights to see how these methods compare.</p>
<p>Note: Because the data was balanced by replicating the positive examples, the total dataset size is larger, and each epoch runs for more training steps.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">resampled_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">resampled_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>

<span class="c1"># Reset the bias to zero, since this dataset is balanced.</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">resampled_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">output_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">assign</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>

<span class="n">val_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">))</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">resampled_history</span> <span class="o">=</span> <span class="n">resampled_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">resampled_ds</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">resampled_steps_per_epoch</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">],</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">val_ds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If the training process were considering the whole dataset on each gradient update, this oversampling would be basically identical to the class weighting.</p>
<p>But when training the model batch-wise, as you did here, the oversampled data provides a smoother gradient signal: Instead of each positive example being shown in one batch with a large weight, they’re shown in many different batches each time with a small weight.</p>
<p>This smoother gradient signal makes it easier to train the model.</p>
</div>
<div class="section" id="id13">
<h3>Check training history<a class="headerlink" href="#id13" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Note that the distributions of metrics will be different here, because the training data has a totally different distribution from the validation and test data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_metrics</span><span class="p">(</span><span class="n">resampled_history</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Re-train">
<h3>Re-train<a class="headerlink" href="#Re-train" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Because training is easier on the balanced data, the above training procedure may overfit quickly.</p>
<p>So break up the epochs to give the <code class="docutils literal notranslate"><span class="pre">callbacks.EarlyStopping</span></code> finer control over when to stop training.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">resampled_model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">resampled_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>

<span class="c1"># Reset the bias to zero, since this dataset is balanced.</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">resampled_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">output_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">assign</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>

<span class="n">resampled_history</span> <span class="o">=</span> <span class="n">resampled_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">resampled_ds</span><span class="p">,</span>
    <span class="c1"># These are not real epochs</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">],</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_ds</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Re-check-training-history">
<h3>Re-check training history<a class="headerlink" href="#Re-check-training-history" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_metrics</span><span class="p">(</span><span class="n">resampled_history</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id14">
<h3>Evaluate metrics<a class="headerlink" href="#id14" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_predictions_resampled</span> <span class="o">=</span> <span class="n">resampled_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">test_predictions_resampled</span> <span class="o">=</span> <span class="n">resampled_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">resampled_results</span> <span class="o">=</span> <span class="n">resampled_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span>
                                             <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">resampled_model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">resampled_results</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;: &#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">plot_cm</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_resampled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id15">
<h3>Plot the ROC<a class="headerlink" href="#id15" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Train Baseline&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Test Baseline&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Train Weighted&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Test Weighted&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Train Resampled&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_resampled</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="s2">&quot;Test Resampled&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_resampled</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id16">
<h3>Plot the AUPRC<a class="headerlink" href="#id16" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Train Baseline&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Test Baseline&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_baseline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Train Weighted&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Test Weighted&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_weighted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Train Resampled&quot;</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_predictions_resampled</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plot_prc</span><span class="p">(</span><span class="s2">&quot;Test Resampled&quot;</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">test_predictions_resampled</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Applying-this-tutorial-to-your-problem">
<h2>Applying this tutorial to your problem<a class="headerlink" href="#Applying-this-tutorial-to-your-problem" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Imbalanced data classification is an inherently difficult task since there are so few samples to learn from. You should always start with the data first and do your best to collect as many samples as possible and give substantial thought to what features may be relevant so the model can get the most out of your minority class. At some point your model may struggle to improve and yield the results you want, so it is important to keep in mind the context of your problem and the trade offs between
different types of errors.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>