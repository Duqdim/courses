

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Custom training with tf.distribute.Strategy &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Custom training with tf.distribute.Strategy</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Distributed_training/1-02_custom_training.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Custom-training-with-tf.distribute.Strategy">
<h1>Custom training with tf.distribute.Strategy<a class="headerlink" href="#Custom-training-with-tf.distribute.Strategy" title="Enlazar permanentemente con este título">¶</a></h1>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>4b05ddd3e2b34482827dd73e3a604b75|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>90b4fb89999e4ea5ac62cf43ff6a0fd7|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>6c5e4bc250554a8bad2baaacfcd1c4fe|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>a3890263cbe4492683ffbf6970868af9|Download notebook</p>
</td></table><p>This tutorial demonstrates how to use <code class="docutils literal notranslate"><span class="pre">`tf.distribute.Strategy</span></code> &lt;<a class="reference external" href="https://www.tensorflow.org/guide/distributed_training">https://www.tensorflow.org/guide/distributed_training</a>&gt;`__ with custom training loops. We will train a simple CNN model on the fashion MNIST dataset. The fashion MNIST dataset contains 60000 train images of size 28 x 28 and 10000 test images of size 28 x 28.</p>
<p>We are using custom training loops to train our model because they give us flexibility and a greater control on training. Moreover, it is easier to debug the model and the training loop.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Import TensorFlow</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Helper libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Download-the-fashion-MNIST-dataset">
<h2>Download the fashion MNIST dataset<a class="headerlink" href="#Download-the-fashion-MNIST-dataset" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fashion_mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Adding a dimension to the array -&gt; new shape == (28, 28, 1)</span>
<span class="c1"># We are doing this because the first layer in our model is a convolutional</span>
<span class="c1"># layer and it requires a 4D input (batch_size, height, width, channels).</span>
<span class="c1"># batch_size dimension will be added later on.</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

<span class="c1"># Getting the images in [0, 1] range.</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Create-a-strategy-to-distribute-the-variables-and-the-graph">
<h2>Create a strategy to distribute the variables and the graph<a class="headerlink" href="#Create-a-strategy-to-distribute-the-variables-and-the-graph" title="Enlazar permanentemente con este título">¶</a></h2>
<p>How does <code class="docutils literal notranslate"><span class="pre">tf.distribute.MirroredStrategy</span></code> strategy work?</p>
<ul class="simple">
<li><p>All the variables and the model graph is replicated on the replicas.</p></li>
<li><p>Input is evenly distributed across the replicas.</p></li>
<li><p>Each replica calculates the loss and gradients for the input it received.</p></li>
<li><p>The gradients are synced across all the replicas by summing them.</p></li>
<li><p>After the sync, the same update is made to the copies of the variables on each replica.</p></li>
</ul>
<p>Note: You can put all the code below inside a single scope. We are dividing it into several code cells for illustration purposes.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># If the list of devices is not specified in the</span>
<span class="c1"># `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.</span>
<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Number of devices: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">strategy</span><span class="o">.</span><span class="n">num_replicas_in_sync</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Setup-input-pipeline">
<h2>Setup input pipeline<a class="headerlink" href="#Setup-input-pipeline" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Export the graph and the variables to the platform-agnostic SavedModel format. After your model is saved, you can load it with or without the scope.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>

<span class="n">BATCH_SIZE_PER_REPLICA</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">GLOBAL_BATCH_SIZE</span> <span class="o">=</span> <span class="n">BATCH_SIZE_PER_REPLICA</span> <span class="o">*</span> <span class="n">strategy</span><span class="o">.</span><span class="n">num_replicas_in_sync</span>

<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
<p>Create the datasets and distribute them:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">))</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">GLOBAL_BATCH_SIZE</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">GLOBAL_BATCH_SIZE</span><span class="p">)</span>

<span class="n">train_dist_dataset</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">test_dist_dataset</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Create-the-model">
<h2>Create the model<a class="headerlink" href="#Create-the-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Create a model using <code class="docutils literal notranslate"><span class="pre">tf.keras.Sequential</span></code>. You can also use the Model Subclassing API to do this.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="p">])</span>

  <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Create a checkpoint directory to store the checkpoints.</span>
<span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="s1">&#39;./training_checkpoints&#39;</span>
<span class="n">checkpoint_prefix</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">&quot;ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Define-the-loss-function">
<h2>Define the loss function<a class="headerlink" href="#Define-the-loss-function" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Normally, on a single machine with 1 GPU/CPU, loss is divided by the number of examples in the batch of input.</p>
<p><em>So, how should the loss be calculated when using a ``tf.distribute.Strategy``?</em></p>
<ul class="simple">
<li><p>For an example, let’s say you have 4 GPU’s and a batch size of 64. One batch of input is distributed across the replicas (4 GPUs), each replica getting an input of size 16.</p></li>
<li><p>The model on each replica does a forward pass with its respective input and calculates the loss. Now, instead of dividing the loss by the number of examples in its respective input (BATCH_SIZE_PER_REPLICA = 16), the loss should be divided by the GLOBAL_BATCH_SIZE (64).</p></li>
</ul>
<p><em>Why do this?</em></p>
<ul class="simple">
<li><p>This needs to be done because after the gradients are calculated on each replica, they are synced across the replicas by <strong>summing</strong> them.</p></li>
</ul>
<p><em>How to do this in TensorFlow?</em></p>
<ul>
<li><p>If you’re writing a custom training loop, as in this tutorial, you should sum the per example losses and divide the sum by the GLOBAL_BATCH_SIZE: <code class="docutils literal notranslate"><span class="pre">scale_loss</span> <span class="pre">=</span> <span class="pre">tf.reduce_sum(loss)</span> <span class="pre">*</span> <span class="pre">(1.</span> <span class="pre">/</span> <span class="pre">GLOBAL_BATCH_SIZE)</span></code> or you can use <code class="docutils literal notranslate"><span class="pre">tf.nn.compute_average_loss</span></code> which takes the per example loss, optional sample weights, and GLOBAL_BATCH_SIZE as arguments and returns the scaled loss.</p></li>
<li><p>If you are using regularization losses in your model then you need to scale the loss value by number of replicas. You can do this by using the <code class="docutils literal notranslate"><span class="pre">tf.nn.scale_regularization_loss</span></code> function.</p></li>
<li><p>Using <code class="docutils literal notranslate"><span class="pre">tf.reduce_mean</span></code> is not recommended. Doing so divides the loss by actual per replica batch size which may vary step to step.</p></li>
<li><p>This reduction and scaling is done automatically in keras <code class="docutils literal notranslate"><span class="pre">model.compile</span></code> and <code class="docutils literal notranslate"><span class="pre">model.fit</span></code></p></li>
<li><p>If using <code class="docutils literal notranslate"><span class="pre">tf.keras.losses</span></code> classes (as in the example below), the loss reduction needs to be explicitly specified to be one of <code class="docutils literal notranslate"><span class="pre">NONE</span></code> or <code class="docutils literal notranslate"><span class="pre">SUM</span></code>. <code class="docutils literal notranslate"><span class="pre">AUTO</span></code> and <code class="docutils literal notranslate"><span class="pre">SUM_OVER_BATCH_SIZE</span></code> are disallowed when used with <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code>. <code class="docutils literal notranslate"><span class="pre">AUTO</span></code> is disallowed because the user should explicitly think about what reduction they want to make sure it is correct in the distributed case. <code class="docutils literal notranslate"><span class="pre">SUM_OVER_BATCH_SIZE</span></code> is disallowed because currently it would only divide by per replica batch size,
and leave the dividing by number of replicas to the user, which might be easy to miss. So instead we ask the user do the reduction themselves explicitly.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">labels</span></code> is multi-dimensional, then average the <code class="docutils literal notranslate"><span class="pre">per_example_loss</span></code> across the number of elements in each sample. For example, if the shape of <code class="docutils literal notranslate"><span class="pre">predictions</span></code> is <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">H,</span> <span class="pre">W,</span> <span class="pre">n_classes)</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code> is <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">H,</span> <span class="pre">W)</span></code>, you will need to update <code class="docutils literal notranslate"><span class="pre">per_example_loss</span></code> like: <code class="docutils literal notranslate"><span class="pre">per_example_loss</span> <span class="pre">/=</span> <span class="pre">tf.cast(tf.reduce_prod(tf.shape(labels)[1:]),</span> <span class="pre">tf.float32)</span></code></p>
<p>Caution: <strong>Verify the shape of your loss</strong>. Loss functions in <code class="docutils literal notranslate"><span class="pre">tf.losses</span></code>/<code class="docutils literal notranslate"><span class="pre">tf.keras.losses</span></code> typically return the average over the last dimension of the input. The loss classes wrap these functions. Passing <code class="docutils literal notranslate"><span class="pre">reduction=Reduction.NONE</span></code> when creating an instance of a loss class means “no <strong>additional</strong> reduction”. For categorical losses with an example input shape of <code class="docutils literal notranslate"><span class="pre">[batch,</span> <span class="pre">W,</span> <span class="pre">H,</span> <span class="pre">n_classes]</span></code> the <code class="docutils literal notranslate"><span class="pre">n_classes</span></code> dimension is reduced. For pointwise losses like <code class="docutils literal notranslate"><span class="pre">losses.mean_squared_error</span></code>
or <code class="docutils literal notranslate"><span class="pre">losses.binary_crossentropy</span></code> include a dummy axis so that <code class="docutils literal notranslate"><span class="pre">[batch,</span> <span class="pre">W,</span> <span class="pre">H,</span> <span class="pre">1]</span></code> is reduced to <code class="docutils literal notranslate"><span class="pre">[batch,</span> <span class="pre">W,</span> <span class="pre">H]</span></code>. Without the dummy axis <code class="docutils literal notranslate"><span class="pre">[batch,</span> <span class="pre">W,</span> <span class="pre">H]</span></code> will be incorrectly reduced to <code class="docutils literal notranslate"><span class="pre">[batch,</span> <span class="pre">W]</span></code>.</p>
</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
  <span class="c1"># Set reduction to `none` so we can do the reduction afterwards and divide by</span>
  <span class="c1"># global batch size.</span>
  <span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
      <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
    <span class="n">per_example_loss</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">compute_average_loss</span><span class="p">(</span><span class="n">per_example_loss</span><span class="p">,</span> <span class="n">global_batch_size</span><span class="o">=</span><span class="n">GLOBAL_BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Define-the-metrics-to-track-loss-and-accuracy">
<h2>Define the metrics to track loss and accuracy<a class="headerlink" href="#Define-the-metrics-to-track-loss-and-accuracy" title="Enlazar permanentemente con este título">¶</a></h2>
<p>These metrics track the test loss and training and test accuracy. You can use <code class="docutils literal notranslate"><span class="pre">.result()</span></code> to get the accumulated statistics at any time.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
  <span class="n">test_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_loss&#39;</span><span class="p">)</span>

  <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">)</span>
  <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_accuracy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-loop">
<h2>Training loop<a class="headerlink" href="#Training-loop" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># model, optimizer, and checkpoint must be created under `strategy.scope`.</span>
<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>

  <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
  <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span>

  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

  <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
  <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

  <span class="n">train_accuracy</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">loss</span>

<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
  <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span>

  <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">t_loss</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

  <span class="n">test_loss</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">t_loss</span><span class="p">)</span>
  <span class="n">test_accuracy</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># `run` replicates the provided computation and runs it</span>
<span class="c1"># with the distributed input.</span>
<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">distributed_train_step</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">):</span>
  <span class="n">per_replica_losses</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">,))</span>
  <span class="k">return</span> <span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">per_replica_losses</span><span class="p">,</span>
                         <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">distributed_test_step</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">test_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">dataset_inputs</span><span class="p">,))</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
  <span class="c1"># TRAIN LOOP</span>
  <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="n">num_batches</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_dist_dataset</span><span class="p">:</span>
    <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">distributed_train_step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">train_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">num_batches</span>

  <span class="c1"># TEST LOOP</span>
  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_dist_dataset</span><span class="p">:</span>
    <span class="n">distributed_test_step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">checkpoint</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint_prefix</span><span class="p">)</span>

  <span class="n">template</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{}</span><span class="s2">, Loss: </span><span class="si">{}</span><span class="s2">, Accuracy: </span><span class="si">{}</span><span class="s2">, Test Loss: </span><span class="si">{}</span><span class="s2">, &quot;</span>
              <span class="s2">&quot;Test Accuracy: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span>
                         <span class="n">train_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">test_loss</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
                         <span class="n">test_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

  <span class="n">test_loss</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
  <span class="n">train_accuracy</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
  <span class="n">test_accuracy</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Things to note in the example above:</p>
<ul class="simple">
<li><p>We are iterating over the <code class="docutils literal notranslate"><span class="pre">train_dist_dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">test_dist_dataset</span></code> using a <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">...</span></code> construct.</p></li>
<li><p>The scaled loss is the return value of the <code class="docutils literal notranslate"><span class="pre">distributed_train_step</span></code>. This value is aggregated across replicas using the <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy.reduce</span></code> call and then across batches by summing the return value of the <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy.reduce</span></code> calls.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.keras.Metrics</span></code> should be updated inside <code class="docutils literal notranslate"><span class="pre">train_step</span></code> and <code class="docutils literal notranslate"><span class="pre">test_step</span></code> that gets executed by <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy.run</span></code>. *<code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy.run</span></code> returns results from each local replica in the strategy, and there are multiple ways to consume this result. You can do <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy.reduce</span></code> to get an aggregated value. You can also do <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy.experimental_local_results</span></code> to get the list of values contained in the result, one per local replica.</p></li>
</ul>
</div>
<div class="section" id="Restore-the-latest-checkpoint-and-test">
<h2>Restore the latest checkpoint and test<a class="headerlink" href="#Restore-the-latest-checkpoint-and-test" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A model checkpointed with a <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code> can be restored with or without a strategy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">eval_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;eval_accuracy&#39;</span><span class="p">)</span>

<span class="n">new_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">new_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">GLOBAL_BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">eval_step</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">eval_accuracy</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">new_optimizer</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">new_model</span><span class="p">)</span>
<span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">))</span>

<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="p">:</span>
  <span class="n">eval_step</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Accuracy after restoring the saved model without strategy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">eval_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Alternate-ways-of-iterating-over-a-dataset">
<h2>Alternate ways of iterating over a dataset<a class="headerlink" href="#Alternate-ways-of-iterating-over-a-dataset" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Using-iterators">
<h3>Using iterators<a class="headerlink" href="#Using-iterators" title="Enlazar permanentemente con este título">¶</a></h3>
<p>If you want to iterate over a given number of steps and not through the entire dataset you can create an iterator using the <code class="docutils literal notranslate"><span class="pre">iter</span></code> call and explicity call <code class="docutils literal notranslate"><span class="pre">next</span></code> on the iterator. You can choose to iterate over the dataset both inside and outside the tf.function. Here is a small snippet demonstrating iteration of the dataset outside the tf.function using an iterator.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
  <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="n">num_batches</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">train_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_dist_dataset</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">distributed_train_step</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">train_iter</span><span class="p">))</span>
    <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">average_train_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">num_batches</span>

  <span class="n">template</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{}</span><span class="s2">, Loss: </span><span class="si">{}</span><span class="s2">, Accuracy: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">average_train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
  <span class="n">train_accuracy</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Iterating-inside-a-tf.function">
<h3>Iterating inside a tf.function<a class="headerlink" href="#Iterating-inside-a-tf.function" title="Enlazar permanentemente con este título">¶</a></h3>
<p>You can also iterate over the entire input <code class="docutils literal notranslate"><span class="pre">train_dist_dataset</span></code> inside a tf.function using the <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">...</span></code> construct or by creating iterators like we did above. The example below demonstrates wrapping one epoch of training in a tf.function and iterating over <code class="docutils literal notranslate"><span class="pre">train_dist_dataset</span></code> inside the function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">distributed_train_epoch</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
  <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="n">num_batches</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="n">per_replica_losses</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,))</span>
    <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">per_replica_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">num_batches</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
  <span class="n">train_loss</span> <span class="o">=</span> <span class="n">distributed_train_epoch</span><span class="p">(</span><span class="n">train_dist_dataset</span><span class="p">)</span>

  <span class="n">template</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{}</span><span class="s2">, Loss: </span><span class="si">{}</span><span class="s2">, Accuracy: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

  <span class="n">train_accuracy</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Tracking-training-loss-across-replicas">
<h3>Tracking training loss across replicas<a class="headerlink" href="#Tracking-training-loss-across-replicas" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Note: As a general rule, you should use <code class="docutils literal notranslate"><span class="pre">tf.keras.Metrics</span></code> to track per-sample values and avoid values that have been aggregated within a replica.</p>
<p>We do <em>not</em> recommend using <code class="docutils literal notranslate"><span class="pre">tf.metrics.Mean</span></code> to track the training loss across different replicas, because of the loss scaling computation that is carried out.</p>
<p>For example, if you run a training job with the following characteristics: * Two replicas * Two samples are processed on each replica * Resulting loss values: [2, 3] and [4, 5] on each replica * Global batch size = 4</p>
<p>With loss scaling, you calculate the per-sample value of loss on each replica by adding the loss values, and then dividing by the global batch size. In this case: <code class="docutils literal notranslate"><span class="pre">(2</span> <span class="pre">+</span> <span class="pre">3)</span> <span class="pre">/</span> <span class="pre">4</span> <span class="pre">=</span> <span class="pre">1.25</span></code> and <code class="docutils literal notranslate"><span class="pre">(4</span> <span class="pre">+</span> <span class="pre">5)</span> <span class="pre">/</span> <span class="pre">4</span> <span class="pre">=</span> <span class="pre">2.25</span></code>.</p>
<p>If you use <code class="docutils literal notranslate"><span class="pre">tf.metrics.Mean</span></code> to track loss across the two replicas, the result is different. In this example, you end up with a <code class="docutils literal notranslate"><span class="pre">total</span></code> of 3.50 and <code class="docutils literal notranslate"><span class="pre">count</span></code> of 2, which results in <code class="docutils literal notranslate"><span class="pre">total</span></code>/<code class="docutils literal notranslate"><span class="pre">count</span></code> = 1.75 when <code class="docutils literal notranslate"><span class="pre">result()</span></code> is called on the metric. Loss calculated with <code class="docutils literal notranslate"><span class="pre">tf.keras.Metrics</span></code> is scaled by an additional factor that is equal to the number of replicas in sync.</p>
</div>
<div class="section" id="Guide-and-examples">
<h3>Guide and examples<a class="headerlink" href="#Guide-and-examples" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Here are some examples for using distribution strategy with custom training loops:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="../../guide/distributed_training">Distributed training guide</a></p></li>
<li><p><a class="reference external" href="https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/densenet/distributed_train.py">DenseNet</a> example using <code class="docutils literal notranslate"><span class="pre">MirroredStrategy</span></code>.</p></li>
<li><p><a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/nlp/bert/run_classifier.py">BERT</a> example trained using <code class="docutils literal notranslate"><span class="pre">MirroredStrategy</span></code> and <code class="docutils literal notranslate"><span class="pre">TPUStrategy</span></code>. This example is particularly helpful for understanding how to load from a checkpoint and generate periodic checkpoints during distributed training etc.</p></li>
<li><p><a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py">NCF</a> example trained using <code class="docutils literal notranslate"><span class="pre">MirroredStrategy</span></code> that can be enabled using the <code class="docutils literal notranslate"><span class="pre">keras_use_ctl</span></code> flag.</p></li>
<li><p><a class="reference external" href="https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/nmt_with_attention/distributed_train.py">NMT</a> example trained using <code class="docutils literal notranslate"><span class="pre">MirroredStrategy</span></code>.</p></li>
</ol>
<p>More examples listed in the Distribution strategy guide.</p>
</div>
</div>
<div class="section" id="Next-steps">
<h2>Next steps<a class="headerlink" href="#Next-steps" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>Try out the new <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code> API on your models.</p></li>
<li><p>Visit the <a class="reference internal" href="../../guide/function.html"><span class="doc">Performance section</span></a> in the guide to learn more about other strategies and <a class="reference internal" href="../../guide/profiler.html"><span class="doc">tools</span></a> you can use to optimize the performance of your TensorFlow models.</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>