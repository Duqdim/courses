

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Parameter Server Training &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Parameter Server Training</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Distributed_training/1-05_parameter_server_training.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Parameter-Server-Training">
<h1>Parameter Server Training<a class="headerlink" href="#Parameter-Server-Training" title="Enlazar permanentemente con este título">¶</a></h1>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>9804a32bf81f4d0e91b89e066d0720d8|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>d6b33e2dca6545df8ddc9780c5b32509|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>c63ef962106e482e9d69502b9f53eb55|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>630a7de3e15d40aa968bdca13ab79486|Download notebook</p>
</td></table><div class="section" id="Overview">
<h2>Overview<a class="headerlink" href="#Overview" title="Enlazar permanentemente con este título">¶</a></h2>
<p><a class="reference external" href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">Parameter server training</a> is a common data-parallel method to scale up model training on multiple machines. A parameter server training cluster consists of workers and parameter servers. Variables are created on parameter servers and they are read and updated by workers in each step. By default, workers read and update these variables independently without synchronizing with each other. This is why sometimes
parameter server-style training is called asynchronous training.</p>
<p>TensorFlow 2 parameter server training uses a central-coordinator via the <code class="docutils literal notranslate"><span class="pre">tf.distribute.experimental.coordinator.ClusterCoordinator</span></code> class.</p>
<p>In this implementation the <code class="docutils literal notranslate"><span class="pre">worker</span></code> and <code class="docutils literal notranslate"><span class="pre">parameter</span> <span class="pre">server</span></code> tasks run <code class="docutils literal notranslate"><span class="pre">tf.distribute.Server</span></code>s that listen for requests from the coordinator. The coordinator creates resources, dispatches training tasks, writes checkpoints, and deals with task failures.</p>
<p>We believe this architecture and the new <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> class provide a more flexible and simpler programming model.</p>
<div class="section" id="ClusterCoordinator">
<h3><code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code><a class="headerlink" href="#ClusterCoordinator" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> class needs to work in conjunction with a <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code> object. This <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code> object is needed to pass the information of the cluster and is used to define a training step as we have seen in <cite>custom training with ``MirroredStrategy`</cite> &lt;<a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/custom_training#training_loop">https://www.tensorflow.org/tutorials/distribute/custom_training#training_loop</a>&gt;`__. The <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> object then dispatches the execution of these training steps to remote workers. Currently, the
<code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> only works with <code class="docutils literal notranslate"><span class="pre">tf.distribute.experimental.ParameterServerStrategy</span></code>.</p>
<p>The most important API provided by the <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> object is <code class="docutils literal notranslate"><span class="pre">schedule</span></code>. The <code class="docutils literal notranslate"><span class="pre">schedule</span></code> API enqueues a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> and returns a future-like <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code> immediately. The queued functions will be dispatched to remote workers in background threads and their <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code>s will be filled asynchronously. Since <code class="docutils literal notranslate"><span class="pre">schedule</span></code> doesn’t require worker assignment, the <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> passed in can be executed on any available worker. If the worker it is executed on becomes
unavailable before its completion, the function will be retried on another available worker. Because of this fact and the fact that function execution is not atomic, a function may be executed more than once.</p>
<p>In addition to dispatching remote functions, the <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> also helps to create datasets on all the workers and rebuild these datasets when a worker recovers from failure.</p>
</div>
</div>
<div class="section" id="Tutorial-Setup">
<h2>Tutorial Setup<a class="headerlink" href="#Tutorial-Setup" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install portpicker
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">portpicker</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.layers.experimental.preprocessing</span> <span class="k">as</span> <span class="nn">kpl</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Cluster-Setup">
<h2>Cluster Setup<a class="headerlink" href="#Cluster-Setup" title="Enlazar permanentemente con este título">¶</a></h2>
<p>As mentioned above, a parameter server training cluster requires a coordinator task that runs your training program, one or several workers and parameter server tasks that run TensorFlow servers, i.e. <code class="docutils literal notranslate"><span class="pre">tf.distribute.Server</span></code>, and possibly an additional evaluation task that runs side-car evaluation (see the side-car evaluation section below). The requirements to set them up are:</p>
<ul class="simple">
<li><p>The coordinator task needs to know the addresses and ports of all other TensorFlow servers except the evaluator.</p></li>
<li><p>The workers and parameter servers need to know which port they need to listen to. For the sake of simplicity, we usually pass in the complete cluster information when we create TensorFlow servers on these tasks.</p></li>
<li><p>The evaluator task doesn’t have to know the setup of the training cluster. If it does, it should not attempt to connect to the training cluster.</p></li>
<li><p>Workers and parameter servers should have task types as “worker” and “ps” respectively. The coordinator should use “chief” as the task type for legacy reasons.</p></li>
</ul>
<p>In this tutorial, we will create an in-process cluster so that the whole parameter server training can be run in colab. We will introduce how to set up <a class="reference external" href="#real_clusters">real clusters</a> in a later section.</p>
<div class="section" id="In-process-cluster">
<h3>In-process cluster<a class="headerlink" href="#In-process-cluster" title="Enlazar permanentemente con este título">¶</a></h3>
<p>In this tutorial, we will start a bunch of TensorFlow servers in advance and connect to them later:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">create_in_process_cluster</span><span class="p">(</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">num_ps</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates and starts local servers and returns the cluster_resolver.&quot;&quot;&quot;</span>
  <span class="n">worker_ports</span> <span class="o">=</span> <span class="p">[</span><span class="n">portpicker</span><span class="o">.</span><span class="n">pick_unused_port</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_workers</span><span class="p">)]</span>
  <span class="n">ps_ports</span> <span class="o">=</span> <span class="p">[</span><span class="n">portpicker</span><span class="o">.</span><span class="n">pick_unused_port</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_ps</span><span class="p">)]</span>

  <span class="n">cluster_dict</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">cluster_dict</span><span class="p">[</span><span class="s2">&quot;worker&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;localhost:</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">port</span> <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="n">worker_ports</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">num_ps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">cluster_dict</span><span class="p">[</span><span class="s2">&quot;ps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;localhost:</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">port</span> <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="n">ps_ports</span><span class="p">]</span>

  <span class="n">cluster_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ClusterSpec</span><span class="p">(</span><span class="n">cluster_dict</span><span class="p">)</span>

  <span class="c1"># Workers need some inter_ops threads to work properly.</span>
  <span class="n">worker_config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">num_workers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">worker_config</span><span class="o">.</span><span class="n">inter_op_parallelism_threads</span> <span class="o">=</span> <span class="n">num_workers</span> <span class="o">+</span> <span class="mi">1</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_workers</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span>
        <span class="n">cluster_spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s2">&quot;worker&quot;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">worker_config</span><span class="p">,</span>
        <span class="n">protocol</span><span class="o">=</span><span class="s2">&quot;grpc&quot;</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_ps</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span>
        <span class="n">cluster_spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s2">&quot;ps&quot;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="s2">&quot;grpc&quot;</span><span class="p">)</span>

  <span class="n">cluster_resolver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">SimpleClusterResolver</span><span class="p">(</span>
      <span class="n">cluster_spec</span><span class="p">,</span> <span class="n">rpc_layer</span><span class="o">=</span><span class="s2">&quot;grpc&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">cluster_resolver</span>

<span class="c1"># Set the environment variable to allow reporting worker and ps failure to the</span>
<span class="c1"># coordinator. This is a workaround and won&#39;t be necessary in the future.</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;GRPC_FAIL_FAST&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;use_caller&quot;</span>

<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">NUM_PS</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">cluster_resolver</span> <span class="o">=</span> <span class="n">create_in_process_cluster</span><span class="p">(</span><span class="n">NUM_WORKERS</span><span class="p">,</span> <span class="n">NUM_PS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Training-with-Custom-Training-Loop">
<h2>Training with Custom Training Loop<a class="headerlink" href="#Training-with-Custom-Training-Loop" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Custom training loop with <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code> provides great flexibility to define training loops. Currently for parameter server training in TensorFlow 2, only custom training loop is supported. Here we use <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code> to define a training step and then use <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> to dispatch the execution of training steps to remote workers.</p>
<div class="section" id="Create-the-ParameterServerStrategy">
<h3>Create the <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code><a class="headerlink" href="#Create-the-ParameterServerStrategy" title="Enlazar permanentemente con este título">¶</a></h3>
<p>To write a training step in custom training loop, the first step is to create a <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code>. We will explain the <code class="docutils literal notranslate"><span class="pre">variable_partitioner</span></code> later.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">variable_partitioner</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">partitioners</span><span class="o">.</span><span class="n">FixedShardsPartitioner</span><span class="p">(</span>
        <span class="n">num_shards</span><span class="o">=</span><span class="n">NUM_PS</span><span class="p">))</span>

<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">ParameterServerStrategy</span><span class="p">(</span>
    <span class="n">cluster_resolver</span><span class="p">,</span>
    <span class="n">variable_partitioner</span><span class="o">=</span><span class="n">variable_partitioner</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Then you will create a model, define a dataset and a step function as we have seen in the training loop with other <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code>s. You can find more details in this <a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/custom_training">tutorial</a>.</p>
<p>In order to use GPUs for training, allocate GPUs visible to each worker. <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code> will use all the available GPUs on each worker, with the restriction that all workers should have the same number of GPUs available. To ensure efficient dataset prefetching, use the recommended distributed dataset creation APIs mentioned in the <a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/parameter_server_training#dispatch_training_steps_to_remote_workers">Dispatch Training steps to remote
workers</a> section below. Also, make sure to call <code class="docutils literal notranslate"><span class="pre">strategy.run</span></code> inside worker_fn to take full advantage of GPUs allocated on workers. Rest of the steps are the same for training with or without GPUs.</p>
<p>Let’s create these components in following steps:</p>
</div>
<div class="section" id="Setup-the-data">
<h3>Setup the data<a class="headerlink" href="#Setup-the-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>First, write a function that creates a dataset that includes preprocessing logic implemented by Keras preprocessing layers. We will create these layers outside the <code class="docutils literal notranslate"><span class="pre">dataset_fn</span></code> but apply the transformation inside the <code class="docutils literal notranslate"><span class="pre">dataset_fn</span></code> since you will wrap the <code class="docutils literal notranslate"><span class="pre">dataset_fn</span></code> into a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> which doesn’t allow variables to be created inside it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">feature_vocab</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;avenger&quot;</span><span class="p">,</span> <span class="s2">&quot;ironman&quot;</span><span class="p">,</span> <span class="s2">&quot;batman&quot;</span><span class="p">,</span> <span class="s2">&quot;hulk&quot;</span><span class="p">,</span> <span class="s2">&quot;spiderman&quot;</span><span class="p">,</span> <span class="s2">&quot;kingkong&quot;</span><span class="p">,</span>
    <span class="s2">&quot;wonder_woman&quot;</span>
<span class="p">]</span>
<span class="n">label_vocab</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;no&quot;</span><span class="p">]</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
  <span class="n">feature_lookup_layer</span> <span class="o">=</span> <span class="n">kpl</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span><span class="n">vocabulary</span><span class="o">=</span><span class="n">feature_vocab</span><span class="p">)</span>

  <span class="n">label_lookup_layer</span> <span class="o">=</span> <span class="n">kpl</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span><span class="n">vocabulary</span><span class="o">=</span><span class="n">label_vocab</span><span class="p">,</span>
                                        <span class="n">num_oov_indices</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                        <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

  <span class="n">raw_feature_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
      <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;feature&quot;</span><span class="p">)</span>
  <span class="n">feature_id_input</span> <span class="o">=</span> <span class="n">feature_lookup_layer</span><span class="p">(</span><span class="n">raw_feature_input</span><span class="p">)</span>
  <span class="n">feature_preprocess_stage</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
      <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">raw_feature_input</span><span class="p">},</span> <span class="n">feature_id_input</span><span class="p">)</span>

  <span class="n">raw_label_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
      <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
  <span class="n">label_id_input</span> <span class="o">=</span> <span class="n">label_lookup_layer</span><span class="p">(</span><span class="n">raw_label_input</span><span class="p">)</span>
  <span class="n">label_preprocess_stage</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">({</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="n">raw_label_input</span><span class="p">},</span> <span class="n">label_id_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Generate toy examples in a dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">feature_and_label_gen</span><span class="p">(</span><span class="n">num_examples</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
  <span class="n">examples</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">[]}</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">feature_vocab</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;yes&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;avenger&quot;</span> <span class="ow">in</span> <span class="n">features</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;no&quot;</span><span class="p">]</span>
    <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">examples</span>

<span class="n">examples</span> <span class="o">=</span> <span class="n">feature_and_label_gen</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Then we create the training dataset wrapped in a dataset_fn:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">dataset_fn</span><span class="p">(</span><span class="n">_</span><span class="p">):</span>
  <span class="n">raw_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

  <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">raw_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
      <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span>
          <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">feature_preprocess_stage</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])},</span>
          <span class="n">label_preprocess_stage</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
      <span class="p">))</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">train_dataset</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Build-the-model">
<h3>Build the model<a class="headerlink" href="#Build-the-model" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Second, we create the model and other objects. Make sure to create all variables under <code class="docutils literal notranslate"><span class="pre">strategy.scope</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># These variables created under the `strategy.scope` will be placed on parameter</span>
<span class="c1"># servers in a round-robin fashion.</span>
<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
  <span class="c1"># Create the model. The input needs to be compatible with KPLs.</span>
  <span class="n">model_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
      <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model_input&quot;</span><span class="p">)</span>

  <span class="n">emb_layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
      <span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_lookup_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()),</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="n">emb_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">emb_layer</span><span class="p">(</span><span class="n">model_input</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">dense_output</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">emb_output</span><span class="p">)</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">({</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">model_input</span><span class="p">},</span> <span class="n">dense_output</span><span class="p">)</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Define-the-training-step">
<h3>Define the training step<a class="headerlink" href="#Define-the-training-step" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Third, create the training step wrapped into a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">step_fn</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">replica_fn</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
      <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">per_example_loss</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span>
              <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">compute_average_loss</span><span class="p">(</span><span class="n">per_example_loss</span><span class="p">)</span>
      <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

    <span class="n">actual_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">accuracy</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">actual_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>

  <span class="n">batch_data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
  <span class="n">losses</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">replica_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>In the above step function, calling <code class="docutils literal notranslate"><span class="pre">strategy.run</span></code> and <code class="docutils literal notranslate"><span class="pre">strategy.reduce</span></code> in the <code class="docutils literal notranslate"><span class="pre">step_fn</span></code> can support multiple GPUs per worker. If the workers have GPUs allocated, <code class="docutils literal notranslate"><span class="pre">strategy.run</span></code> will distribute the datasets on multiple replicas.</p>
</div>
<div class="section" id="Dispatch-training-steps-to-remote-workers">
<h3>Dispatch training steps to remote workers<a class="headerlink" href="#Dispatch-training-steps-to-remote-workers" title="Enlazar permanentemente con este título">¶</a></h3>
<p>After all the computations are defined by <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code>, we will use the <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> class to create resources and distribute the training steps to remote workers.</p>
<p>Let’s first create a <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> object and pass in the strategy object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">coordinator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">coordinator</span><span class="o">.</span><span class="n">ClusterCoordinator</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Then we create a per-worker dataset and an iterator. In the <code class="docutils literal notranslate"><span class="pre">per_worker_dataset_fn</span></code> below, wrapping the <code class="docutils literal notranslate"><span class="pre">dataset_fn</span></code> into <code class="docutils literal notranslate"><span class="pre">strategy.distribute_datasets_from_function</span></code> is recommended to allow efficient prefetching to GPUs seamlessly.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">per_worker_dataset_fn</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">strategy</span><span class="o">.</span><span class="n">distribute_datasets_from_function</span><span class="p">(</span><span class="n">dataset_fn</span><span class="p">)</span>

<span class="n">per_worker_dataset</span> <span class="o">=</span> <span class="n">coordinator</span><span class="o">.</span><span class="n">create_per_worker_dataset</span><span class="p">(</span><span class="n">per_worker_dataset_fn</span><span class="p">)</span>
<span class="n">per_worker_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">per_worker_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The final step is to distribute the computation to remote workers using <code class="docutils literal notranslate"><span class="pre">schedule</span></code>. The <code class="docutils literal notranslate"><span class="pre">schedule</span></code> method enqueues a <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> and returns a future-like <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code> immediately. The queued functions will be dispatched to remote workers in background threads and the <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code> will be filled asynchronously. The <code class="docutils literal notranslate"><span class="pre">join</span></code> method can be used to wait until all scheduled functions are excuted.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">num_epoches</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epoches</span><span class="p">):</span>
  <span class="n">accuracy</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps_per_epoch</span><span class="p">):</span>
    <span class="n">coordinator</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">step_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">per_worker_iterator</span><span class="p">,))</span>
  <span class="c1"># Wait at epoch boundaries.</span>
  <span class="n">coordinator</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
  <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Finished epoch </span><span class="si">%d</span><span class="s2">, accuracy is </span><span class="si">%f</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<p>Here is how you can fetch the result of a <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">coordinator</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">step_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">per_worker_iterator</span><span class="p">,))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Final loss is </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">loss</span><span class="o">.</span><span class="n">fetch</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>Alternatively, you can launch all steps and do something while waiting for completion:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
  <span class="n">coordinator</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">step_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">per_worker_iterator</span><span class="p">,))</span>
<span class="k">while</span> <span class="ow">not</span> <span class="n">coordinator</span><span class="o">.</span><span class="n">done</span><span class="p">():</span>
  <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
  <span class="c1"># Do something like logging metrics or writing checkpoints.</span>
</pre></div>
</div>
<p>For the complete training and serving workflow for this particular example, please check out this <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/distribute/parameter_server_training_test.py">test</a>.</p>
</div>
<div class="section" id="More-about-dataset-creation">
<h3>More about dataset creation<a class="headerlink" href="#More-about-dataset-creation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The dataset in the above code is created using the <code class="docutils literal notranslate"><span class="pre">create_per_worker_dataset</span></code> API. It creates one dataset per worker and returns a container object. You can call <code class="docutils literal notranslate"><span class="pre">iter</span></code> method on it to create a per-worker iterator. The per-worker iterator contains one iterator per worker and the corresponding slice of a worker will be substituted in the input argument of the function passed to the <code class="docutils literal notranslate"><span class="pre">schedule</span></code> method before the function is executed on a particular worker.</p>
<p>Currently the <code class="docutils literal notranslate"><span class="pre">schedule</span></code> method assumes workers are equivalent and thus assumes the datasets on different workers are the same except they may be shuffled differently if they contain a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle">dataset.shuffle</a> operation. Because of this, we also recommend the datasets to be repeated indefinitely and schedule a finite number of steps instead of relying on the <code class="docutils literal notranslate"><span class="pre">OutOfRangeError</span></code> from a dataset.</p>
<p>Another important note is that <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> datasets don’t support implicit serialization and deserialization across task boundaries. So it is important to create the whole dataset inside the function passed to <code class="docutils literal notranslate"><span class="pre">create_per_worker_dataset</span></code>.</p>
</div>
<div class="section" id="Variable-sharding">
<h3>Variable sharding<a class="headerlink" href="#Variable-sharding" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Variable sharding refers to splitting a variable into multiple smaller variables. We call these smaller variables <em>shard</em>s. Variable sharding may be useful to distribute the network load when accessing these shards. It is also useful to distribute computation and storage of a normal variable across multiple parameter servers.</p>
<p>To enable variable sharding, you can pass in a <code class="docutils literal notranslate"><span class="pre">variable_partitioner</span></code> when constructing a <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code> object. The <code class="docutils literal notranslate"><span class="pre">variable_partitioner</span></code> will be invoked every time when a variable is created and it is expected to return the number of shards along each dimension of the variable. Some out-of-box <code class="docutils literal notranslate"><span class="pre">variable_partitioner</span></code>s are provided such as <code class="docutils literal notranslate"><span class="pre">tf.distribute.experimental.partitioners.FixedShardsPartitioner</span></code>.</p>
<p>In the above example, we use the <code class="docutils literal notranslate"><span class="pre">FixedShardsPartitioner</span></code> which will split all variables into two shards and each shard will be assigned to different parameter servers:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">emb_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
<span class="k">assert</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;/job:ps/replica:0/task:0/device:CPU:0&quot;</span>
<span class="k">assert</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;/job:ps/replica:0/task:1/device:CPU:0&quot;</span>
</pre></div>
</div>
</div>
<p>When a <code class="docutils literal notranslate"><span class="pre">variable_partitioner</span></code> is passed in and if you create a variable directly under <code class="docutils literal notranslate"><span class="pre">strategy.scope()</span></code>, it will become a container type with a <code class="docutils literal notranslate"><span class="pre">variables</span></code> property which provides access to the list of shards. In most cases, this container will be automatically converted to a Tensor by concatenating all the shards. As a result, it can be used as a normal variable. On the other hand, some TensorFlow methods such as <code class="docutils literal notranslate"><span class="pre">tf.nn.embedding_lookup</span></code> provide efficient implementation for this
container type and in these methods automatic concatenation will be avoided.</p>
<p>Please see the API docstring of <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code> for more details.</p>
</div>
</div>
<div class="section" id="Evaluation">
<h2>Evaluation<a class="headerlink" href="#Evaluation" title="Enlazar permanentemente con este título">¶</a></h2>
<p>There are more than one way to define and run an evaluation loop in distributed training. Each has its own pros and cons as described below. The inline evaluation method is recommended if you don’t have a preference.</p>
<div class="section" id="Inline-evaluation">
<h3>Inline evaluation<a class="headerlink" href="#Inline-evaluation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>In this method the coordinator alternates between training and evaluation and thus we call it inline evaluation. There are several benefits of inline evaluation. For example, it can support large evaluation models and evaluation datasets that a single task cannot hold. For another example, the evaluation results can be used to make decisions for training next epoch.</p>
<p>There are two ways to implement inline evaluation:</p>
<ul class="simple">
<li><p><strong>Direct evaluation</strong> - For small models and evaluation datasets the coordinator can run evaluation directly on the distributed model with the evaluation dataset on the coordinator:</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
      <span class="n">feature_and_label_gen</span><span class="p">(</span><span class="n">num_examples</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span>
              <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">feature_preprocess_stage</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])},</span>
              <span class="n">label_preprocess_stage</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
          <span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>

<span class="n">eval_accuracy</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">eval_dataset</span><span class="p">:</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">actual_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">eval_accuracy</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">actual_pred</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Evaluation accuracy: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">eval_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p><strong>Distributed evaluation</strong> - For large models or datasets that are infeasible to run directly on the coordinator, the coordinator task can distribute evaluation tasks to the workers via the <code class="docutils literal notranslate"><span class="pre">schedule</span></code>/<code class="docutils literal notranslate"><span class="pre">join</span></code> methods:</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
  <span class="c1"># Define the eval metric on parameter servers.</span>
  <span class="n">eval_accuracy</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">eval_step</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">replica_fn</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">actual_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">eval_accuracy</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">actual_pred</span><span class="p">)</span>
  <span class="n">batch_data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
  <span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">replica_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">eval_dataset_fn</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
      <span class="n">feature_and_label_gen</span><span class="p">(</span><span class="n">num_examples</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span>
              <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">feature_preprocess_stage</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])},</span>
              <span class="n">label_preprocess_stage</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
          <span class="p">))</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>

<span class="n">per_worker_eval_dataset</span> <span class="o">=</span> <span class="n">coordinator</span><span class="o">.</span><span class="n">create_per_worker_dataset</span><span class="p">(</span><span class="n">eval_dataset_fn</span><span class="p">)</span>
<span class="n">per_worker_eval_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">per_worker_eval_dataset</span><span class="p">)</span>

<span class="n">eval_steps_per_epoch</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_steps_per_epoch</span><span class="p">):</span>
  <span class="n">coordinator</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">eval_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">per_worker_eval_iterator</span><span class="p">,))</span>
<span class="n">coordinator</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Evaluation accuracy: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">eval_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>Note: currently the <code class="docutils literal notranslate"><span class="pre">schedule</span></code>/<code class="docutils literal notranslate"><span class="pre">join</span></code> methods don’t support visitation guarantee or exactly-once semantics. In other words, there is no guarantee that all evaluation examples in a dataset will be evaluated exactly once; some may not be visited and some may be evaluated multiple times. Visitation guarantee on evaluation dataset is being worked on.</p>
</div>
<div class="section" id="Side-car-evaluation">
<h3>Side-car evaluation<a class="headerlink" href="#Side-car-evaluation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Another method is called side-car evaluation which is to create a dedicated evaluator task that repeatedly reads checkpoints and runs evaluation on a latest checkpoint. It allows your training program to finish early if you don’t need to change your training loop based on evaluation results. However, it requires an additional evaluator task and periodic checkpointing to trigger evaluation. Following is a possible side-car evaluation loop:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">eval_model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">eval_data</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">eval_model</span><span class="p">)</span>

<span class="k">for</span> <span class="n">latest_checkpoint</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">checkpoints_iterator</span><span class="p">(</span>
    <span class="n">checkpoint_dir</span><span class="p">):</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">latest_checkpoint</span><span class="p">)</span><span class="o">.</span><span class="n">expect_partial</span><span class="p">()</span>
  <span class="k">except</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">OpError</span><span class="p">,)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="c1"># checkpoint may be deleted by training when it is about to read it.</span>
    <span class="k">continue</span>

  <span class="c1"># Optionally add callbacks to write summaries.</span>
  <span class="n">eval_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>

  <span class="c1"># Evaluation finishes when it has evaluated the last epoch.</span>
  <span class="k">if</span> <span class="n">latest_checkpoint</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;-</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_epoches</span><span class="p">)):</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Clusters-in-Real-world">
<h2>Clusters in Real-world<a class="headerlink" href="#Clusters-in-Real-world" title="Enlazar permanentemente con este título">¶</a></h2>
<p>In a real production environment, you will run all tasks in different processes on different machines. The simplest way to configure cluster information on each task is to set “TF_CONFIG” environment variables and use <code class="docutils literal notranslate"><span class="pre">TFConfigClusterResolver</span></code> to parse “TF_CONFIG”. For a general description about “TF_CONFIG” environment variables, please see the <a class="reference external" href="https://www.tensorflow.org/guide/distributed_training#setting_up_tf_config_environment_variable">distributed training guide</a>.</p>
<p>If you start your training tasks using Kubernetes or other configuration templates, it is very likely that these templates have already set “TF_CONFIG” for you.</p>
<div class="section" id="Set-“TF_CONFIG”-environment-variable">
<h3>Set “TF_CONFIG” environment variable<a class="headerlink" href="#Set-“TF_CONFIG”-environment-variable" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Suppose you have 3 workers and 2 parameter servers, the “TF_CONFIG” of worker 1 can be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_CONFIG&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
    <span class="s2">&quot;cluster&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;host1:port&quot;</span><span class="p">,</span> <span class="s2">&quot;host2:port&quot;</span><span class="p">,</span> <span class="s2">&quot;host3:port&quot;</span><span class="p">],</span>
        <span class="s2">&quot;ps&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;host4:port&quot;</span><span class="p">,</span> <span class="s2">&quot;host5:port&quot;</span><span class="p">],</span>
        <span class="s2">&quot;chief&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;host6:port&quot;</span><span class="p">]</span>
    <span class="p">},</span>
   <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;worker&quot;</span><span class="p">,</span> <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="p">})</span>
</pre></div>
</div>
<p>The “TF_CONFIG” of the evaluator can be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_CONFIG&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
    <span class="s2">&quot;cluster&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;evaluator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;host7:port&quot;</span><span class="p">]</span>
    <span class="p">},</span>
   <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;evaluator&quot;</span><span class="p">,</span> <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="p">})</span>
</pre></div>
</div>
<p>The “cluster” part in the above “TF_CONFIG” string for the evaluator is optional.</p>
</div>
<div class="section" id="If-you-use-the-same-binary-for-all-tasks">
<h3>If you use the same binary for all tasks<a class="headerlink" href="#If-you-use-the-same-binary-for-all-tasks" title="Enlazar permanentemente con este título">¶</a></h3>
<p>If you prefer to run all these tasks using a single binary, you will need to let your program branch into different roles at the very beginning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cluster_resolver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">TFConfigClusterResolver</span><span class="p">()</span>
<span class="k">if</span> <span class="n">cluster_resolver</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;worker&quot;</span><span class="p">,</span> <span class="s2">&quot;ps&quot;</span><span class="p">):</span>
  <span class="c1"># start a TensorFlow server and wait.</span>
<span class="k">elif</span> <span class="n">cluster_resolver</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;evaluator&quot;</span><span class="p">:</span>
  <span class="c1"># run side-car evaluation</span>
<span class="k">else</span><span class="p">:</span>
  <span class="c1"># run the coordinator.</span>
</pre></div>
</div>
<p>The following code starts a TensorFlow server and waits:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the environment variable to allow reporting worker and ps failure to the</span>
<span class="c1"># coordinator. This is a workaround and won&#39;t be necessary in the future.</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;GRPC_FAIL_FAST&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;use_caller&quot;</span>

<span class="n">cluster_resolver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">TF_ConfigClusterResolver</span><span class="p">()</span>
<span class="n">server</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span>
    <span class="n">cluster_resolver</span><span class="o">.</span><span class="n">cluster_spec</span><span class="p">(),</span>
    <span class="n">job_name</span><span class="o">=</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">task_type</span><span class="p">,</span>
    <span class="n">task_index</span><span class="o">=</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span>
    <span class="n">protocol</span><span class="o">=</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">rpc_layer</span> <span class="ow">or</span> <span class="s2">&quot;grpc&quot;</span><span class="p">,</span>
    <span class="n">start</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">server</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Handling-Task-Failure">
<h2>Handling Task Failure<a class="headerlink" href="#Handling-Task-Failure" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Worker-failure">
<h3>Worker failure<a class="headerlink" href="#Worker-failure" title="Enlazar permanentemente con este título">¶</a></h3>
<p>As mentioned above, the <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator</span></code> has built-in fault tolerance for worker failure. Upon worker recovery, the corresponding slice of datasets created by <code class="docutils literal notranslate"><span class="pre">create_per_worker_dataset</span></code> that are still in scope will be recreated by invoking its original <code class="docutils literal notranslate"><span class="pre">dataset_fn</span></code> passed to <code class="docutils literal notranslate"><span class="pre">create_per_worker_dataset</span></code>.</p>
</div>
<div class="section" id="Parameter-server-or-the-coordinator-failure">
<h3>Parameter server or the coordinator failure<a class="headerlink" href="#Parameter-server-or-the-coordinator-failure" title="Enlazar permanentemente con este título">¶</a></h3>
<p>However, when the coordinator sees a parameter server error, it will raise an <code class="docutils literal notranslate"><span class="pre">UnavailableError</span></code> or <code class="docutils literal notranslate"><span class="pre">AbortedError</span></code> immediately. You can restart the coordinator in this case. The coordinator itself can also become unavailable. Therefore, in order to not lose much of the training progress, it is important to checkpoint the model variables periodically and load model variables from a checkpoint, if any, before training starts. The training progress can be inferred approximately from
<code class="docutils literal notranslate"><span class="pre">optimizer.iterations</span></code> if an optimizer is checkpointed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">checkpoint_manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">),</span>
    <span class="n">checkpoint_dir</span><span class="p">,</span>
    <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">if</span> <span class="n">checkpoint_manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
  <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">checkpoint_manager</span><span class="o">.</span><span class="n">checkpoint</span>
  <span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span>
      <span class="n">checkpoint_manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span><span class="o">.</span><span class="n">assert_existing_objects_matched</span><span class="p">()</span>

<span class="n">global_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">starting_epoch</span> <span class="o">=</span> <span class="n">global_steps</span> <span class="o">//</span> <span class="n">steps_per_epoch</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">starting_epoch</span><span class="p">,</span> <span class="n">num_epoches</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps_per_epoch</span><span class="p">):</span>
    <span class="n">coordinator</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">step_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">per_worker_iterator</span><span class="p">,))</span>
  <span class="n">coordinator</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
  <span class="n">checkpoint_manager</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="Fetching-a-RemoteValue">
<h3>Fetching a <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code><a class="headerlink" href="#Fetching-a-RemoteValue" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Fetching a <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code> is guaranteed to succeed if a function is executed successfully. This is because currently the return value is immediately copied to the coordinator after a function is executed. If there is any worker failure during the copy, the function will be retried on another available worker. Therefore, if you want to optimize for performance, you can schedule functions without a return value.</p>
</div>
</div>
<div class="section" id="Error-Reporting">
<h2>Error Reporting<a class="headerlink" href="#Error-Reporting" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Once the coordinator sees an error such as <code class="docutils literal notranslate"><span class="pre">UnavailableError</span></code> from parameter servers or other application errors such as an <code class="docutils literal notranslate"><span class="pre">InvalidArgument</span></code> from <code class="docutils literal notranslate"><span class="pre">tf.debugging.check_numerics</span></code>, it will cancel all pending and queued functions before raising the error. Fetching their corresponding <code class="docutils literal notranslate"><span class="pre">RemoteValue</span></code>s will raise a <code class="docutils literal notranslate"><span class="pre">CancelledError</span></code>.</p>
<p>After an error is raised, the coordinator will not raise the same error or any error from cancelled functions.</p>
</div>
<div class="section" id="Performance-Improvement">
<h2>Performance Improvement<a class="headerlink" href="#Performance-Improvement" title="Enlazar permanentemente con este título">¶</a></h2>
<p>There are several possible reasons if you see performance issues when you train with <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code> and <code class="docutils literal notranslate"><span class="pre">ClusterResolver</span></code>.</p>
<p>One common reason is parameter servers have unbalanced load and some heavily-loaded parameter servers have reached capacity. There can also be multiple root causes. Some simple methods to mitigate this issue are to</p>
<ol class="arabic simple">
<li><p>shard your large model variables via specifying a <code class="docutils literal notranslate"><span class="pre">variable_partitioner</span></code> when constructing a <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code>.</p></li>
<li><p>avoid creating a hotspot variable that is required by all parameter servers in a single step if possible. For example, use a constant learning rate or subclass <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.schedules.LearningRateSchedule</span></code> in optimizers since the default behavior is that the learning rate will become a variable placed on a particular parameter server and requested by all other parameter servers in each step.</p></li>
<li><p>shuffle your large vocabularies before passing them to Keras preprocessing layers.</p></li>
</ol>
<p>Another possible reason for performance issues is the coordinator. Our first implementation of <code class="docutils literal notranslate"><span class="pre">schedule</span></code>/<code class="docutils literal notranslate"><span class="pre">join</span></code> is Python-based and thus may have threading overhead. Also the latency between the coordinator and the workers can be large. If this is the case, you can pack multiple steps into a single <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>steps_per_invocation = 10
@tf.function
def step_fn(iterator):
  for _ in range(steps_per_invocation):
    features, labels = next(iterator)
    def replica_fn(features, labels):
      ...

    strategy.run(replica_fn, args=(features, labels))
</pre></div>
</div>
<p>We will keep optimizing the coordinator and hopefully most users don’t have to manually pack steps in the future.</p>
<p>In addition, a small trick for performance improvement is to schedule functions without a return value as explained in the handling task failure section above.</p>
</div>
<div class="section" id="Known-Limitations">
<h2>Known Limitations<a class="headerlink" href="#Known-Limitations" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Most of the known limitations are covered in above sections. Here is a summary: * <code class="docutils literal notranslate"><span class="pre">os.environment[&quot;grpc_fail_fast&quot;]=&quot;use_caller&quot;</span></code> is needed on every task, including the coordinator, to make fault tolerance work properly. * Synchronous parameter server training is not supported. * <code class="docutils literal notranslate"><span class="pre">ParameterServerStrategy</span></code> doesn’t work with Keras <code class="docutils literal notranslate"><span class="pre">compile</span></code> and <code class="docutils literal notranslate"><span class="pre">fit</span></code> APIs. * <code class="docutils literal notranslate"><span class="pre">ClusterCoordinator.schedule</span></code> doesn’t support visitation guarantees for a dataset. * When
<code class="docutils literal notranslate"><span class="pre">ClusterCoordinator.create_per_worker_dataset</span></code> is used, the whole dataset must be created inside the function passed to it. * It is usually necessary to pack multiple steps into a single function to achieve optimal performance. * It is not supported to load a saved_model via <code class="docutils literal notranslate"><span class="pre">tf.saved_model.load</span></code> containing sharded variables. Note loading such a saved_model using TensorFlow Serving is expected to work. * It is not supported to load a checkpoint containg sharded optimizer slot variables
into a different number of shards. * It is not supported to recover from parameter server failure without restarting the coordinator task.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>