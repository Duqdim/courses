

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Custom training: walkthrough &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-texto/index.html">Analítica de Texto</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Custom training: walkthrough</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Customization/1-03_custom_training_walkthrough.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Custom-training:-walkthrough">
<h1>Custom training: walkthrough<a class="headerlink" href="#Custom-training:-walkthrough" title="Enlazar permanentemente con este título">¶</a></h1>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>fff62a5bb87e4a40bf7a44a274ccfbc9|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>dd7aa67015394a4ab5662a717b9b8704|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>d2356646200e42e9b99b06244f202052|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>f2ed2953acdd4194ab14cdc06b7e5532|Download notebook</p>
</td></table><p>This guide uses machine learning to <em>categorize</em> Iris flowers by species. It uses TensorFlow to: 1. Build a model, 2. Train this model on example data, and 3. Use the model to make predictions about unknown data.</p>
<div class="section" id="TensorFlow-programming">
<h2>TensorFlow programming<a class="headerlink" href="#TensorFlow-programming" title="Enlazar permanentemente con este título">¶</a></h2>
<p>This guide uses these high-level TensorFlow concepts:</p>
<ul class="simple">
<li><p>Use TensorFlow’s default <a class="reference internal" href="../../guide/eager.html"><span class="doc">eager execution</span></a> development environment,</p></li>
<li><p>Import data with the <a class="reference external" href="../../guide/datasets.ipynb">Datasets API</a>,</p></li>
<li><p>Build models and layers with TensorFlow’s <a class="reference external" href="../../guide/keras/overview.ipynb">Keras API</a>.</p></li>
</ul>
<p>This tutorial is structured like many TensorFlow programs:</p>
<ol class="arabic simple">
<li><p>Import and parse the dataset.</p></li>
<li><p>Select the type of model.</p></li>
<li><p>Train the model.</p></li>
<li><p>Evaluate the model’s effectiveness.</p></li>
<li><p>Use the trained model to make predictions.</p></li>
</ol>
</div>
<div class="section" id="Setup-program">
<h2>Setup program<a class="headerlink" href="#Setup-program" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Configure-imports">
<h3>Configure imports<a class="headerlink" href="#Configure-imports" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Import TensorFlow and the other required Python modules. By default, TensorFlow uses <a class="reference internal" href="../../guide/eager.html"><span class="doc">eager execution</span></a> to evaluate operations immediately, returning concrete values instead of creating a computational graph that is executed later. If you are used to a REPL or the <code class="docutils literal notranslate"><span class="pre">python</span></code> interactive console, this feels familiar.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TensorFlow version: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eager execution: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="The-Iris-classification-problem">
<h2>The Iris classification problem<a class="headerlink" href="#The-Iris-classification-problem" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Imagine you are a botanist seeking an automated way to categorize each Iris flower you find. Machine learning provides many algorithms to classify flowers statistically. For instance, a sophisticated machine learning program could classify flowers based on photographs. Our ambitions are more modest—we’re going to classify Iris flowers based on the length and width measurements of their <a class="reference external" href="https://en.wikipedia.org/wiki/Sepal">sepals</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Petal">petals</a>.</p>
<p>The Iris genus entails about 300 species, but our program will only classify the following three:</p>
<ul class="simple">
<li><p>Iris setosa</p></li>
<li><p>Iris virginica</p></li>
<li><p>Iris versicolor</p></li>
</ul>
<table><tr><td><p><img alt="Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor" src="https://www.tensorflow.org/images/iris_three_species.jpg" /></p>
</td></tr><tr><td align="center"><p>Figure 1. Iris setosa (by Radomil, CC BY-SA 3.0), Iris versicolor, (by Dlanglois, CC BY-SA 3.0), and Iris virginica (by Frank Mayfield, CC BY-SA 2.0).</p>
</td></tr></table><p>Fortunately, someone has already created a <a class="reference external" href="https://en.wikipedia.org/wiki/Iris_flower_data_set">dataset of 120 Iris flowers</a> with the sepal and petal measurements. This is a classic dataset that is popular for beginner machine learning classification problems.</p>
</div>
<div class="section" id="Import-and-parse-the-training-dataset">
<h2>Import and parse the training dataset<a class="headerlink" href="#Import-and-parse-the-training-dataset" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Download the dataset file and convert it into a structure that can be used by this Python program.</p>
<div class="section" id="Download-the-dataset">
<h3>Download the dataset<a class="headerlink" href="#Download-the-dataset" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Download the training dataset file using the <code class="docutils literal notranslate"><span class="pre">tf.keras.utils.get_file</span></code> function. This returns the file path of the downloaded file:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_dataset_url</span> <span class="o">=</span> <span class="s2">&quot;https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv&quot;</span>

<span class="n">train_dataset_fp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">train_dataset_url</span><span class="p">),</span>
                                           <span class="n">origin</span><span class="o">=</span><span class="n">train_dataset_url</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Local copy of the dataset file: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_dataset_fp</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Inspect-the-data">
<h3>Inspect the data<a class="headerlink" href="#Inspect-the-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>This dataset, <code class="docutils literal notranslate"><span class="pre">iris_training.csv</span></code>, is a plain text file that stores tabular data formatted as comma-separated values (CSV). Use the <code class="docutils literal notranslate"><span class="pre">head</span> <span class="pre">-n5</span></code> command to take a peek at the first five entries:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>head -n5 <span class="o">{</span>train_dataset_fp<span class="o">}</span>
</pre></div>
</div>
</div>
<p>From this view of the dataset, notice the following:</p>
<ol class="arabic simple">
<li><p>The first line is a header containing information about the dataset:</p></li>
</ol>
<ul class="simple">
<li><p>There are 120 total examples. Each example has four features and one of three possible label names.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Subsequent rows are data records, one <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#example">example</a> per line, where:</p></li>
</ol>
<ul class="simple">
<li><p>The first four fields are <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#feature">features</a>: these are the characteristics of an example. Here, the fields hold float numbers representing flower measurements.</p></li>
<li><p>The last column is the <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#label">label</a>: this is the value we want to predict. For this dataset, it’s an integer value of 0, 1, or 2 that corresponds to a flower name.</p></li>
</ul>
<p>Let’s write that out in code:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># column order in CSV file</span>
<span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;species&#39;</span><span class="p">]</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="n">column_names</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">label_name</span> <span class="o">=</span> <span class="n">column_names</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Features: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature_names</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label_name</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Each label is associated with string name (for example, “setosa”), but machine learning typically relies on numeric values. The label numbers are mapped to a named representation, such as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">0</span></code>: Iris setosa</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code>: Iris versicolor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">2</span></code>: Iris virginica</p></li>
</ul>
<p>For more information about features and labels, see the <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/framing/ml-terminology">ML Terminology section of the Machine Learning Crash Course</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Iris setosa&#39;</span><span class="p">,</span> <span class="s1">&#39;Iris versicolor&#39;</span><span class="p">,</span> <span class="s1">&#39;Iris virginica&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Create-a-tf.data.Dataset">
<h3>Create a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code><a class="headerlink" href="#Create-a-tf.data.Dataset" title="Enlazar permanentemente con este título">¶</a></h3>
<p>TensorFlow’s <a class="reference internal" href="../../guide/data.html"><span class="doc">Dataset API</span></a> handles many common cases for loading data into a model. This is a high-level API for reading data and transforming it into a form used for training.</p>
<p>Since the dataset is a CSV-formatted text file, use the <code class="docutils literal notranslate"><span class="pre">tf.data.experimental.make_csv_dataset</span></code> function to parse the data into a suitable format. Since this function generates data for training models, the default behavior is to shuffle the data (<code class="docutils literal notranslate"><span class="pre">shuffle=True,</span> <span class="pre">shuffle_buffer_size=10000</span></code>), and repeat the dataset forever (<code class="docutils literal notranslate"><span class="pre">num_epochs=None</span></code>). We also set the <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#batch_size">batch_size</a> parameter:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">make_csv_dataset</span><span class="p">(</span>
    <span class="n">train_dataset_fp</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
    <span class="n">label_name</span><span class="o">=</span><span class="n">label_name</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">make_csv_dataset</span></code> function returns a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> of <code class="docutils literal notranslate"><span class="pre">(features,</span> <span class="pre">label)</span></code> pairs, where <code class="docutils literal notranslate"><span class="pre">features</span></code> is a dictionary: <code class="docutils literal notranslate"><span class="pre">{'feature_name':</span> <span class="pre">value}</span></code></p>
<p>These <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> objects are iterable. Let’s look at a batch of features:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Notice that like-features are grouped together, or <em>batched</em>. Each example row’s fields are appended to the corresponding feature array. Change the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> to set the number of examples stored in these feature arrays.</p>
<p>You can start to see some clusters by plotting a few features from the batch:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">],</span>
            <span class="n">features</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Petal length&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Sepal length&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>To simplify the model building step, create a function to repackage the features dictionary into a single array with shape: <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_features)</span></code>.</p>
<p>This function uses the <code class="docutils literal notranslate"><span class="pre">tf.stack</span></code> method which takes values from a list of tensors and creates a combined tensor at the specified dimension:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">pack_features_vector</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Pack the features into a single array.&quot;&quot;&quot;</span>
  <span class="n">features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span>
</pre></div>
</div>
</div>
<p>Then use the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset#map</span></code> method to pack the <code class="docutils literal notranslate"><span class="pre">features</span></code> of each <code class="docutils literal notranslate"><span class="pre">(features,label)</span></code> pair into the training dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">pack_features_vector</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The features element of the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> are now arrays with shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">num_features)</span></code>. Let’s look at the first few examples:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Select-the-type-of-model">
<h2>Select the type of model<a class="headerlink" href="#Select-the-type-of-model" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Why-model?">
<h3>Why model?<a class="headerlink" href="#Why-model?" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#model">model</a> is a relationship between features and the label. For the Iris classification problem, the model defines the relationship between the sepal and petal measurements and the predicted Iris species. Some simple models can be described with a few lines of algebra, but complex machine learning models have a large number of parameters that are difficult to summarize.</p>
<p>Could you determine the relationship between the four features and the Iris species <em>without</em> using machine learning? That is, could you use traditional programming techniques (for example, a lot of conditional statements) to create a model? Perhaps—if you analyzed the dataset long enough to determine the relationships between petal and sepal measurements to a particular species. And this becomes difficult—maybe impossible—on more complicated datasets. A good machine learning approach
<em>determines the model for you</em>. If you feed enough representative examples into the right machine learning model type, the program will figure out the relationships for you.</p>
</div>
<div class="section" id="Select-the-model">
<h3>Select the model<a class="headerlink" href="#Select-the-model" title="Enlazar permanentemente con este título">¶</a></h3>
<p>We need to select the kind of model to train. There are many types of models and picking a good one takes experience. This tutorial uses a neural network to solve the Iris classification problem. <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#neural_network">Neural networks</a> can find complex relationships between features and the label. It is a highly-structured graph, organized into one or more <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#hidden_layer">hidden
layers</a>. Each hidden layer consists of one or more <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#neuron">neurons</a>. There are several categories of neural networks and this program uses a dense, or <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#fully_connected_layer">fully-connected neural network</a>: the neurons in one layer receive input connections from <em>every</em> neuron in the previous layer. For
example, Figure 2 illustrates a dense neural network consisting of an input layer, two hidden layers, and an output layer:</p>
<table><tr><td><p><img alt="A diagram of the network architecture: Inputs, 2 hidden layers, and outputs" src="https://www.tensorflow.org/images/custom_estimators/full_network.png" /></p>
</td></tr><tr><td align="center"><p>Figure 2. A neural network with features, hidden layers, and predictions.</p>
</td></tr></table><p>When the model from Figure 2 is trained and fed an unlabeled example, it yields three predictions: the likelihood that this flower is the given Iris species. This prediction is called <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#inference">inference</a>. For this example, the sum of the output predictions is 1.0. In Figure 2, this prediction breaks down as: <code class="docutils literal notranslate"><span class="pre">0.02</span></code> for <em>Iris setosa</em>, <code class="docutils literal notranslate"><span class="pre">0.95</span></code> for <em>Iris versicolor</em>, and <code class="docutils literal notranslate"><span class="pre">0.03</span></code> for <em>Iris virginica</em>. This means that the
model predicts—with 95% probability—that an unlabeled example flower is an <em>Iris versicolor</em>.</p>
</div>
<div class="section" id="Create-a-model-using-Keras">
<h3>Create a model using Keras<a class="headerlink" href="#Create-a-model-using-Keras" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The TensorFlow <code class="docutils literal notranslate"><span class="pre">tf.keras</span></code> API is the preferred way to create models and layers. This makes it easy to build models and experiment while Keras handles the complexity of connecting everything together.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.keras.Sequential</span></code> model is a linear stack of layers. Its constructor takes a list of layer instances, in this case, two <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Dense</span></code> layers with 10 nodes each, and an output layer with 3 nodes representing our label predictions. The first layer’s <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> parameter corresponds to the number of features from the dataset, and is required:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,)),</span>  <span class="c1"># input shape required</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
<p>The <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#activation_function">activation function</a> determines the output shape of each node in the layer. These non-linearities are important—without them the model would be equivalent to a single layer. There are many <code class="docutils literal notranslate"><span class="pre">tf.keras.activations</span></code>, but <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#ReLU">ReLU</a> is common for hidden layers.</p>
<p>The ideal number of hidden layers and neurons depends on the problem and the dataset. Like many aspects of machine learning, picking the best shape of the neural network requires a mixture of knowledge and experimentation. As a rule of thumb, increasing the number of hidden layers and neurons typically creates a more powerful model, which requires more data to train effectively.</p>
</div>
<div class="section" id="Using-the-model">
<h3>Using the model<a class="headerlink" href="#Using-the-model" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Let’s have a quick look at what this model does to a batch of features:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">predictions</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Here, each example returns a <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#logits">logit</a> for each class.</p>
<p>To convert these logits to a probability for each class, use the <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#softmax">softmax</a> function:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>Taking the <code class="docutils literal notranslate"><span class="pre">tf.argmax</span></code> across classes gives us the predicted class index. But, the model hasn’t been trained yet, so these aren’t good predictions:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    Labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Train-the-model">
<h2>Train the model<a class="headerlink" href="#Train-the-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p><a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#training">Training</a> is the stage of machine learning when the model is gradually optimized, or the model <em>learns</em> the dataset. The goal is to learn enough about the structure of the training dataset to make predictions about unseen data. If you learn <em>too much</em> about the training dataset, then the predictions only work for the data it has seen and will not be generalizable. This problem is called
<a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#overfitting">overfitting</a>—it’s like memorizing the answers instead of understanding how to solve a problem.</p>
<p>The Iris classification problem is an example of <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#supervised_machine_learning">supervised machine learning</a>: the model is trained from examples that contain labels. In <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#unsupervised_machine_learning">unsupervised machine learning</a>, the examples don’t contain labels. Instead, the model typically finds patterns among the features.</p>
<div class="section" id="Define-the-loss-and-gradient-function">
<h3>Define the loss and gradient function<a class="headerlink" href="#Define-the-loss-and-gradient-function" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Both training and evaluation stages need to calculate the model’s <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#loss">loss</a>. This measures how off a model’s predictions are from the desired label, in other words, how bad the model is performing. We want to minimize, or optimize, this value.</p>
<p>Our model will calculate its loss using the <code class="docutils literal notranslate"><span class="pre">tf.keras.losses.SparseCategoricalCrossentropy</span></code> function which takes the model’s class probability predictions and the desired label, and returns the average loss across the examples.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">training</span><span class="p">):</span>
  <span class="c1"># training=training is needed only if there are layers with different</span>
  <span class="c1"># behavior during training versus inference (e.g. Dropout).</span>
  <span class="n">y_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_</span><span class="p">)</span>


<span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss test: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code> context to calculate the <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#gradient">gradients</a> used to optimize your model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">loss_value</span><span class="p">,</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_value</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Create-an-optimizer">
<h3>Create an optimizer<a class="headerlink" href="#Create-an-optimizer" title="Enlazar permanentemente con este título">¶</a></h3>
<p>An <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#optimizer">optimizer</a> applies the computed gradients to the model’s variables to minimize the <code class="docutils literal notranslate"><span class="pre">loss</span></code> function. You can think of the loss function as a curved surface (see Figure 3) and we want to find its lowest point by walking around. The gradients point in the direction of steepest ascent—so we’ll travel the opposite way and move down the hill. By iteratively calculating the loss and gradient for each batch, we’ll
adjust the model during training. Gradually, the model will find the best combination of weights and bias to minimize loss. And the lower the loss, the better the model’s predictions.</p>
<table><tr><td><p><a class="no-scaled-link reference internal" href="https://cs231n.github.io/assets/nn3/opt1.gif"><img alt="Optimization algorithms visualized over time in 3D space." class="no-scaled-link" src="https://cs231n.github.io/assets/nn3/opt1.gif" style="width: 70%;" /></a></p>
</td></tr><tr><td align="center"><p>Figure 3. Optimization algorithms visualized over time in 3D space.(Source: Stanford class CS231n, MIT License, Image credit: Alec Radford)</p>
</td></tr></table><p>TensorFlow has many optimization algorithms available for training. This model uses the <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.SGD</span></code> that implements the <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent">stochastic gradient descent</a> (SGD) algorithm. The <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> sets the step size to take for each iteration down the hill. This is a <em>hyperparameter</em> that you’ll commonly adjust to achieve better results.</p>
<p>Let’s setup the optimizer:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We’ll use this to calculate a single optimization step:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss_value</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step: </span><span class="si">{}</span><span class="s2">, Initial Loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                                          <span class="n">loss_value</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

<span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step: </span><span class="si">{}</span><span class="s2">,         Loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                                          <span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-loop">
<h3>Training loop<a class="headerlink" href="#Training-loop" title="Enlazar permanentemente con este título">¶</a></h3>
<p>With all the pieces in place, the model is ready for training! A training loop feeds the dataset examples into the model to help it make better predictions. The following code block sets up these training steps:</p>
<ol class="arabic simple">
<li><p>Iterate each <em>epoch</em>. An epoch is one pass through the dataset.</p></li>
<li><p>Within an epoch, iterate over each example in the training <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> grabbing its <em>features</em> (<code class="docutils literal notranslate"><span class="pre">x</span></code>) and <em>label</em> (<code class="docutils literal notranslate"><span class="pre">y</span></code>).</p></li>
<li><p>Using the example’s features, make a prediction and compare it with the label. Measure the inaccuracy of the prediction and use that to calculate the model’s loss and gradients.</p></li>
<li><p>Use an <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> to update the model’s variables.</p></li>
<li><p>Keep track of some stats for visualization.</p></li>
<li><p>Repeat for each epoch.</p></li>
</ol>
<p>The <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> variable is the number of times to loop over the dataset collection. Counter-intuitively, training a model longer does not guarantee a better model. <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> is a <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#hyperparameter">hyperparameter</a> that you can tune. Choosing the right number usually requires both experience and experimentation:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">## Note: Rerunning this cell uses the same model variables</span>

<span class="c1"># Keep results for plotting</span>
<span class="n">train_loss_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_accuracy_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">201</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
  <span class="n">epoch_loss_avg</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">()</span>
  <span class="n">epoch_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>

  <span class="c1"># Training loop - using batches of 32</span>
  <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">:</span>
    <span class="c1"># Optimize the model</span>
    <span class="n">loss_value</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

    <span class="c1"># Track progress</span>
    <span class="n">epoch_loss_avg</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss_value</span><span class="p">)</span>  <span class="c1"># Add current batch loss</span>
    <span class="c1"># Compare predicted label to actual label</span>
    <span class="c1"># training=True is needed only if there are layers with different</span>
    <span class="c1"># behavior during training versus inference (e.g. Dropout).</span>
    <span class="n">epoch_accuracy</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

  <span class="c1"># End epoch</span>
  <span class="n">train_loss_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_loss_avg</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>
  <span class="n">train_accuracy_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">())</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:03d}</span><span class="s2">: Loss: </span><span class="si">{:.3f}</span><span class="s2">, Accuracy: </span><span class="si">{:.3%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span>
                                                                <span class="n">epoch_loss_avg</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span>
                                                                <span class="n">epoch_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Visualize-the-loss-function-over-time">
<h3>Visualize the loss function over time<a class="headerlink" href="#Visualize-the-loss-function-over-time" title="Enlazar permanentemente con este título">¶</a></h3>
<p>While it’s helpful to print out the model’s training progress, it’s often <em>more</em> helpful to see this progress. <a class="reference external" href="https://www.tensorflow.org/tensorboard">TensorBoard</a> is a nice visualization tool that is packaged with TensorFlow, but we can create basic charts using the <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> module.</p>
<p>Interpreting these charts takes some experience, but you really want to see the <em>loss</em> go down and the <em>accuracy</em> go up:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Training Metrics&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_loss_results</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_accuracy_results</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Evaluate-the-model’s-effectiveness">
<h2>Evaluate the model’s effectiveness<a class="headerlink" href="#Evaluate-the-model’s-effectiveness" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Now that the model is trained, we can get some statistics on its performance.</p>
<p><em>Evaluating</em> means determining how effectively the model makes predictions. To determine the model’s effectiveness at Iris classification, pass some sepal and petal measurements to the model and ask the model to predict what Iris species they represent. Then compare the model’s predictions against the actual label. For example, a model that picked the correct species on half the input examples has an <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#accuracy">accuracy</a> of <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.
Figure 4 shows a slightly more effective model, getting 4 out of 5 predictions correct at 80% accuracy:</p>
<table cellpadding="8" border="0"><colgroup><col span="4" ><col span="1" bgcolor="lightblue"><col span="1" bgcolor="lightgreen"></colgroup><tr bgcolor="lightgray"><th colspan="4"><p>Example features</p>
</th><th colspan="1"><p>Label</p>
</th><th colspan="1"><p>Model prediction</p>
</th></tr><tr><td><p>5.9</p>
</td><td><p>3.0</p>
</td><td><p>4.3</p>
</td><td><p>1.5</p>
</td><td align="center"><p>1</p>
</td><td align="center"><p>1</p>
</td></tr><tr><td><p>6.9</p>
</td><td><p>3.1</p>
</td><td><p>5.4</p>
</td><td><p>2.1</p>
</td><td align="center"><p>2</p>
</td><td align="center"><p>2</p>
</td></tr><tr><td><p>5.1</p>
</td><td><p>3.3</p>
</td><td><p>1.7</p>
</td><td><p>0.5</p>
</td><td align="center"><p>0</p>
</td><td align="center"><p>0</p>
</td></tr><tr><td><p>6.0</p>
</td><td><p>3.4</p>
</td><td><p>4.5</p>
</td><td><p>1.6</p>
</td><td align="center"><p>1</p>
</td><td align="center" bgcolor="red"><p>2</p>
</td></tr><tr><td><p>5.5</p>
</td><td><p>2.5</p>
</td><td><p>4.0</p>
</td><td><p>1.3</p>
</td><td align="center"><p>1</p>
</td><td align="center"><p>1</p>
</td></tr><tr><td align="center" colspan="6"><p>Figure 4. An Iris classifier that is 80% accurate.</p>
</td></tr></table><div class="section" id="Setup-the-test-dataset">
<h3>Setup the test dataset<a class="headerlink" href="#Setup-the-test-dataset" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Evaluating the model is similar to training the model. The biggest difference is the examples come from a separate <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/glossary#test_set">test set</a> rather than the training set. To fairly assess a model’s effectiveness, the examples used to evaluate a model must be different from the examples used to train the model.</p>
<p>The setup for the test <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> is similar to the setup for training <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>. Download the CSV text file and parse that values, then give it a little shuffle:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_url</span> <span class="o">=</span> <span class="s2">&quot;https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv&quot;</span>

<span class="n">test_fp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">test_url</span><span class="p">),</span>
                                  <span class="n">origin</span><span class="o">=</span><span class="n">test_url</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">make_csv_dataset</span><span class="p">(</span>
    <span class="n">test_fp</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
    <span class="n">label_name</span><span class="o">=</span><span class="s1">&#39;species&#39;</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">pack_features_vector</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Evaluate-the-model-on-the-test-dataset">
<h3>Evaluate the model on the test dataset<a class="headerlink" href="#Evaluate-the-model-on-the-test-dataset" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Unlike the training stage, the model only evaluates a single <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#epoch">epoch</a> of the test data. In the following code cell, we iterate over each example in the test set and compare the model’s prediction against the actual label. This is used to measure the model’s accuracy across the entire test set:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()</span>

<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="p">:</span>
  <span class="c1"># training=False is needed only if there are layers with different</span>
  <span class="c1"># behavior during training versus inference (e.g. Dropout).</span>
  <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">test_accuracy</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set accuracy: </span><span class="si">{:.3%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<p>We can see on the last batch, for example, the model is usually correct:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">y</span><span class="p">,</span><span class="n">prediction</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Use-the-trained-model-to-make-predictions">
<h2>Use the trained model to make predictions<a class="headerlink" href="#Use-the-trained-model-to-make-predictions" title="Enlazar permanentemente con este título">¶</a></h2>
<p>We’ve trained a model and “proven” that it’s good—but not perfect—at classifying Iris species. Now let’s use the trained model to make some predictions on <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#unlabeled_example">unlabeled examples</a>; that is, on examples that contain features but not a label.</p>
<p>In real-life, the unlabeled examples could come from lots of different sources including apps, CSV files, and data feeds. For now, we’re going to manually provide three unlabeled examples to predict their labels. Recall, the label numbers are mapped to a named representation as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">0</span></code>: Iris setosa</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code>: Iris versicolor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">2</span></code>: Iris virginica</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">predict_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">5.1</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,],</span>
    <span class="p">[</span><span class="mf">5.9</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,],</span>
    <span class="p">[</span><span class="mf">6.9</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">5.4</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">]</span>
<span class="p">])</span>

<span class="c1"># training=False is needed only if there are layers with different</span>
<span class="c1"># behavior during training versus inference (e.g. Dropout).</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">predict_dataset</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">logits</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
  <span class="n">class_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="n">class_idx</span><span class="p">]</span>
  <span class="n">name</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="n">class_idx</span><span class="p">]</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Example </span><span class="si">{}</span><span class="s2"> prediction: </span><span class="si">{}</span><span class="s2"> (</span><span class="si">{:4.1f}</span><span class="s2">%)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="mi">100</span><span class="o">*</span><span class="n">p</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>