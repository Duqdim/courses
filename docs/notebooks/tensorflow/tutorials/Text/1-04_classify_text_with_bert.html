

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Classify text with BERT &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" />
    <link rel="next" title="Solve GLUE tasks using BERT on TPU" href="1-05_solve_glue_tasks_using_bert_on_tpu.html" />
    <link rel="prev" title="Text classification with an RNN" href="1-03_text_classification_rnn.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/content.html">Sesiones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/course-info.html">Información del curso</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes-neuronales-con-tensorflow/complement.html">Material Complementario</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-texto/index.html">Analítica de Texto</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a> &raquo;</li>
        
          <li><a href="../../../../redes-neuronales-con-tensorflow/content.html">Sesiones</a> &raquo;</li>
        
      <li>Classify text with BERT</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Text/1-04_classify_text_with_bert.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Classify-text-with-BERT">
<h1>Classify text with BERT<a class="headerlink" href="#Classify-text-with-BERT" title="Enlazar permanentemente con este título">¶</a></h1>
<p>This tutorial contains complete code to fine-tune BERT to perform sentiment analysis on a dataset of plain-text IMDB movie reviews. In addition to training a model, you will learn how to preprocess text into an appropriate format.</p>
<p>In this notebook, you will:</p>
<ul class="simple">
<li><p>Load the IMDB dataset</p></li>
<li><p>Load a BERT model from TensorFlow Hub</p></li>
<li><p>Build your own model by combining BERT with a classifier</p></li>
<li><p>Train your own model, fine-tuning BERT as part of that</p></li>
<li><p>Save your model and use it to classify sentences</p></li>
</ul>
<p>If you’re new to working with the IMDB dataset, please see <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/text_classification">Basic text classification</a> for more details.</p>
<div class="section" id="About-BERT">
<h2>About BERT<a class="headerlink" href="#About-BERT" title="Enlazar permanentemente con este título">¶</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT</a> and other Transformer encoder architectures have been wildly successful on a variety of tasks in NLP (natural language processing). They compute vector-space representations of natural language that are suitable for use in deep learning models. The BERT family of models uses the Transformer encoder architecture to process each token of input text in the full context of all tokens before and after, hence the name: Bidirectional Encoder Representations
from Transformers.</p>
<p>BERT models are usually pre-trained on a large corpus of text, then fine-tuned for specific tasks.</p>
</div>
<div class="section" id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># A dependency of the preprocessing for BERT inputs</span>
<span class="o">!</span>pip install -q tensorflow-text
</pre></div>
</div>
</div>
<p>You will use the AdamW optimizer from <a class="reference external" href="https://github.com/tensorflow/models">tensorflow/models</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install -q tf-models-official
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>
<span class="kn">import</span> <span class="nn">tensorflow_text</span> <span class="k">as</span> <span class="nn">text</span>
<span class="kn">from</span> <span class="nn">official.nlp</span> <span class="kn">import</span> <span class="n">optimization</span>  <span class="c1"># to create AdamW optmizer</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s1">&#39;ERROR&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Sentiment-Analysis">
<h2>Sentiment Analysis<a class="headerlink" href="#Sentiment-Analysis" title="Enlazar permanentemente con este título">¶</a></h2>
<p>This notebook trains a sentiment analysis model to classify movie reviews as <em>positive</em> or <em>negative</em>, based on the text of the review.</p>
<p>You’ll use the <a class="reference external" href="https://ai.stanford.edu/~amaas/data/sentiment/">Large Movie Review Dataset</a> that contains the text of 50,000 movie reviews from the <a class="reference external" href="https://www.imdb.com/">Internet Movie Database</a>.</p>
<div class="section" id="Download-the-IMDB-dataset">
<h3>Download the IMDB dataset<a class="headerlink" href="#Download-the-IMDB-dataset" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Let’s download and extract the dataset, then explore the directory structure.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz&#39;</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="s1">&#39;aclImdb_v1.tar.gz&#39;</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span>
                                  <span class="n">untar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
                                  <span class="n">cache_subdir</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">dataset_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="s1">&#39;aclImdb&#39;</span><span class="p">)</span>

<span class="n">train_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>

<span class="c1"># remove unused folders to make it easier to load the data</span>
<span class="n">remove_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span> <span class="s1">&#39;unsup&#39;</span><span class="p">)</span>
<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">remove_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next, you will use the <code class="docutils literal notranslate"><span class="pre">text_dataset_from_directory</span></code> utility to create a labeled <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code>.</p>
<p>The IMDB dataset has already been divided into train and test, but it lacks a validation set. Let’s create a validation set using an 80:20 split of the training data by using the <code class="docutils literal notranslate"><span class="pre">validation_split</span></code> argument below.</p>
<p>Note: When using the <code class="docutils literal notranslate"><span class="pre">validation_split</span></code> and <code class="docutils literal notranslate"><span class="pre">subset</span></code> arguments, make sure to either specify a random seed, or to pass <code class="docutils literal notranslate"><span class="pre">shuffle=False</span></code>, so that the validation and training splits have no overlap.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">raw_train_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text_dataset_from_directory</span><span class="p">(</span>
    <span class="s1">&#39;aclImdb/train&#39;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">subset</span><span class="o">=</span><span class="s1">&#39;training&#39;</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="n">class_names</span> <span class="o">=</span> <span class="n">raw_train_ds</span><span class="o">.</span><span class="n">class_names</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">raw_train_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>

<span class="n">val_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text_dataset_from_directory</span><span class="p">(</span>
    <span class="s1">&#39;aclImdb/train&#39;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">subset</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>

<span class="n">test_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text_dataset_from_directory</span><span class="p">(</span>
    <span class="s1">&#39;aclImdb/test&#39;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s take a look at a few reviews.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">text_batch</span><span class="p">,</span> <span class="n">label_batch</span> <span class="ow">in</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Review: </span><span class="si">{</span><span class="n">text_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">label_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Label : </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Loading-models-from-TensorFlow-Hub">
<h2>Loading models from TensorFlow Hub<a class="headerlink" href="#Loading-models-from-TensorFlow-Hub" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Here you can choose which BERT model you will load from TensorFlow Hub and fine-tune. There are multiple BERT models available.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3">BERT-Base</a>, <a class="reference external" href="https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3">Uncased</a> and <a class="reference external" href="https://tfhub.dev/google/collections/bert/1">seven more models</a> with trained weights released by the original BERT authors.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/bert/1">Small BERTs</a> have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/albert/1">ALBERT</a>: four different sizes of “A Lite BERT” that reduces model size (but not computation time) by sharing parameters between layers.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/experts/bert/1">BERT Experts</a>: eight models that all have the BERT-base architecture but offer a choice between different pre-training domains, to align more closely with the target task.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/electra/1">Electra</a> has the same architecture as BERT (in three different sizes), but gets pre-trained as a discriminator in a set-up that resembles a Generative Adversarial Network (GAN).</p></li>
<li><p>BERT with Talking-Heads Attention and Gated GELU [<a class="reference external" href="https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1">base</a>, <a class="reference external" href="https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_large/1">large</a>] has two improvements to the core of the Transformer architecture.</p></li>
</ul>
<p>The model documentation on TensorFlow Hub has more details and references to the research literature. Follow the links above, or click on the <code class="docutils literal notranslate"><span class="pre">`tfhub.dev</span></code> &lt;<a class="reference external" href="http://tfhub.dev">http://tfhub.dev</a>&gt;`__ URL printed after the next cell execution.</p>
<p>The suggestion is to start with a Small BERT (with fewer parameters) since they are faster to fine-tune. If you like a small model but with higher accuracy, ALBERT might be your next option. If you want even better accuracy, choose one of the classic BERT sizes or their recent refinements like Electra, Talking Heads, or a BERT Expert.</p>
<p>Aside from the models available below, there are <a class="reference external" href="https://tfhub.dev/google/collections/transformer_encoders_text/1">multiple versions</a> of the models that are larger and can yield even better accuracy, but they are too big to be fine-tuned on a single GPU. You will be able to do that on the <a class="reference external" href="https://www.tensorflow.org/tutorials/text/solve_glue_tasks_using_bert_on_tpu">Solve GLUE tasks using BERT on a TPU colab</a>.</p>
<p>You’ll see in the code below that switching the tfhub.dev URL is enough to try any of these models, because all the differences between them are encapsulated in the SavedModels from TF Hub.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#@title Choose a BERT model to fine-tune</span>

<span class="n">bert_model_name</span> <span class="o">=</span> <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-512_A-8&#39;</span>  <span class="c1">#@param [&quot;bert_en_uncased_L-12_H-768_A-12&quot;, &quot;bert_en_cased_L-12_H-768_A-12&quot;, &quot;bert_multi_cased_L-12_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-2_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-2_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-2_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-2_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-4_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-4_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-4_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-4_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-6_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-6_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-6_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-6_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-8_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-8_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-8_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-8_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-10_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-10_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-10_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-10_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-12_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-12_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-12_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-12_H-768_A-12&quot;, &quot;albert_en_base&quot;, &quot;electra_small&quot;, &quot;electra_base&quot;, &quot;experts_pubmed&quot;, &quot;experts_wiki_books&quot;, &quot;talking-heads_base&quot;]</span>

<span class="n">map_name_to_handle</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_multi_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_base/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_small&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/electra_small/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/electra_base/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_pubmed&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/experts/bert/pubmed/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_wiki_books&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/experts/bert/wiki_books/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;talking-heads_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">map_model_to_preprocess</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_multi_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_small&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_pubmed&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_wiki_books&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;talking-heads_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">tfhub_handle_encoder</span> <span class="o">=</span> <span class="n">map_name_to_handle</span><span class="p">[</span><span class="n">bert_model_name</span><span class="p">]</span>
<span class="n">tfhub_handle_preprocess</span> <span class="o">=</span> <span class="n">map_model_to_preprocess</span><span class="p">[</span><span class="n">bert_model_name</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;BERT model selected           : </span><span class="si">{</span><span class="n">tfhub_handle_encoder</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Preprocess model auto-selected: </span><span class="si">{</span><span class="n">tfhub_handle_preprocess</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="The-preprocessing-model">
<h2>The preprocessing model<a class="headerlink" href="#The-preprocessing-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models discussed above, which implements this transformation using TF ops from the TF.text library. It is not necessary to run pure Python code outside your TensorFlow model to preprocess text.</p>
<p>The preprocessing model must be the one referenced by the documentation of the BERT model, which you can read at the URL printed above. For BERT models from the drop-down above, the preprocessing model is selected automatically.</p>
<p>Note: You will load the preprocessing model into a <a class="reference external" href="https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer">hub.KerasLayer</a> to compose your fine-tuned model. This is the preferred API to load a TF2-style SavedModel from TF Hub into a Keras model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bert_preprocess_model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">tfhub_handle_preprocess</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s try the preprocessing model on some text and see the output:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">text_test</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;this is such an amazing movie!&#39;</span><span class="p">]</span>
<span class="n">text_preprocessed</span> <span class="o">=</span> <span class="n">bert_preprocess_model</span><span class="p">(</span><span class="n">text_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Keys       : </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">text_preprocessed</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Shape      : </span><span class="si">{</span><span class="n">text_preprocessed</span><span class="p">[</span><span class="s2">&quot;input_word_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Word Ids   : </span><span class="si">{</span><span class="n">text_preprocessed</span><span class="p">[</span><span class="s2">&quot;input_word_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">12</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Input Mask : </span><span class="si">{</span><span class="n">text_preprocessed</span><span class="p">[</span><span class="s2">&quot;input_mask&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">12</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Type Ids   : </span><span class="si">{</span><span class="n">text_preprocessed</span><span class="p">[</span><span class="s2">&quot;input_type_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">12</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>As you can see, now you have the 3 outputs from the preprocessing that a BERT model would use (<code class="docutils literal notranslate"><span class="pre">input_words_id</span></code>, <code class="docutils literal notranslate"><span class="pre">input_mask</span></code> and <code class="docutils literal notranslate"><span class="pre">input_type_ids</span></code>).</p>
<p>Some other important points: - The input is truncated to 128 tokens. The number of tokens can be customized, and you can see more details on the <a class="reference external" href="https://www.tensorflow.org/tutorials/text/solve_glue_tasks_using_bert_on_tpu">Solve GLUE tasks using BERT on a TPU colab</a>. - The <code class="docutils literal notranslate"><span class="pre">input_type_ids</span></code> only have one value (0) because this is a single sentence input. For a multiple sentence input, it would have one number for each input.</p>
<p>Since this text preprocessor is a TensorFlow model, It can be included in your model directly.</p>
</div>
<div class="section" id="Using-the-BERT-model">
<h2>Using the BERT model<a class="headerlink" href="#Using-the-BERT-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Before putting BERT into your own model, let’s take a look at its outputs. You will load it from TF Hub and see the returned values.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bert_model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">tfhub_handle_encoder</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bert_results</span> <span class="o">=</span> <span class="n">bert_model</span><span class="p">(</span><span class="n">text_preprocessed</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loaded BERT: </span><span class="si">{</span><span class="n">tfhub_handle_encoder</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Pooled Outputs Shape:</span><span class="si">{</span><span class="n">bert_results</span><span class="p">[</span><span class="s2">&quot;pooled_output&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Pooled Outputs Values:</span><span class="si">{</span><span class="n">bert_results</span><span class="p">[</span><span class="s2">&quot;pooled_output&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">12</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Sequence Outputs Shape:</span><span class="si">{</span><span class="n">bert_results</span><span class="p">[</span><span class="s2">&quot;sequence_output&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Sequence Outputs Values:</span><span class="si">{</span><span class="n">bert_results</span><span class="p">[</span><span class="s2">&quot;sequence_output&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">12</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The BERT models return a map with 3 important keys: <code class="docutils literal notranslate"><span class="pre">pooled_output</span></code>, <code class="docutils literal notranslate"><span class="pre">sequence_output</span></code>, <code class="docutils literal notranslate"><span class="pre">encoder_outputs</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pooled_output</span></code> to represent each input sequence as a whole. The shape is <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">H]</span></code>. You can think of this as an embedding for the entire movie review.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sequence_output</span></code> represents each input token in the context. The shape is <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">seq_length,</span> <span class="pre">H]</span></code>. You can think of this as a contextual embedding for every token in the movie review.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">encoder_outputs</span></code> are the intermediate activations of the <code class="docutils literal notranslate"><span class="pre">L</span></code> Transformer blocks. <code class="docutils literal notranslate"><span class="pre">outputs[&quot;encoder_outputs&quot;][i]</span></code> is a Tensor of shape <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">seq_length,</span> <span class="pre">1024]</span></code> with the outputs of the i-th Transformer block, for <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">i</span> <span class="pre">&lt;</span> <span class="pre">L</span></code>. The last value of the list is equal to <code class="docutils literal notranslate"><span class="pre">sequence_output</span></code>.</p></li>
</ul>
<p>For the fine-tuning you are going to use the <code class="docutils literal notranslate"><span class="pre">pooled_output</span></code> array.</p>
</div>
<div class="section" id="Define-your-model">
<h2>Define your model<a class="headerlink" href="#Define-your-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You will create a very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer.</p>
<p>Note: for more information about the base model’s input and output you can use just follow the model’s url for documentation. Here specifically you don’t need to worry about it because the preprocessing model will take care of that for you.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">build_classifier_model</span><span class="p">():</span>
  <span class="n">text_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">)</span>
  <span class="n">preprocessing_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">tfhub_handle_preprocess</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;preprocessing&#39;</span><span class="p">)</span>
  <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">preprocessing_layer</span><span class="p">(</span><span class="n">text_input</span><span class="p">)</span>
  <span class="n">encoder</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">tfhub_handle_encoder</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;BERT_encoder&#39;</span><span class="p">)</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;pooled_output&#39;</span><span class="p">]</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">net</span><span class="p">)</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;classifier&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">text_input</span><span class="p">,</span> <span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s check that the model runs with the output of the preprocessing model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">classifier_model</span> <span class="o">=</span> <span class="n">build_classifier_model</span><span class="p">()</span>
<span class="n">bert_raw_result</span> <span class="o">=</span> <span class="n">classifier_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">text_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">bert_raw_result</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>The output is meaningless, of course, because the model has not been trained yet.</p>
<p>Let’s take a look at the model’s structure.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">classifier_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Model-training">
<h2>Model training<a class="headerlink" href="#Model-training" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier.</p>
<div class="section" id="Loss-function">
<h3>Loss function<a class="headerlink" href="#Loss-function" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Since this is a binary classification problem and the model outputs a probability (a single-unit layer), you’ll use <code class="docutils literal notranslate"><span class="pre">losses.BinaryCrossentropy</span></code> loss function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Optimizer">
<h3>Optimizer<a class="headerlink" href="#Optimizer" title="Enlazar permanentemente con este título">¶</a></h3>
<p>For fine-tuning, let’s use the same optimizer that BERT was originally trained with: the “Adaptive Moments” (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as <a class="reference external" href="https://arxiv.org/abs/1711.05101">AdamW</a>.</p>
<p>For the learning rate (<code class="docutils literal notranslate"><span class="pre">init_lr</span></code>), we use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (<code class="docutils literal notranslate"><span class="pre">num_warmup_steps</span></code>). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">cardinality</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">num_train_steps</span> <span class="o">=</span> <span class="n">steps_per_epoch</span> <span class="o">*</span> <span class="n">epochs</span>
<span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">num_train_steps</span><span class="p">)</span>

<span class="n">init_lr</span> <span class="o">=</span> <span class="mf">3e-5</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimization</span><span class="o">.</span><span class="n">create_optimizer</span><span class="p">(</span><span class="n">init_lr</span><span class="o">=</span><span class="n">init_lr</span><span class="p">,</span>
                                          <span class="n">num_train_steps</span><span class="o">=</span><span class="n">num_train_steps</span><span class="p">,</span>
                                          <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">num_warmup_steps</span><span class="p">,</span>
                                          <span class="n">optimizer_type</span><span class="o">=</span><span class="s1">&#39;adamw&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Loading-the-BERT-model-and-training">
<h3>Loading the BERT model and training<a class="headerlink" href="#Loading-the-BERT-model-and-training" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Using the <code class="docutils literal notranslate"><span class="pre">classifier_model</span></code> you created earlier, you can compile the model with the loss, metric and optimizer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">classifier_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                         <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                         <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note: training time will vary depending on the complexity of the BERT model you have selected.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training model with </span><span class="si">{</span><span class="n">tfhub_handle_encoder</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">classifier_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_ds</span><span class="p">,</span>
                               <span class="n">validation_data</span><span class="o">=</span><span class="n">val_ds</span><span class="p">,</span>
                               <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Evaluate-the-model">
<h3>Evaluate the model<a class="headerlink" href="#Evaluate-the-model" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Let’s see how the model performs. Two values will be returned. Loss (a number which represents the error, lower values are better), and accuracy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">classifier_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Plot-the-accuracy-and-loss-over-time">
<h3>Plot the accuracy and loss over time<a class="headerlink" href="#Plot-the-accuracy-and-loss-over-time" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Based on the <code class="docutils literal notranslate"><span class="pre">History</span></code> object returned by <code class="docutils literal notranslate"><span class="pre">model.fit()</span></code>. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">history_dict</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span>
<span class="nb">print</span><span class="p">(</span><span class="n">history_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># &quot;bo&quot; is for &quot;blue dot&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="c1"># b is for &quot;solid blue line&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="c1"># plt.xlabel(&#39;Epochs&#39;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>In this plot, the red lines represents the training loss and accuracy, and the blue lines are the validation loss and accuracy.</p>
</div>
</div>
<div class="section" id="Export-for-inference">
<h2>Export for inference<a class="headerlink" href="#Export-for-inference" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Now you just save your fine-tuned model for later use.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">dataset_name</span> <span class="o">=</span> <span class="s1">&#39;imdb&#39;</span>
<span class="n">saved_model_path</span> <span class="o">=</span> <span class="s1">&#39;./</span><span class="si">{}</span><span class="s1">_bert&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dataset_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">))</span>

<span class="n">classifier_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">saved_model_path</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s reload the model so you can try it side by side with the model that is still in memory.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">reloaded_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">saved_model_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here you can test your model on any sentence you want, just add to the examples variable below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">print_my_examples</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
  <span class="n">result_for_printing</span> <span class="o">=</span> \
    <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;input: </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s1">&lt;30</span><span class="si">}</span><span class="s1"> : score: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span>
                         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>
  <span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">result_for_printing</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>


<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;this is such an amazing movie!&#39;</span><span class="p">,</span>  <span class="c1"># this is the same sentence tried earlier</span>
    <span class="s1">&#39;The movie was great!&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The movie was meh.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The movie was okish.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The movie was terrible...&#39;</span>
<span class="p">]</span>

<span class="n">reloaded_results</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">reloaded_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">examples</span><span class="p">)))</span>
<span class="n">original_results</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">classifier_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">examples</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Results from the saved model:&#39;</span><span class="p">)</span>
<span class="n">print_my_examples</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">reloaded_results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Results from the model in memory:&#39;</span><span class="p">)</span>
<span class="n">print_my_examples</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">original_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If you want to use your model on <a class="reference external" href="https://www.tensorflow.org/tfx/guide/serving">TF Serving</a>, remember that it will call your SavedModel through one of its named signatures. In Python, you can test them as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">serving_results</span> <span class="o">=</span> <span class="n">reloaded_model</span> \
            <span class="o">.</span><span class="n">signatures</span><span class="p">[</span><span class="s1">&#39;serving_default&#39;</span><span class="p">](</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">examples</span><span class="p">))</span>

<span class="n">serving_results</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">serving_results</span><span class="p">[</span><span class="s1">&#39;classifier&#39;</span><span class="p">])</span>

<span class="n">print_my_examples</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">serving_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Next-steps">
<h2>Next steps<a class="headerlink" href="#Next-steps" title="Enlazar permanentemente con este título">¶</a></h2>
<p>As a next step, you can try <a class="reference external" href="https://www.tensorflow.org/tutorials/text/solve_glue_tasks_using_bert_on_tpu">Solve GLUE tasks using BERT on a TPU tutorial</a> which runs on a TPU and shows you how to work with multiple inputs.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>