

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Solve GLUE tasks using BERT on TPU &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
        <script src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "math|output_area"}}</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Solve GLUE tasks using BERT on TPU</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Text/1-05_solve_glue_tasks_using_bert_on_tpu.ipynb.txt" rel="nofollow"> Ver código fuente de la página</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Solve-GLUE-tasks-using-BERT-on-TPU">
<h1>Solve GLUE tasks using BERT on TPU<a class="headerlink" href="#Solve-GLUE-tasks-using-BERT-on-TPU" title="Enlazar permanentemente con este título">¶</a></h1>
<p>BERT can be used to solve many problems in natural language processing. You will learn how to fine-tune BERT for many tasks from the <a class="reference external" href="https://gluebenchmark.com/">GLUE benchmark</a>:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://nyu-mll.github.io/CoLA/">CoLA</a> (Corpus of Linguistic Acceptability): Is the sentence grammatically correct?</p></li>
<li><p><a class="reference external" href="https://nlp.stanford.edu/sentiment/index.html">SST-2</a> (Stanford Sentiment Treebank): The task is to predict the sentiment of a given sentence.</p></li>
<li><p><a class="reference external" href="https://www.microsoft.com/en-us/download/details.aspx?id=52398">MRPC</a> (Microsoft Research Paraphrase Corpus): Determine whether a pair of sentences are semantically equivalent.</p></li>
<li><p><a class="reference external" href="https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs">QQP</a> (Quora Question Pairs2): Determine whether a pair of questions are semantically equivalent.</p></li>
<li><p><a class="reference external" href="http://www.nyu.edu/projects/bowman/multinli/">MNLI</a> (Multi-Genre Natural Language Inference): Given a premise sentence and a hypothesis sentence, the task is to predict whether the premise entails the hypothesis (entailment), contradicts the hypothesis (contradiction), or neither (neutral).</p></li>
<li><p><a class="reference external" href="https://rajpurkar.github.io/SQuAD-explorer/">QNLI</a>(Question-answering Natural Language Inference): The task is to determine whether the context sentence contains the answer to the question.</p></li>
<li><p><a class="reference external" href="https://aclweb.org/aclwiki/Recognizing_Textual_Entailment">RTE</a>(Recognizing Textual Entailment): Determine if a sentence entails a given hypothesis or not.</p></li>
<li><p><a class="reference external" href="https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html">WNLI</a>(Winograd Natural Language Inference): The task is to predict if the sentence with the pronoun substituted is entailed by the original sentence.</p></li>
</ol>
<p>This tutorial contains complete end-to-end code to train these models on a TPU. You can also run this notebook on a GPU, by changing one line (described below).</p>
<p>In this notebook, you will:</p>
<ul class="simple">
<li><p>Load a BERT model from TensorFlow Hub</p></li>
<li><p>Choose one of GLUE tasks and download the dataset</p></li>
<li><p>Preprocess the text</p></li>
<li><p>Fine-tune BERT (examples are given for single-sentence and multi-sentence datasets)</p></li>
<li><p>Save the trained model and use it</p></li>
</ul>
<p>Key point: The model you develop will be end-to-end. The preprocessing logic will be included in the model itself, making it capable of accepting raw strings as input.</p>
<p>Note: This notebook should be run using a TPU. In Colab, choose <strong>Runtime -&gt; Change runtime type</strong> and verify that a <strong>TPU</strong> is selected.</p>
<div class="section" id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You will use a separate model to preprocess text before using it to fine-tune BERT. This model depends on <a class="reference external" href="https://github.com/tensorflow/text">tensorflow/text</a>, which you will install below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install -q -U tensorflow-text
</pre></div>
</div>
</div>
<p>You will use the AdamW optimizer from <a class="reference external" href="https://github.com/tensorflow/models">tensorflow/models</a> to fine-tune BERT, which you will install as well.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install -q -U tf-models-official
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install -U tfds-nightly
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="kn">import</span> <span class="nn">tensorflow_text</span> <span class="k">as</span> <span class="nn">text</span>  <span class="c1"># A dependency of the preprocessing model</span>
<span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>
<span class="kn">from</span> <span class="nn">official.nlp</span> <span class="kn">import</span> <span class="n">optimization</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s1">&#39;ERROR&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next, configure TFHub to read checkpoints directly from TFHub’s Cloud Storage buckets. This is only recommended when running TFHub models on TPU.</p>
<p>Without this setting TFHub would download the compressed file and extract the checkpoint locally. Attempting to load from these local files will fail with the following error:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>InvalidArgumentError: Unimplemented: File system scheme &#39;[local]&#39; not implemented
</pre></div>
</div>
<p>This is because the <a class="reference external" href="https://cloud.google.com/tpu/docs/troubleshooting#cannot_use_local_filesystem">TPU can only read directly from Cloud Storage buckets</a>.</p>
<p>Note: This setting is automatic in Colab.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TFHUB_MODEL_LOAD_FORMAT&quot;</span><span class="p">]</span><span class="o">=</span><span class="s2">&quot;UNCOMPRESSED&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="Connect-to-the-TPU-worker">
<h3>Connect to the TPU worker<a class="headerlink" href="#Connect-to-the-TPU-worker" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The following code connects to the TPU worker and changes TensorFlow’s default device to the CPU device on the TPU worker. It also defines a TPU distribution strategy that you will use to distribute model training onto the 8 separate TPU cores available on this one TPU worker. See TensorFlow’s <a class="reference external" href="https://www.tensorflow.org/guide/tpu">TPU guide</a> for more information.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;COLAB_TPU_ADDR&#39;</span><span class="p">]:</span>
  <span class="n">cluster_resolver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">TPUClusterResolver</span><span class="p">(</span><span class="n">tpu</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental_connect_to_cluster</span><span class="p">(</span><span class="n">cluster_resolver</span><span class="p">)</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">tpu</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">initialize_tpu_system</span><span class="p">(</span><span class="n">cluster_resolver</span><span class="p">)</span>
  <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">(</span><span class="n">cluster_resolver</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using TPU&#39;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_gpu_available</span><span class="p">():</span>
  <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using GPU&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Running on CPU is not recommended.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Loading-models-from-TensorFlow-Hub">
<h2>Loading models from TensorFlow Hub<a class="headerlink" href="#Loading-models-from-TensorFlow-Hub" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Here you can choose which BERT model you will load from TensorFlow Hub and fine-tune. There are multiple BERT models available to choose from.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3">BERT-Base</a>, <a class="reference external" href="https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3">Uncased</a> and <a class="reference external" href="https://tfhub.dev/google/collections/bert/1">seven more models</a> with trained weights released by the original BERT authors.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/bert/1">Small BERTs</a> have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/albert/1">ALBERT</a>: four different sizes of «A Lite BERT» that reduces model size (but not computation time) by sharing parameters between layers.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/experts/bert/1">BERT Experts</a>: eight models that all have the BERT-base architecture but offer a choice between different pre-training domains, to align more closely with the target task.</p></li>
<li><p><a class="reference external" href="https://tfhub.dev/google/collections/electra/1">Electra</a> has the same architecture as BERT (in three different sizes), but gets pre-trained as a discriminator in a set-up that resembles a Generative Adversarial Network (GAN).</p></li>
<li><p>BERT with Talking-Heads Attention and Gated GELU [<a class="reference external" href="https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1">base</a>, <a class="reference external" href="https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_large/1">large</a>] has two improvements to the core of the Transformer architecture.</p></li>
</ul>
<p>See the model documentation linked above for more details.</p>
<p>In this tutorial, you will start with BERT-base. You can use larger and more recent models for higher accuracy, or smaller models for faster training times. To change the model, you only need to switch a single line of code (shown below). All the differences are encapsulated in the SavedModel you will download from TensorFlow Hub.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#@title Choose a BERT model to fine-tune</span>

<span class="n">bert_model_name</span> <span class="o">=</span> <span class="s1">&#39;bert_en_uncased_L-12_H-768_A-12&#39;</span>  <span class="c1">#@param [&quot;bert_en_uncased_L-12_H-768_A-12&quot;, &quot;bert_en_uncased_L-24_H-1024_A-16&quot;, &quot;bert_en_wwm_uncased_L-24_H-1024_A-16&quot;, &quot;bert_en_cased_L-12_H-768_A-12&quot;, &quot;bert_en_cased_L-24_H-1024_A-16&quot;, &quot;bert_en_wwm_cased_L-24_H-1024_A-16&quot;, &quot;bert_multi_cased_L-12_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-2_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-2_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-2_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-2_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-4_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-4_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-4_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-4_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-6_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-6_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-6_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-6_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-8_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-8_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-8_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-8_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-10_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-10_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-10_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-10_H-768_A-12&quot;, &quot;small_bert/bert_en_uncased_L-12_H-128_A-2&quot;, &quot;small_bert/bert_en_uncased_L-12_H-256_A-4&quot;, &quot;small_bert/bert_en_uncased_L-12_H-512_A-8&quot;, &quot;small_bert/bert_en_uncased_L-12_H-768_A-12&quot;, &quot;albert_en_base&quot;, &quot;albert_en_large&quot;, &quot;albert_en_xlarge&quot;, &quot;albert_en_xxlarge&quot;, &quot;electra_small&quot;, &quot;electra_base&quot;, &quot;experts_pubmed&quot;, &quot;experts_wiki_books&quot;, &quot;talking-heads_base&quot;, &quot;talking-heads_large&quot;]</span>

<span class="n">map_name_to_handle</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_uncased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_wwm_uncased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_wwm_uncased_L-24_H-1024_A-16/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_cased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_cased_L-24_H-1024_A-16/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_wwm_cased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_wwm_cased_L-24_H-1024_A-16/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_multi_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_base/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_large&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_large/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_xlarge&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_xlarge/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_xxlarge&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_xxlarge/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_small&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/electra_small/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/electra_base/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_pubmed&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/experts/bert/pubmed/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_wiki_books&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/google/experts/bert/wiki_books/2&#39;</span><span class="p">,</span>
    <span class="s1">&#39;talking-heads_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;talking-heads_large&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_large/1&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">map_model_to_preprocess</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;bert_en_uncased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_wwm_cased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_cased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_en_wwm_uncased_L-24_H-1024_A-16&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-2_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-4_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-6_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-8_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-10_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-128_A-2&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-256_A-4&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-512_A-8&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;small_bert/bert_en_uncased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert_multi_cased_L-12_H-768_A-12&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_large&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_xlarge&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;albert_en_xxlarge&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/albert_en_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_small&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;electra_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_pubmed&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;experts_wiki_books&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;talking-heads_base&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
    <span class="s1">&#39;talking-heads_large&#39;</span><span class="p">:</span>
        <span class="s1">&#39;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&#39;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">tfhub_handle_encoder</span> <span class="o">=</span> <span class="n">map_name_to_handle</span><span class="p">[</span><span class="n">bert_model_name</span><span class="p">]</span>
<span class="n">tfhub_handle_preprocess</span> <span class="o">=</span> <span class="n">map_model_to_preprocess</span><span class="p">[</span><span class="n">bert_model_name</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BERT model selected           :&#39;</span><span class="p">,</span> <span class="n">tfhub_handle_encoder</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Preprocessing model auto-selected:&#39;</span><span class="p">,</span> <span class="n">tfhub_handle_preprocess</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Preprocess-the-text">
<h2>Preprocess the text<a class="headerlink" href="#Preprocess-the-text" title="Enlazar permanentemente con este título">¶</a></h2>
<p>On the <a class="reference external" href="https://www.tensorflow.org/tutorials/text/classify_text_with_bert">Classify text with BERT colab</a> the preprocessing model is used directly embedded with the BERT encoder.</p>
<p>This tutorial demonstrates how to do preprocessing as part of your input pipeline for training, using Dataset.map, and then merge it into the model that gets exported for inference. That way, both training and inference can work from raw text inputs, although the TPU itself requires numeric inputs.</p>
<p>TPU requirements aside, it can help performance have preprocessing done asynchronously in an input pipeline (you can learn more in the <a class="reference external" href="https://www.tensorflow.org/guide/data_performance">tf.data performance guide</a>).</p>
<p>This tutorial also demonstrates how to build multi-input models, and how to adjust the sequence length of the inputs to BERT.</p>
<p>Let’s demonstrate the preprocessing model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">bert_preprocess</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">tfhub_handle_preprocess</span><span class="p">)</span>
<span class="n">tok</span> <span class="o">=</span> <span class="n">bert_preprocess</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="s1">&#39;Hello TensorFlow!&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Each preprocessing model also provides a method, <code class="docutils literal notranslate"><span class="pre">.bert_pack_inputs(tensors,</span> <span class="pre">seq_length)</span></code>, which takes a list of tokens (like <code class="docutils literal notranslate"><span class="pre">tok</span></code> above) and a sequence length argument. This packs the inputs to create a dictionary of tensors in the format expected by the BERT model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">text_preprocessed</span> <span class="o">=</span> <span class="n">bert_preprocess</span><span class="o">.</span><span class="n">bert_pack_inputs</span><span class="p">([</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape Word Ids : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_word_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Word Ids       : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_word_ids&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">16</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape Mask     : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input Mask     : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_mask&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">16</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape Type Ids : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_type_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Type Ids       : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_type_ids&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">16</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>Here are some details to pay attention to: - <code class="docutils literal notranslate"><span class="pre">input_mask</span></code> The mask allows the model to cleanly differentiate between the content and the padding. The mask has the same shape as the <code class="docutils literal notranslate"><span class="pre">input_word_ids</span></code>, and contains a 1 anywhere the <code class="docutils literal notranslate"><span class="pre">input_word_ids</span></code> is not padding. - <code class="docutils literal notranslate"><span class="pre">input_type_ids</span></code> has the same shape as <code class="docutils literal notranslate"><span class="pre">input_mask</span></code>, but inside the non-padded region, contains a 0 or a 1 indicating which sentence the token is a part of.</p>
<p>Next, you will create a preprocessing model that encapsulates all this logic. Your model will take strings as input, and return appropriately formatted objects which can be passed to BERT.</p>
<p>Each BERT model has a specific preprocessing model, make sure to use the proper one described on the BERT’s model documentation.</p>
<p>Note: BERT adds a «position embedding» to the token embedding of each input, and these come from a fixed-size lookup table. That imposes a max seq length of 512 (which is also a practical limit, due to the quadratic growth of attention computation). For this Colab 128 is good enough.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">make_bert_preprocess_model</span><span class="p">(</span><span class="n">sentence_features</span><span class="p">,</span> <span class="n">seq_length</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns Model mapping string features to BERT inputs.</span>

<span class="sd">  Args:</span>
<span class="sd">    sentence_features: a list with the names of string-valued features.</span>
<span class="sd">    seq_length: an integer that defines the sequence length of BERT inputs.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A Keras Model that can be called on a list or dict of string Tensors</span>
<span class="sd">    (with the order or names, resp., given by sentence_features) and</span>
<span class="sd">    returns a dict of tensors for input to BERT.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">input_segments</span> <span class="o">=</span> <span class="p">[</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">ft</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">ft</span> <span class="ow">in</span> <span class="n">sentence_features</span><span class="p">]</span>

  <span class="c1"># Tokenize the text to word pieces.</span>
  <span class="n">bert_preprocess</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">tfhub_handle_preprocess</span><span class="p">)</span>
  <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">bert_preprocess</span><span class="o">.</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;tokenizer&#39;</span><span class="p">)</span>
  <span class="n">segments</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">input_segments</span><span class="p">]</span>

  <span class="c1"># Optional: Trim segments in a smart way to fit seq_length.</span>
  <span class="c1"># Simple cases (like this example) can skip this step and let</span>
  <span class="c1"># the next step apply a default truncation to approximately equal lengths.</span>
  <span class="n">truncated_segments</span> <span class="o">=</span> <span class="n">segments</span>

  <span class="c1"># Pack inputs. The details (start/end token ids, dict of output tensors)</span>
  <span class="c1"># are model-dependent, so this gets loaded from the SavedModel.</span>
  <span class="n">packer</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">bert_preprocess</span><span class="o">.</span><span class="n">bert_pack_inputs</span><span class="p">,</span>
                          <span class="n">arguments</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">seq_length</span><span class="o">=</span><span class="n">seq_length</span><span class="p">),</span>
                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;packer&#39;</span><span class="p">)</span>
  <span class="n">model_inputs</span> <span class="o">=</span> <span class="n">packer</span><span class="p">(</span><span class="n">truncated_segments</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">input_segments</span><span class="p">,</span> <span class="n">model_inputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s demonstrate the preprocessing model. You will create a test with two sentences input (input1 and input2). The output is what a BERT model would expect as input: <code class="docutils literal notranslate"><span class="pre">input_word_ids</span></code>, <code class="docutils literal notranslate"><span class="pre">input_masks</span></code> and <code class="docutils literal notranslate"><span class="pre">input_type_ids</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_preprocess_model</span> <span class="o">=</span> <span class="n">make_bert_preprocess_model</span><span class="p">([</span><span class="s1">&#39;my_input1&#39;</span><span class="p">,</span> <span class="s1">&#39;my_input2&#39;</span><span class="p">])</span>
<span class="n">test_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;some random test sentence&#39;</span><span class="p">]),</span>
             <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;another sentence&#39;</span><span class="p">])]</span>
<span class="n">text_preprocessed</span> <span class="o">=</span> <span class="n">test_preprocess_model</span><span class="p">(</span><span class="n">test_text</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Keys           : &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">text_preprocessed</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape Word Ids : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_word_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Word Ids       : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_word_ids&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">16</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape Mask     : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input Mask     : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_mask&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">16</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape Type Ids : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_type_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Type Ids       : &#39;</span><span class="p">,</span> <span class="n">text_preprocessed</span><span class="p">[</span><span class="s1">&#39;input_type_ids&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">16</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>Let’s take a look at the model’s structure, paying attention to the two inputs you just defined.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">test_preprocess_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>To apply the preprocessing in all the inputs from the dataset, you will use the <code class="docutils literal notranslate"><span class="pre">map</span></code> function from the dataset. The result is then cached for <a class="reference external" href="https://www.tensorflow.org/guide/data_performance#top_of_page">performance</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span>


<span class="k">def</span> <span class="nf">load_dataset_from_tfds</span><span class="p">(</span><span class="n">in_memory_ds</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                           <span class="n">bert_preprocess_model</span><span class="p">):</span>
  <span class="n">is_training</span> <span class="o">=</span> <span class="n">split</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">in_memory_ds</span><span class="p">[</span><span class="n">split</span><span class="p">])</span>
  <span class="n">num_examples</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">splits</span><span class="p">[</span><span class="n">split</span><span class="p">]</span><span class="o">.</span><span class="n">num_examples</span>

  <span class="k">if</span> <span class="n">is_training</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">num_examples</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">ex</span><span class="p">:</span> <span class="p">(</span><span class="n">bert_preprocess_model</span><span class="p">(</span><span class="n">ex</span><span class="p">),</span> <span class="n">ex</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]))</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">num_examples</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Define-your-model">
<h2>Define your model<a class="headerlink" href="#Define-your-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You are now ready to define your model for sentence or sentence pair classification by feeding the preprocessed inputs through the BERT encoder and putting a linear classifier on top (or other arrangement of layers as you prefer), and using dropout for regularization.</p>
<p>Note: Here the model will be defined using the <a class="reference external" href="https://www.tensorflow.org/guide/keras/functional">Keras functional API</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">build_classifier_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
      <span class="n">input_word_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
      <span class="n">input_mask</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
      <span class="n">input_type_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
  <span class="p">)</span>

  <span class="n">encoder</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">tfhub_handle_encoder</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;encoder&#39;</span><span class="p">)</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="s1">&#39;pooled_output&#39;</span><span class="p">]</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">net</span><span class="p">)</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;classifier&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;prediction&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s try running the model on some preprocessed inputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_classifier_model</span> <span class="o">=</span> <span class="n">build_classifier_model</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">bert_raw_result</span> <span class="o">=</span> <span class="n">test_classifier_model</span><span class="p">(</span><span class="n">text_preprocessed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">bert_raw_result</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Let’s take a look at the model’s structure. You can see the three BERT expected inputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">test_classifier_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Choose-a-task-from-GLUE">
<h2>Choose a task from GLUE<a class="headerlink" href="#Choose-a-task-from-GLUE" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You are going to use a TensorFlow DataSet from the <a class="reference external" href="https://www.tensorflow.org/datasets/catalog/glue">GLUE</a> benchmark suite.</p>
<p>Colab lets you download these small datasets to the local filesystem, and the code below reads them entirely into memory, because the separate TPU worker host cannot access the local filesystem of the colab runtime.</p>
<p>For bigger datasets, you’ll need to create your own <a class="reference external" href="https://cloud.google.com/storage">Google Cloud Storage</a> bucket and have the TPU worker read the data from there. You can learn more in the <a class="reference external" href="https://www.tensorflow.org/guide/tpu#input_datasets">TPU guide</a>.</p>
<p>It’s recommended to start with the CoLa dataset (for single sentence) or MRPC (for multi sentence) since these are small and don’t take long to fine tune.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tfds_name</span> <span class="o">=</span> <span class="s1">&#39;glue/cola&#39;</span>  <span class="c1">#@param [&#39;glue/cola&#39;, &#39;glue/sst2&#39;, &#39;glue/mrpc&#39;, &#39;glue/qqp&#39;, &#39;glue/mnli&#39;, &#39;glue/qnli&#39;, &#39;glue/rte&#39;, &#39;glue/wnli&#39;]</span>

<span class="n">tfds_info</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">builder</span><span class="p">(</span><span class="n">tfds_name</span><span class="p">)</span><span class="o">.</span><span class="n">info</span>

<span class="n">sentence_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tfds_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">sentence_features</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;idx&#39;</span><span class="p">)</span>
<span class="n">sentence_features</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>

<span class="n">available_splits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tfds_info</span><span class="o">.</span><span class="n">splits</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">train_split</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span>
<span class="n">validation_split</span> <span class="o">=</span> <span class="s1">&#39;validation&#39;</span>
<span class="n">test_split</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span>
<span class="k">if</span> <span class="n">tfds_name</span> <span class="o">==</span> <span class="s1">&#39;glue/mnli&#39;</span><span class="p">:</span>
  <span class="n">validation_split</span> <span class="o">=</span> <span class="s1">&#39;validation_matched&#39;</span>
  <span class="n">test_split</span> <span class="o">=</span> <span class="s1">&#39;test_matched&#39;</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="n">tfds_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">num_classes</span>
<span class="n">num_examples</span> <span class="o">=</span> <span class="n">tfds_info</span><span class="o">.</span><span class="n">splits</span><span class="o">.</span><span class="n">total_num_examples</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using </span><span class="si">{</span><span class="n">tfds_name</span><span class="si">}</span><span class="s1"> from TFDS&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;This dataset has </span><span class="si">{</span><span class="n">num_examples</span><span class="si">}</span><span class="s1"> examples&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Number of classes: </span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Features </span><span class="si">{</span><span class="n">sentence_features</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Splits </span><span class="si">{</span><span class="n">available_splits</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/job:localhost&#39;</span><span class="p">):</span>
  <span class="c1"># batch_size=-1 is a way to load the dataset into memory</span>
  <span class="n">in_memory_ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">tfds_name</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle_files</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># The code below is just to show some samples from the selected dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Here are some sample rows from </span><span class="si">{</span><span class="n">tfds_name</span><span class="si">}</span><span class="s1"> dataset&#39;</span><span class="p">)</span>
<span class="n">sample_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">in_memory_ds</span><span class="p">[</span><span class="n">train_split</span><span class="p">])</span>

<span class="n">labels_names</span> <span class="o">=</span> <span class="n">tfds_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">sample_i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">sample_row</span> <span class="ow">in</span> <span class="n">sample_dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
  <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample_row</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">sentence_features</span><span class="p">]</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;sample row </span><span class="si">{</span><span class="n">sample_i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
  <span class="n">sample_label</span> <span class="o">=</span> <span class="n">sample_row</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;label: </span><span class="si">{</span><span class="n">sample_label</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">labels_names</span><span class="p">[</span><span class="n">sample_label</span><span class="p">]</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>
  <span class="n">sample_i</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<p>The dataset also determines the problem type (classification or regression) and the appropriate loss function for training.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">get_configuration</span><span class="p">(</span><span class="n">glue_task</span><span class="p">):</span>

  <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">glue_task</span> <span class="o">==</span> <span class="s1">&#39;glue/cola&#39;</span><span class="p">:</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">MatthewsCorrelationCoefficient</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
        <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Train-your-model">
<h2>Train your model<a class="headerlink" href="#Train-your-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Finally, you can train the model end-to-end on the dataset you chose.</p>
<div class="section" id="Distribution">
<h3>Distribution<a class="headerlink" href="#Distribution" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Recall the set-up code at the top, which has connected the colab runtime to a TPU worker with multiple TPU devices. To distribute training onto them, you will create and compile your main Keras model within the scope of the TPU distribution strategy. (For details, see <a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/keras">Distributed training with Keras</a>.)</p>
<p>Preprocessing, on the other hand, runs on the CPU of the worker host, not the TPUs, so the Keras model for preprocessing as well as the training and validation datasets mapped with it are built outside the distribution strategy scope. The call to <code class="docutils literal notranslate"><span class="pre">Model.fit()</span></code> will take care of distributing the passed-in dataset to the model replicas.</p>
<p>Note: The single TPU worker host already has the resource objects (think: a lookup table) needed for tokenization. Scaling up to multiple workers requires use of <code class="docutils literal notranslate"><span class="pre">Strategy.experimental_distribute_datasets_from_function</span></code> with a function that loads the preprocessing model separately onto each worker.</p>
</div>
<div class="section" id="Optimizer">
<h3>Optimizer<a class="headerlink" href="#Optimizer" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Fine-tuning follows the optimizer set-up from BERT pre-training (as in <a class="reference external" href="https://www.tensorflow.org/tutorials/text/classify_text_with_bert">Classify text with BERT</a>): It uses the AdamW optimizer with a linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (<code class="docutils literal notranslate"><span class="pre">num_warmup_steps</span></code>). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">init_lr</span> <span class="o">=</span> <span class="mf">2e-5</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fine tuning </span><span class="si">{</span><span class="n">tfhub_handle_encoder</span><span class="si">}</span><span class="s1"> model&#39;</span><span class="p">)</span>
<span class="n">bert_preprocess_model</span> <span class="o">=</span> <span class="n">make_bert_preprocess_model</span><span class="p">(</span><span class="n">sentence_features</span><span class="p">)</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>

  <span class="c1"># metric have to be created inside the strategy scope</span>
  <span class="n">metrics</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">get_configuration</span><span class="p">(</span><span class="n">tfds_name</span><span class="p">)</span>

  <span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_data_size</span> <span class="o">=</span> <span class="n">load_dataset_from_tfds</span><span class="p">(</span>
      <span class="n">in_memory_ds</span><span class="p">,</span> <span class="n">tfds_info</span><span class="p">,</span> <span class="n">train_split</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">bert_preprocess_model</span><span class="p">)</span>
  <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">train_data_size</span> <span class="o">//</span> <span class="n">batch_size</span>
  <span class="n">num_train_steps</span> <span class="o">=</span> <span class="n">steps_per_epoch</span> <span class="o">*</span> <span class="n">epochs</span>
  <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="n">num_train_steps</span> <span class="o">//</span> <span class="mi">10</span>

  <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">validation_data_size</span> <span class="o">=</span> <span class="n">load_dataset_from_tfds</span><span class="p">(</span>
      <span class="n">in_memory_ds</span><span class="p">,</span> <span class="n">tfds_info</span><span class="p">,</span> <span class="n">validation_split</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
      <span class="n">bert_preprocess_model</span><span class="p">)</span>
  <span class="n">validation_steps</span> <span class="o">=</span> <span class="n">validation_data_size</span> <span class="o">//</span> <span class="n">batch_size</span>

  <span class="n">classifier_model</span> <span class="o">=</span> <span class="n">build_classifier_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimization</span><span class="o">.</span><span class="n">create_optimizer</span><span class="p">(</span>
      <span class="n">init_lr</span><span class="o">=</span><span class="n">init_lr</span><span class="p">,</span>
      <span class="n">num_train_steps</span><span class="o">=</span><span class="n">num_train_steps</span><span class="p">,</span>
      <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">num_warmup_steps</span><span class="p">,</span>
      <span class="n">optimizer_type</span><span class="o">=</span><span class="s1">&#39;adamw&#39;</span><span class="p">)</span>

  <span class="n">classifier_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">metrics</span><span class="p">])</span>

  <span class="n">classifier_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
      <span class="n">x</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
      <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
      <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
      <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Export-for-inference">
<h2>Export for inference<a class="headerlink" href="#Export-for-inference" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You will create a final model that has the preprocessing part and the fine-tuned BERT we’ve just created.</p>
<p>At inference time, preprocessing needs to be part of the model (because there is no longer a separate input queue as for training data that does it). Preprocessing is not just computation; it has its own resources (the vocab table) that must be attached to the Keras Model that is saved for export. This final assembly is what will be saved.</p>
<p>You are going to save the model on colab and later you can download to keep it for the future (<strong>View -&gt; Table of contents -&gt; Files</strong>).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">main_save_path</span> <span class="o">=</span> <span class="s1">&#39;./my_models&#39;</span>
<span class="n">bert_type</span> <span class="o">=</span> <span class="n">tfhub_handle_encoder</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="n">saved_model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">tfds_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="p">)</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">bert_type</span><span class="si">}</span><span class="s1">&#39;</span>

<span class="n">saved_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">main_save_path</span><span class="p">,</span> <span class="n">saved_model_name</span><span class="p">)</span>

<span class="n">preprocess_inputs</span> <span class="o">=</span> <span class="n">bert_preprocess_model</span><span class="o">.</span><span class="n">inputs</span>
<span class="n">bert_encoder_inputs</span> <span class="o">=</span> <span class="n">bert_preprocess_model</span><span class="p">(</span><span class="n">preprocess_inputs</span><span class="p">)</span>
<span class="n">bert_outputs</span> <span class="o">=</span> <span class="n">classifier_model</span><span class="p">(</span><span class="n">bert_encoder_inputs</span><span class="p">)</span>
<span class="n">model_for_export</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">preprocess_inputs</span><span class="p">,</span> <span class="n">bert_outputs</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Saving&#39;</span><span class="p">,</span> <span class="n">saved_model_path</span><span class="p">)</span>

<span class="c1"># Save everything on the Colab host (even the variables from TPU memory)</span>
<span class="n">save_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">SaveOptions</span><span class="p">(</span><span class="n">experimental_io_device</span><span class="o">=</span><span class="s1">&#39;/job:localhost&#39;</span><span class="p">)</span>
<span class="n">model_for_export</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">saved_model_path</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                      <span class="n">options</span><span class="o">=</span><span class="n">save_options</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Test-the-model">
<h2>Test the model<a class="headerlink" href="#Test-the-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>The final step is testing the results of your exported model.</p>
<p>Just to make some comparison, let’s reload the model and test it using some inputs from the test split from the dataset.</p>
<p>Note: The test is done on the colab host, not the TPU worker that it has connected to, so it appears below with explicit device placements. You can omit those when loading the SavedModel elsewhere.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/job:localhost&#39;</span><span class="p">):</span>
  <span class="n">reloaded_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">saved_model_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#@title Utility methods</span>

<span class="k">def</span> <span class="nf">prepare</span><span class="p">(</span><span class="n">record</span><span class="p">):</span>
  <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">[[</span><span class="n">record</span><span class="p">[</span><span class="n">ft</span><span class="p">]]</span> <span class="k">for</span> <span class="n">ft</span> <span class="ow">in</span> <span class="n">sentence_features</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">model_inputs</span>


<span class="k">def</span> <span class="nf">prepare_serving</span><span class="p">(</span><span class="n">record</span><span class="p">):</span>
  <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">ft</span><span class="p">:</span> <span class="n">record</span><span class="p">[</span><span class="n">ft</span><span class="p">]</span> <span class="k">for</span> <span class="n">ft</span> <span class="ow">in</span> <span class="n">sentence_features</span><span class="p">}</span>
  <span class="k">return</span> <span class="n">model_inputs</span>


<span class="k">def</span> <span class="nf">print_bert_results</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">bert_result</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">):</span>

  <span class="n">bert_result_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">bert_result</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">if</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/cola&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;This sentence is acceptable&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;This sentence is unacceptable&#39;</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/sst2&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;This sentence has POSITIVE sentiment&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;This sentence has NEGATIVE sentiment&#39;</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/mrpc&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence1:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence2:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Are a paraphrase&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Are NOT a paraphrase&#39;</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/qqp&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;question1:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;question2:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Questions are similar&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Questions are NOT similar&#39;</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/mnli&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;premise   :&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;hypothesis:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;This premise is NEUTRAL to the hypothesis&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;This premise CONTRADICTS the hypothesis&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;This premise ENTAILS the hypothesis&#39;</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/qnli&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;question:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The question is NOT answerable by the sentence&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The question is answerable by the sentence&#39;</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/rte&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence1:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence2:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sentence1 DOES NOT entails sentence2&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sentence1 entails sentence2&#39;</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">dataset_name</span> <span class="o">==</span> <span class="s1">&#39;glue/wnli&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence1:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sentence2:&#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">bert_result_class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sentence1 DOES NOT entails sentence2&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sentence1 entails sentence2&#39;</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BERT raw results:&#39;</span><span class="p">,</span> <span class="n">bert_result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="Test">
<h3>Test<a class="headerlink" href="#Test" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/job:localhost&#39;</span><span class="p">):</span>
  <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">in_memory_ds</span><span class="p">[</span><span class="n">test_split</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">test_row</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence_features</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">reloaded_model</span><span class="p">(</span><span class="n">test_row</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">reloaded_model</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_row</span><span class="p">))</span>

    <span class="n">print_bert_results</span><span class="p">(</span><span class="n">test_row</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">tfds_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If you want to use your model on <a class="reference external" href="https://www.tensorflow.org/tfx/guide/serving">TF Serving</a>, remember that it will call your SavedModel through one of its named signatures. Notice there are some small differences in the input. In Python, you can test them as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/job:localhost&#39;</span><span class="p">):</span>
  <span class="n">serving_model</span> <span class="o">=</span> <span class="n">reloaded_model</span><span class="o">.</span><span class="n">signatures</span><span class="p">[</span><span class="s1">&#39;serving_default&#39;</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">test_row</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare_serving</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">serving_model</span><span class="p">(</span><span class="o">**</span><span class="n">test_row</span><span class="p">)</span>
    <span class="c1"># The &#39;prediction&#39; key is the classifier&#39;s defined model name.</span>
    <span class="n">print_bert_results</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_row</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">],</span> <span class="n">tfds_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>You did it! Your saved model could be used for serving or simple inference in a process, with a simpler api with less code and easier to maintain.</p>
</div>
</div>
<div class="section" id="Next-Steps">
<h2>Next Steps<a class="headerlink" href="#Next-Steps" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Now that you’ve tried one of the base BERT models, you can try other ones to achieve more accuracy or maybe with smaller model versions.</p>
<p>You can also try in other datasets.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Construido con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>