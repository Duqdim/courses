

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Decoding API &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
        <script src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Decoding API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Text/1-14_decoding_api_in_tf_nlp.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Decoding-API">
<h1>Decoding API<a class="headerlink" href="#Decoding-API" title="Enlazar permanentemente con este título">¶</a></h1>
<p>This API provides an interface to experiment with different decoding strategies used for auto-regressive models.</p>
<ol class="arabic simple">
<li><p>The following sampling strategies are provided in sampling_module.py, which inherits from the base Decoding class:</p></li>
</ol>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.09751">top_p</a> : <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/nlp/modeling/ops/sampling_module.py#L65">github</a></p>
<p>This implementation chooses most probable logits with cumulative probabilities upto top_p.</p>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1805.04833.pdf">top_k</a> : <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/nlp/modeling/ops/sampling_module.py#L48">github</a></p>
<p>At each timestep, this implementation samples from top-k logits based on their probability distribution</p>
</li>
<li><p>Greedy : <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/nlp/modeling/ops/sampling_module.py#L26">github</a></p>
<p>This implementation returns the top logits based on probabilities.</p>
</li>
</ul>
<ol class="arabic" start="2">
<li><p>Beam search is provided in beam_search.py. <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/nlp/modeling/ops/beam_search.py">github</a></p>
<p>This implementation reduces the risk of missing hidden high probability logits by keeping the most likely num_beams of logits at each time step and eventually choosing the logits that has the overall highest probability.</p>
</li>
</ol>
<div class="section" id="Install-the-TensorFlow-Model-Garden-pip-package">
<h2>Install the TensorFlow Model Garden pip package<a class="headerlink" href="#Install-the-TensorFlow-Model-Garden-pip-package" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tf-models-official</span></code> is the stable Model Garden package. Note that it may not include the latest changes in the <code class="docutils literal notranslate"><span class="pre">tensorflow_models</span></code> github repo. To include latest changes, you may install <code class="docutils literal notranslate"><span class="pre">tf-models-nightly</span></code>, which is the nightly Model Garden package created daily automatically.</p></li>
<li><p>pip will install all models and dependencies automatically.</p></li>
</ul>
<table class="tfo-notebook-buttons" align="left"><td><p><a href="#id1"><span class="problematic" id="id2">|</span></a>78b8b59bf95e405181489f745d774c2d|View on TensorFlow.org</p>
</td><td><p><a href="#id3"><span class="problematic" id="id4">|</span></a>4b943ab7eb0342f68d2591ba2229cb2d|Run in Google Colab</p>
</td><td><p><a href="#id5"><span class="problematic" id="id6">|</span></a>9b5640be20ed4342a8b22f012daac893|View source on GitHub</p>
</td><td><p><a href="#id7"><span class="problematic" id="id8">|</span></a>2b5f87670c504c50b43eb90d26d08953|Download notebook</p>
</td></table><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pip</span> <span class="n">install</span>  <span class="n">tf</span><span class="o">-</span><span class="n">models</span><span class="o">-</span><span class="n">nightly</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">official</span> <span class="kn">import</span> <span class="n">nlp</span>
<span class="kn">from</span> <span class="nn">official.nlp.modeling.ops</span> <span class="kn">import</span> <span class="n">sampling_module</span>
<span class="kn">from</span> <span class="nn">official.nlp.modeling.ops</span> <span class="kn">import</span> <span class="n">beam_search</span>
</pre></div>
</div>
</div>
<div class="section" id="Initialize-Sampling-Module-in-TF-NLP.">
<h3>Initialize Sampling Module in TF-NLP.<a class="headerlink" href="#Initialize-Sampling-Module-in-TF-NLP." title="Enlazar permanentemente con este título">¶</a></h3>
<blockquote>
<div><p><strong>symbols_to_logits_fn</strong> : This is a closure implemented by the users of the API. The input to this closure will be</p>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Args:
  1] ids [batch_size, .. (index + 1 or 1 if padded_decode is True)],
  2] index [scalar] : current decoded step,
  3] cache [nested dictionary of tensors].
Returns:
  1] tensor for next-step logits [batch_size, vocab]
  2] the updated_cache [nested dictionary of tensors].
</pre></div>
</div>
<p>This closure calls the model to predict the logits for the ‘index+1’ step. The cache is used for faster decoding. Here is a <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/nlp/modeling/ops/beam_search_test.py#L88">reference</a> implementation for the above closure.</p>
<blockquote>
<div><p><strong>length_normalization_fn</strong> : Closure for returning length normalization parameter.</p>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Args:
  1] length : scalar for decoded step index.
  2] dtype : data-type of output tensor
Returns:
  1] value of length normalization factor.
Example :
  def _length_norm(length, dtype):
    return tf.pow(((5. + tf.cast(length, dtype)) / 6.), 0.0)
</pre></div>
</div>
<blockquote>
<div><p><strong>vocab_size</strong> : Output vocabulary size.</p>
<p><strong>max_decode_length</strong> : Scalar for total number of decoding steps.</p>
</div></blockquote>
<blockquote>
<div><p><strong>eos_id</strong> : Decoding will stop if all output decoded ids in the batch have this ID.</p>
<p><strong>padded_decode</strong> : Set this to True if running on TPU. Tensors are padded to max_decoding_length if this is True.</p>
</div></blockquote>
<blockquote>
<div><p><strong>top_k</strong> : top_k is enabled if this value is &gt; 1.</p>
<p><strong>top_p</strong> : top_p is enabled if this value is &gt; 0 and &lt; 1.0</p>
</div></blockquote>
<blockquote>
<div><p><strong>sampling_temperature</strong> : This is used to re-estimate the softmax output. Temperature skews the distribution towards high probability tokens and lowers the mass in tail distribution. Value has to be positive. Low temperature is equivalent to greedy and makes the distribution sharper, while high temperature makes it more flat.</p>
<p><strong>enable_greedy</strong> : By default, this is true and greedy decoding is enabled.</p>
</div></blockquote>
</div>
</div>
</div>
<div class="section" id="Initialize-the-Model-Hyper-parameters">
<h1>Initialize the Model Hyper-parameters<a class="headerlink" href="#Initialize-the-Model-Hyper-parameters" title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_heads&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">params</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">params</span><span class="p">[</span><span class="s1">&#39;n_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
<p>In auto-regressive architectures like Transformer based <a class="reference external" href="https://arxiv.org/abs/1706.03762">Encoder-Decoder</a> models, Cache is used for fast sequential decoding. It is a nested dictionary storing pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention blocks) for every layer.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>{
    &#39;layer_%d&#39; % layer: {
        &#39;k&#39;: tf.zeros([params[&#39;batch_size&#39;], params[&#39;max_decode_length&#39;], params[&#39;num_heads&#39;], params[&#39;n_dims&#39;]/params[&#39;num_heads&#39;]], dtype=tf.float32),
        &#39;v&#39;: tf.zeros([params[&#39;batch_size&#39;], params[&#39;max_decode_length&#39;], params[&#39;num_heads&#39;], params[&#39;n_dims&#39;]/params[&#39;num_heads&#39;]], dtype=tf.float32)
        } for layer in range(params[&#39;num_layers&#39;]),
    &#39;model_specific_item&#39; : Model specific tensor shape,
}
</pre></div>
</div>
</div>
<div class="section" id="Initialize-cache.">
<h1>Initialize cache.<a class="headerlink" href="#Initialize-cache." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cache</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;k&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_heads&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;n_dims&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_heads&#39;</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
        <span class="s1">&#39;v&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_heads&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;n_dims&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_heads&#39;</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_layers&#39;</span><span class="p">])</span>
    <span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cache key shape for layer 1 :&quot;</span><span class="p">,</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;layer_1&#39;</span><span class="p">][</span><span class="s1">&#39;k&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Define-closure-for-length-normalization.-optional.">
<h1>Define closure for length normalization. <strong>optional.</strong><a class="headerlink" href="#Define-closure-for-length-normalization.-optional." title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">length_norm</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return length normalization factor.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(((</span><span class="mf">5.</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">))</span> <span class="o">/</span> <span class="mf">6.</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Create-model_fn">
<h1>Create model_fn<a class="headerlink" href="#Create-model_fn" title="Enlazar permanentemente con este título">¶</a></h1>
<p>In practice, this will be replaced by an actual model implementation such as <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/nlp/transformer/transformer.py#L236">here</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Args:
i : Step that is being decoded.
Returns:
  logit probabilities of size [batch_size, 1, vocab_size]
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">probabilities</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]],</span>
                            <span class="p">[[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]])</span>
<span class="k">def</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">probabilities</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Initialize-symbols_to_logits_fn">
<h1>Initialize symbols_to_logits_fn<a class="headerlink" href="#Initialize-symbols_to_logits_fn" title="Enlazar permanentemente con este título">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">_symbols_to_logits_fn</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;Calculates logits of the next tokens.&quot;&quot;&quot;</span>
  <span class="k">def</span> <span class="nf">symbols_to_logits_fn</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">temp_cache</span><span class="p">):</span>
    <span class="k">del</span> <span class="n">ids</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">model_fn</span><span class="p">(</span><span class="n">i</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">temp_cache</span>
  <span class="k">return</span> <span class="n">symbols_to_logits_fn</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Greedy">
<h1>Greedy<a class="headerlink" href="#Greedy" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Greedy decoding selects the token id with the highest probability as its next id: <span class="math notranslate nohighlight">\(id_t = argmax_{w}P(id | id_{1:t-1})\)</span> at each timestep <span class="math notranslate nohighlight">\(t\)</span>. The following sketch shows greedy decoding.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">greedy_obj</span> <span class="o">=</span> <span class="n">sampling_module</span><span class="o">.</span><span class="n">SamplingModule</span><span class="p">(</span>
    <span class="n">length_normalization_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="n">symbols_to_logits_fn</span><span class="o">=</span><span class="n">_symbols_to_logits_fn</span><span class="p">(),</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">max_decode_length</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span>
    <span class="n">eos_id</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">padded_decode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ids</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">greedy_obj</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">initial_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">initial_cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Greedy Decoded Ids:&quot;</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="top_k-sampling">
<h1>top_k sampling<a class="headerlink" href="#top_k-sampling" title="Enlazar permanentemente con este título">¶</a></h1>
<p>In <em>Top-K</em> sampling, the <em>K</em> most likely next token ids are filtered and the probability mass is redistributed among only those <em>K</em> ids.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">top_k_obj</span> <span class="o">=</span> <span class="n">sampling_module</span><span class="o">.</span><span class="n">SamplingModule</span><span class="p">(</span>
    <span class="n">length_normalization_fn</span><span class="o">=</span><span class="n">length_norm</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="n">symbols_to_logits_fn</span><span class="o">=</span><span class="n">_symbols_to_logits_fn</span><span class="p">(),</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">max_decode_length</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span>
    <span class="n">eos_id</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">sample_temperature</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
    <span class="n">top_k</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">padded_decode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_greedy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ids</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">top_k_obj</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">initial_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">initial_cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;top-k sampled Ids:&quot;</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="top_p-sampling">
<h1>top_p sampling<a class="headerlink" href="#top_p-sampling" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Instead of sampling only from the most likely <em>K</em> token ids, in <em>Top-p</em> sampling chooses from the smallest possible set of ids whose cumulative probability exceeds the probability <em>p</em>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">top_p_obj</span> <span class="o">=</span> <span class="n">sampling_module</span><span class="o">.</span><span class="n">SamplingModule</span><span class="p">(</span>
    <span class="n">length_normalization_fn</span><span class="o">=</span><span class="n">length_norm</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="n">symbols_to_logits_fn</span><span class="o">=</span><span class="n">_symbols_to_logits_fn</span><span class="p">(),</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">max_decode_length</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span>
    <span class="n">eos_id</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">sample_temperature</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
    <span class="n">top_p</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="n">padded_decode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_greedy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ids</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">top_p_obj</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">initial_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">initial_cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;top-p sampled Ids:&quot;</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Beam-search-decoding">
<h1>Beam search decoding<a class="headerlink" href="#Beam-search-decoding" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Beam search reduces the risk of missing hidden high probability token ids by keeping the most likely num_beams of hypotheses at each time step and eventually choosing the hypothesis that has the overall highest probability.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">beam_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">params</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">beam_cache</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;k&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_heads&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;n_dims&#39;</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
        <span class="s1">&#39;v&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_heads&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;n_dims&#39;</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_layers&#39;</span><span class="p">])</span>
    <span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cache key shape for layer 1 :&quot;</span><span class="p">,</span> <span class="n">beam_cache</span><span class="p">[</span><span class="s1">&#39;layer_1&#39;</span><span class="p">][</span><span class="s1">&#39;k&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ids</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">beam_search</span><span class="o">.</span><span class="n">sequence_beam_search</span><span class="p">(</span>
    <span class="n">symbols_to_logits_fn</span><span class="o">=</span><span class="n">_symbols_to_logits_fn</span><span class="p">(),</span>
    <span class="n">initial_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">9</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
    <span class="n">initial_cache</span><span class="o">=</span><span class="n">beam_cache</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">beam_size</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">max_decode_length</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_decode_length&#39;</span><span class="p">],</span>
    <span class="n">eos_id</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">padded_decode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Beam search ids:&quot;</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>