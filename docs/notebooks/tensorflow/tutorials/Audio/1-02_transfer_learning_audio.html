

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Transfer Learning with YAMNet for environmental sound classification &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../../../_static/clipboard.min.js"></script>
        <script type="text/javascript" src="../../../../_static/copybutton.js"></script>
        <script type="text/javascript" src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" />
    <link rel="next" title="Automatic Speech Recognition with Transformer" href="../../keras.io/audio/0-00_automatic_speech_recognition_with_transformer.html" />
    <link rel="prev" title="Simple audio recognition: Recognizing keywords" href="1-01_simple_audio.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-01">Sesión 01</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-02">Sesión 02</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-03">Sesión 03</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-04">Sesión 04</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-05">Sesión 05</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-06">Sesión 06</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-07">Sesión 07</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-08">Sesión 08</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-09">Sesión 09</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-10">Sesión 10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-11">Sesión 11</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-12">Sesión 12</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-13">Sesión 13</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-14">Sesión 14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-15">Sesión 15</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-16">Sesión 16</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a> &raquo;</li>
        
      <li>Transfer Learning with YAMNet for environmental sound classification</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Audio/1-02_transfer_learning_audio.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Transfer-Learning-with-YAMNet-for-environmental-sound-classification">
<h1>Transfer Learning with YAMNet for environmental sound classification<a class="headerlink" href="#Transfer-Learning-with-YAMNet-for-environmental-sound-classification" title="Enlazar permanentemente con este título">¶</a></h1>
<p><a class="reference external" href="https://tfhub.dev/google/yamnet/1">YAMNet</a> is an audio event classifier that can predict audio events from <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/audioset/yamnet/yamnet_class_map.csv">521 classes</a>, like laughter, barking, or a siren.</p>
<p>In this tutorial you will learn how to:</p>
<ul class="simple">
<li><p>Load and use the YAMNet model for inference.</p></li>
<li><p>Build a new model using the YAMNet embeddings to classify cat and dog sounds.</p></li>
<li><p>Evaluate and export your model.</p></li>
</ul>
<div class="section" id="Import-TensorFlow-and-other-libraries">
<h2>Import TensorFlow and other libraries<a class="headerlink" href="#Import-TensorFlow-and-other-libraries" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Start by installing <a class="reference external" href="https://www.tensorflow.org/io">TensorFlow I/O</a>, which will make it easier for you to load audio files off disk.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install tensorflow_io
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>
<span class="kn">import</span> <span class="nn">tensorflow_io</span> <span class="k">as</span> <span class="nn">tfio</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="About-YAMNet">
<h2>About YAMNet<a class="headerlink" href="#About-YAMNet" title="Enlazar permanentemente con este título">¶</a></h2>
<p>YAMNet is an audio event classifier that takes audio waveform as input and makes independent predictions for each of 521 audio events from the <a class="reference external" href="https://research.google.com/audioset/">AudioSet</a> ontology.</p>
<p>Internally, the model extracts “frames” from the audio signal and processes batches of these frames. This version of the model uses frames that are 0.96s long and extracts one frame every 0.48s.</p>
<p>The model accepts a 1-D float32 Tensor or NumPy array containing a waveform of arbitrary length, represented as mono 16 kHz samples in the range <code class="docutils literal notranslate"><span class="pre">[-1.0,</span> <span class="pre">+1.0]</span></code>. This tutorial contains code to help you convert a <code class="docutils literal notranslate"><span class="pre">.wav</span></code> file into the correct format.</p>
<p>The model returns 3 outputs, including the class scores, embeddings (which you will use for transfer learning), and the log mel spectrogram. You can find more details <a class="reference external" href="https://tfhub.dev/google/yamnet/1">here</a>, and this tutorial will walk you through using these in practice.</p>
<p>One specific use of YAMNet is as a high-level feature extractor: the <code class="docutils literal notranslate"><span class="pre">1024-D</span></code> embedding output of YAMNet can be used as the input features of another shallow model which can then be trained on a small amount of data for a particular task. This allows the quick creation of specialized audio classifiers without requiring a lot of labeled data and without having to train a large model end-to-end.</p>
<p>You will use YAMNet’s embeddings output for transfer learning and train one or more <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">Dense</a> layers on top of this.</p>
<p>First, you will try the model and see the results of classifying audio. You will then construct the data pre-processing pipeline.</p>
<div class="section" id="Loading-YAMNet-from-TensorFlow-Hub">
<h3>Loading YAMNet from TensorFlow Hub<a class="headerlink" href="#Loading-YAMNet-from-TensorFlow-Hub" title="Enlazar permanentemente con este título">¶</a></h3>
<p>You are going to use YAMNet from <a class="reference external" href="https://tfhub.dev/">Tensorflow Hub</a> to extract the embeddings from the sound files.</p>
<p>Loading a model from TensorFlow Hub is straightforward: choose the model, copy its URL and use the <code class="docutils literal notranslate"><span class="pre">load</span></code> function.</p>
<p>Note: to read the documentation of the model, you can use the model url in your browser.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">yamnet_model_handle</span> <span class="o">=</span> <span class="s1">&#39;https://tfhub.dev/google/yamnet/1&#39;</span>
<span class="n">yamnet_model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">yamnet_model_handle</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>With the model loaded and following the <a class="reference external" href="https://www.tensorflow.org/hub/tutorials/yamnet">models’s basic usage tutorial</a> you’ll download a sample wav file and run the inference.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">testing_wav_file_name</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="s1">&#39;miaow_16k.wav&#39;</span><span class="p">,</span>
                                                <span class="s1">&#39;https://storage.googleapis.com/audioset/miaow_16k.wav&#39;</span><span class="p">,</span>
                                                <span class="n">cache_dir</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span>
                                                <span class="n">cache_subdir</span><span class="o">=</span><span class="s1">&#39;test_data&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">testing_wav_file_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>You will need a function to load the audio files. They will also be used later when working with the training data.</p>
<p>Note: The returned <code class="docutils literal notranslate"><span class="pre">wav_data</span></code> from <code class="docutils literal notranslate"><span class="pre">load_wav_16k_mono</span></code> is already normalized to values in <code class="docutils literal notranslate"><span class="pre">[-1.0,</span> <span class="pre">1.0]</span></code> (as stated in the model’s <a class="reference external" href="https://tfhub.dev/google/yamnet/1">documentation</a>).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Util functions for loading audio files and ensure the correct sample rate</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">load_wav_16k_mono</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; read in a waveform file and convert to 16 kHz mono &quot;&quot;&quot;</span>
    <span class="n">file_contents</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">wav</span><span class="p">,</span> <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">audio</span><span class="o">.</span><span class="n">decode_wav</span><span class="p">(</span>
          <span class="n">file_contents</span><span class="p">,</span>
          <span class="n">desired_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">wav</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">wav</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">wav</span> <span class="o">=</span> <span class="n">tfio</span><span class="o">.</span><span class="n">audio</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="n">wav</span><span class="p">,</span> <span class="n">rate_in</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">rate_out</span><span class="o">=</span><span class="mi">16000</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wav</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">testing_wav_data</span> <span class="o">=</span> <span class="n">load_wav_16k_mono</span><span class="p">(</span><span class="n">testing_wav_file_name</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">testing_wav_data</span><span class="p">)</span>

<span class="c1"># Play the audio file.</span>
<span class="n">display</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span><span class="n">testing_wav_data</span><span class="p">,</span><span class="n">rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Load-the-class-mapping">
<h3>Load the class mapping<a class="headerlink" href="#Load-the-class-mapping" title="Enlazar permanentemente con este título">¶</a></h3>
<p>It’s important to load the class names that YAMNet is able to recognize. The mapping file is present at <code class="docutils literal notranslate"><span class="pre">yamnet_model.class_map_path()</span></code>, in the <code class="docutils literal notranslate"><span class="pre">csv</span></code> format.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">class_map_path</span> <span class="o">=</span> <span class="n">yamnet_model</span><span class="o">.</span><span class="n">class_map_path</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">class_names</span> <span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">class_map_path</span><span class="p">)[</span><span class="s1">&#39;display_name&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">class_names</span><span class="p">[:</span><span class="mi">20</span><span class="p">]:</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;...&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Run-inference">
<h3>Run inference<a class="headerlink" href="#Run-inference" title="Enlazar permanentemente con este título">¶</a></h3>
<p>YAMNet provides frame-level class-scores (i.e., 521 scores for every frame). In order to determine clip-level predictions, the scores can be aggregated per-class across frames (e.g., using mean or max aggregation). This is done below by <code class="docutils literal notranslate"><span class="pre">scores_np.mean(axis=0)</span></code>. Finally, in order to find the top-scored class at the clip-level, we take the maximum of the 521 aggregated scores.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">scores</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">yamnet_model</span><span class="p">(</span><span class="n">testing_wav_data</span><span class="p">)</span>
<span class="n">class_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">top_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">class_scores</span><span class="p">)</span>
<span class="n">infered_class</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="n">top_class</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The main sound is: </span><span class="si">{</span><span class="n">infered_class</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The embeddings shape: </span><span class="si">{</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note: The model correctly inferred an animal sound. Your goal is to increase accuracy for specific classes. Also, notice that the the model generated 13 embeddings, 1 per frame.</p>
</div>
</div>
<div class="section" id="ESC-50-dataset">
<h2>ESC-50 dataset<a class="headerlink" href="#ESC-50-dataset" title="Enlazar permanentemente con este título">¶</a></h2>
<p>The <a class="reference external" href="https://github.com/karolpiczak/ESC-50#repository-content">ESC-50 dataset</a>, well described <a class="reference external" href="https://www.karolpiczak.com/papers/Piczak2015-ESC-Dataset.pdf">here</a>, is a labeled collection of 2000 environmental audio recordings (each 5 seconds long). The data consists of 50 classes, with 40 examples per class.</p>
<p>Next, you will download and extract it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="s1">&#39;esc-50.zip&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;https://github.com/karoldvl/ESC-50/archive/master.zip&#39;</span><span class="p">,</span>
                        <span class="n">cache_dir</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span>
                        <span class="n">cache_subdir</span><span class="o">=</span><span class="s1">&#39;datasets&#39;</span><span class="p">,</span>
                        <span class="n">extract</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Explore-the-data">
<h3>Explore the data<a class="headerlink" href="#Explore-the-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>The metadata for each file is specified in the csv file at <code class="docutils literal notranslate"><span class="pre">./datasets/ESC-50-master/meta/esc50.csv</span></code></p>
<p>and all the audio files are in <code class="docutils literal notranslate"><span class="pre">./datasets/ESC-50-master/audio/</span></code></p>
<p>You will create a pandas dataframe with the mapping and use that to have a clearer view of the data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">esc50_csv</span> <span class="o">=</span> <span class="s1">&#39;./datasets/ESC-50-master/meta/esc50.csv&#39;</span>
<span class="n">base_data_path</span> <span class="o">=</span> <span class="s1">&#39;./datasets/ESC-50-master/audio/&#39;</span>

<span class="n">pd_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">esc50_csv</span><span class="p">)</span>
<span class="n">pd_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Filter-the-data">
<h3>Filter the data<a class="headerlink" href="#Filter-the-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Given the data on the dataframe, you will apply some transformations:</p>
<ul class="simple">
<li><p>filter out rows and use only the selected classes (dog and cat). If you want to use any other classes, this is where you can choose them.</p></li>
<li><p>change the filename to have the full path. This will make loading easier later.</p></li>
<li><p>change targets to be within a specific range. In this example, dog will remain 0, but cat will become 1 instead of its original value of 5.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">my_classes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">]</span>
<span class="n">map_class_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;dog&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>

<span class="n">filtered_pd</span> <span class="o">=</span> <span class="n">pd_data</span><span class="p">[</span><span class="n">pd_data</span><span class="o">.</span><span class="n">category</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">my_classes</span><span class="p">)]</span>

<span class="n">class_id</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="n">map_class_to_id</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
<span class="n">filtered_pd</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">class_id</span><span class="p">)</span>

<span class="n">full_path</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_data_path</span><span class="p">,</span> <span class="n">row</span><span class="p">))</span>
<span class="n">filtered_pd</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">full_path</span><span class="p">)</span>

<span class="n">filtered_pd</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Load-the-audio-files-and-retrieve-embeddings">
<h3>Load the audio files and retrieve embeddings<a class="headerlink" href="#Load-the-audio-files-and-retrieve-embeddings" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Here you’ll apply the <code class="docutils literal notranslate"><span class="pre">load_wav_16k_mono</span></code> and prepare the wav data for the model.</p>
<p>When extracting embeddings from the wav data, you get an array of shape <code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">1024)</span></code> where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of frames that YAMNet found (one for every 0.48 seconds of audio).</p>
<p>Your model will use each frame as one input so you need to to create a new column that has one frame per row. You also need to expand the labels and fold column to proper reflect these new rows.</p>
<p>The expanded fold column keeps the original value. You cannot mix frames because, when doing the splits, you might end with parts of the same audio on different splits and that would make our validation and test steps less effective.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">filenames</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">folds</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="p">[</span><span class="s1">&#39;fold&#39;</span><span class="p">]</span>

<span class="n">main_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">filenames</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">folds</span><span class="p">))</span>
<span class="n">main_ds</span><span class="o">.</span><span class="n">element_spec</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">load_wav_for_map</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fold</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">load_wav_16k_mono</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span> <span class="n">label</span><span class="p">,</span> <span class="n">fold</span>

<span class="n">main_ds</span> <span class="o">=</span> <span class="n">main_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">load_wav_for_map</span><span class="p">)</span>
<span class="n">main_ds</span><span class="o">.</span><span class="n">element_spec</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># applies the embedding extraction model to a wav data</span>
<span class="k">def</span> <span class="nf">extract_embedding</span><span class="p">(</span><span class="n">wav_data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fold</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39; run YAMNet to extract embedding from the wav data &#39;&#39;&#39;</span>
  <span class="n">scores</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">yamnet_model</span><span class="p">(</span><span class="n">wav_data</span><span class="p">)</span>
  <span class="n">num_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">embeddings</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">num_embeddings</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">fold</span><span class="p">,</span> <span class="n">num_embeddings</span><span class="p">))</span>

<span class="c1"># extract embedding</span>
<span class="n">main_ds</span> <span class="o">=</span> <span class="n">main_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">extract_embedding</span><span class="p">)</span><span class="o">.</span><span class="n">unbatch</span><span class="p">()</span>
<span class="n">main_ds</span><span class="o">.</span><span class="n">element_spec</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Split-the-data">
<h3>Split the data<a class="headerlink" href="#Split-the-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>You will use the <code class="docutils literal notranslate"><span class="pre">fold</span></code> column to split the dataset into train, validation and test.</p>
<p>The fold values are so that files from the same original wav file are keep on the same split, you can find more information on the <a class="reference external" href="https://www.karolpiczak.com/papers/Piczak2015-ESC-Dataset.pdf">paper</a> describing the dataset.</p>
<p>The last step is to remove the <code class="docutils literal notranslate"><span class="pre">fold</span></code> column from the dataset since we’re not going to use it anymore on the training process.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cached_ds</span> <span class="o">=</span> <span class="n">main_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">cached_ds</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fold</span><span class="p">:</span> <span class="n">fold</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">cached_ds</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fold</span><span class="p">:</span> <span class="n">fold</span> <span class="o">==</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">cached_ds</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fold</span><span class="p">:</span> <span class="n">fold</span> <span class="o">==</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># remove the folds column now that it&#39;s not needed anymore</span>
<span class="n">remove_fold_column</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">fold</span><span class="p">:</span> <span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">remove_fold_column</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">remove_fold_column</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">remove_fold_column</span><span class="p">)</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Create-your-model">
<h2>Create your model<a class="headerlink" href="#Create-your-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You did most of the work! Next, define a very simple Sequential Model to start with – one hiden layer and 2 outputs to recognize cats and dogs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">my_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1024</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_embedding&#39;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">my_classes</span><span class="p">))</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_model&#39;</span><span class="p">)</span>

<span class="n">my_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">my_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                 <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
                 <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
                                            <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                            <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">history</span> <span class="o">=</span> <span class="n">my_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span>
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                       <span class="n">validation_data</span><span class="o">=</span><span class="n">val_ds</span><span class="p">,</span>
                       <span class="n">callbacks</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Lets run the evaluate method on the test data just to be sure there’s no overfitting.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">my_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss: &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>You did it!</p>
</div>
<div class="section" id="Test-your-model">
<h2>Test your model<a class="headerlink" href="#Test-your-model" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Next, try your model on the embedding from the previous test using YAMNet only.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">scores</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">yamnet_model</span><span class="p">(</span><span class="n">testing_wav_data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">infered_class</span> <span class="o">=</span> <span class="n">my_classes</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The main sound is: </span><span class="si">{</span><span class="n">infered_class</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Save-a-model-that-can-directly-take-a-wav-file-as-input">
<h2>Save a model that can directly take a wav file as input<a class="headerlink" href="#Save-a-model-that-can-directly-take-a-wav-file-as-input" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Your model works when you give it the embeddings as input.</p>
<p>In a real situation you’ll want to give it the sound data directly.</p>
<p>To do that you will combine YAMNet with your model into one single model that you can export for other applications.</p>
<p>To make it easier to use the model’s result, the final layer will be a <code class="docutils literal notranslate"><span class="pre">reduce_mean</span></code> operation. When using this model for serving, as you will see bellow, you will need the name of the final layer. If you don’t define one, TF will auto define an incremental one that makes it hard to test as it will keep changing everytime you train the model. When using a raw tf operation you can’t assign a name to it. To address this issue, you’ll create a custom layer that just apply <code class="docutils literal notranslate"><span class="pre">reduce_mean</span></code> and you
will call it ‘classifier’.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">ReduceMeanLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceMeanLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">saved_model_path</span> <span class="o">=</span> <span class="s1">&#39;./dogs_and_cats_yamnet&#39;</span>

<span class="n">input_segment</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;audio&#39;</span><span class="p">)</span>
<span class="n">embedding_extraction_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">yamnet_model_handle</span><span class="p">,</span>
                                            <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;yamnet&#39;</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">embeddings_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">embedding_extraction_layer</span><span class="p">(</span><span class="n">input_segment</span><span class="p">)</span>
<span class="n">serving_outputs</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">embeddings_output</span><span class="p">)</span>
<span class="n">serving_outputs</span> <span class="o">=</span> <span class="n">ReduceMeanLayer</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;classifier&#39;</span><span class="p">)(</span><span class="n">serving_outputs</span><span class="p">)</span>
<span class="n">serving_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">input_segment</span><span class="p">,</span> <span class="n">serving_outputs</span><span class="p">)</span>
<span class="n">serving_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">saved_model_path</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">serving_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Load your saved model to verify that it works as expected.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">reloaded_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">saved_model_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>And for the final test: given some sound data, does your model return the correct result?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">reloaded_results</span> <span class="o">=</span> <span class="n">reloaded_model</span><span class="p">(</span><span class="n">testing_wav_data</span><span class="p">)</span>
<span class="n">cat_or_dog</span> <span class="o">=</span> <span class="n">my_classes</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">reloaded_results</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The main sound is: </span><span class="si">{</span><span class="n">cat_or_dog</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If you want to try your new model on a serving setup, you can use the ‘serving_default’ signature.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">serving_results</span> <span class="o">=</span> <span class="n">reloaded_model</span><span class="o">.</span><span class="n">signatures</span><span class="p">[</span><span class="s1">&#39;serving_default&#39;</span><span class="p">](</span><span class="n">testing_wav_data</span><span class="p">)</span>
<span class="n">cat_or_dog</span> <span class="o">=</span> <span class="n">my_classes</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">serving_results</span><span class="p">[</span><span class="s1">&#39;classifier&#39;</span><span class="p">])]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The main sound is: </span><span class="si">{</span><span class="n">cat_or_dog</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

</pre></div>
</div>
</div>
</div>
<div class="section" id="(Optional)-Some-more-testing">
<h2>(Optional) Some more testing<a class="headerlink" href="#(Optional)-Some-more-testing" title="Enlazar permanentemente con este título">¶</a></h2>
<p>The model is ready.</p>
<p>Let’s compare it to YAMNet on the test dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_pd</span> <span class="o">=</span> <span class="n">filtered_pd</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">filtered_pd</span><span class="p">[</span><span class="s1">&#39;fold&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">row</span> <span class="o">=</span> <span class="n">test_pd</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">waveform</span> <span class="o">=</span> <span class="n">load_wav_16k_mono</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Waveform values: </span><span class="si">{</span><span class="n">waveform</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>

<span class="n">display</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span><span class="n">waveform</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Run the model, check the output.</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">yamnet_model</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>
<span class="n">class_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">top_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">class_scores</span><span class="p">)</span>
<span class="n">infered_class</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="n">top_class</span><span class="p">]</span>
<span class="n">top_score</span> <span class="o">=</span> <span class="n">class_scores</span><span class="p">[</span><span class="n">top_class</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[YAMNet] The main sound is: </span><span class="si">{</span><span class="n">infered_class</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">top_score</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="n">reloaded_results</span> <span class="o">=</span> <span class="n">reloaded_model</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>
<span class="n">your_top_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">reloaded_results</span><span class="p">)</span>
<span class="n">your_infered_class</span> <span class="o">=</span> <span class="n">my_classes</span><span class="p">[</span><span class="n">your_top_class</span><span class="p">]</span>
<span class="n">class_probabilities</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">reloaded_results</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">your_top_score</span> <span class="o">=</span> <span class="n">class_probabilities</span><span class="p">[</span><span class="n">your_top_class</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[Your model] The main sound is: </span><span class="si">{</span><span class="n">your_infered_class</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">your_top_score</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Next-steps">
<h2>Next steps<a class="headerlink" href="#Next-steps" title="Enlazar permanentemente con este título">¶</a></h2>
<p>You just created a model that can classify sounds from dogs or cats. With the same idea and proper data you could, for example, build a bird recognizer based on their singing.</p>
<p>Let us know what you come up with! Share with on social media your project.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>