

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>TF.Text &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
        <script src="../../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>TF.Text</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/notebooks/tensorflow/tutorials/Load_and_process_data/1-07_TF.Text.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="TF.Text">
<h1>TF.Text<a class="headerlink" href="#TF.Text" title="Enlazar permanentemente con este título">¶</a></h1>
<div class="section" id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Enlazar permanentemente con este título">¶</a></h2>
<p>TensorFlow Text provides a collection of text related classes and ops ready to use with TensorFlow 2.0. The library can perform the preprocessing regularly required by text-based models, and includes other features useful for sequence modeling not provided by core TensorFlow.</p>
<p>The benefit of using these ops in your text preprocessing is that they are done in the TensorFlow graph. You do not need to worry about tokenization in training being different than the tokenization at inference, or managing preprocessing scripts.</p>
</div>
<div class="section" id="Eager-Execution">
<h2>Eager Execution<a class="headerlink" href="#Eager-Execution" title="Enlazar permanentemente con este título">¶</a></h2>
<p>TensorFlow Text requires TensorFlow 2.0, and is fully compatible with eager mode and graph mode.</p>
<hr class="docutils" />
<p>Note: On rare occassions, this import may fail looking for the TF library. Please reset the runtime and rerun the pip install below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install tensorflow-text
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_text</span> <span class="k">as</span> <span class="nn">text</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Unicode">
<h2>Unicode<a class="headerlink" href="#Unicode" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Most ops expect that the strings are in UTF-8. If you’re using a different encoding, you can use the core tensorflow transcode op to transcode into UTF-8. You can also use the same op to coerce your string to structurally valid UTF-8 if your input could be invalid.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="sa">u</span><span class="s1">&#39;Everything not saved will be lost.&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-16-BE&#39;</span><span class="p">),</span> <span class="sa">u</span><span class="s1">&#39;Sad☹&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-16-BE&#39;</span><span class="p">)])</span>
<span class="n">utf8_docs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">unicode_transcode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">input_encoding</span><span class="o">=</span><span class="s1">&#39;UTF-16-BE&#39;</span><span class="p">,</span> <span class="n">output_encoding</span><span class="o">=</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Tokenization">
<h2>Tokenization<a class="headerlink" href="#Tokenization" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Tokenization is the process of breaking up a string into tokens. Commonly, these tokens are words, numbers, and/or punctuation.</p>
<p>The main interfaces are <code class="docutils literal notranslate"><span class="pre">Tokenizer</span></code> and <code class="docutils literal notranslate"><span class="pre">TokenizerWithOffsets</span></code> which each have a single method <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> and <code class="docutils literal notranslate"><span class="pre">tokenize_with_offsets</span></code> respectively. There are multiple tokenizers available now. Each of these implement <code class="docutils literal notranslate"><span class="pre">TokenizerWithOffsets</span></code> (which extends <code class="docutils literal notranslate"><span class="pre">Tokenizer</span></code>) which includes an option for getting byte offsets into the original string. This allows the caller to know the bytes in the original string the token was created from.</p>
<p>All of the tokenizers return RaggedTensors with the inner-most dimension of tokens mapping to the original individual strings. As a result, the resulting shape’s rank is increased by one. Please review the ragged tensor guide if you are unfamiliar with them. <a class="reference external" href="https://www.tensorflow.org/guide/ragged_tensors">ragged_tensors</a></p>
<div class="section" id="WhitespaceTokenizer">
<h3>WhitespaceTokenizer<a class="headerlink" href="#WhitespaceTokenizer" title="Enlazar permanentemente con este título">¶</a></h3>
<p>This is a basic tokenizer that splits UTF-8 strings on ICU defined whitespace characters (eg. space, tab, new line).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">([</span><span class="s1">&#39;everything not saved will be lost.&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;Sad☹&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="UnicodeScriptTokenizer">
<h3>UnicodeScriptTokenizer<a class="headerlink" href="#UnicodeScriptTokenizer" title="Enlazar permanentemente con este título">¶</a></h3>
<p>This tokenizer splits UTF-8 strings based on Unicode script boundaries. The script codes used correspond to International Components for Unicode (ICU) UScriptCode values. See: <a class="reference external" href="http://icu-project.org/apiref/icu4c/uscript_8h.html">http://icu-project.org/apiref/icu4c/uscript_8h.html</a></p>
<p>In practice, this is similar to the <code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code> with the most apparent difference being that it will split punctuation (USCRIPT_COMMON) from language texts (eg. USCRIPT_LATIN, USCRIPT_CYRILLIC, etc) while also separating language texts from each other.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeScriptTokenizer</span><span class="p">()</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">([</span><span class="s1">&#39;everything not saved will be lost.&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;Sad☹&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Unicode-split">
<h3>Unicode split<a class="headerlink" href="#Unicode-split" title="Enlazar permanentemente con este título">¶</a></h3>
<p>When tokenizing languages without whitespace to segment words, it is common to just split by character, which can be accomplished using the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/strings/unicode_split">unicode_split</a> op found in core.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">unicode_split</span><span class="p">([</span><span class="sa">u</span><span class="s2">&quot;仅今年前&quot;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)],</span> <span class="s1">&#39;UTF-8&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Offsets">
<h3>Offsets<a class="headerlink" href="#Offsets" title="Enlazar permanentemente con este título">¶</a></h3>
<p>When tokenizing strings, it is often desired to know where in the original string the token originated from. For this reason, each tokenizer which implements <code class="docutils literal notranslate"><span class="pre">TokenizerWithOffsets</span></code> has a <em>tokenize_with_offsets</em> method that will return the byte offsets along with the tokens. The start_offsets lists the bytes in the original string each token starts at, and the end_offsets lists the bytes immediately after the point where each token ends. Note: the start offsets are inclusive and the end offsets
are exclusive.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeScriptTokenizer</span><span class="p">()</span>
<span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">start_offsets</span><span class="p">,</span> <span class="n">end_offsets</span><span class="p">)</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize_with_offsets</span><span class="p">([</span><span class="s1">&#39;everything not saved will be lost.&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;Sad☹&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">start_offsets</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">end_offsets</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="TF.Data-Example">
<h3>TF.Data Example<a class="headerlink" href="#TF.Data-Example" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Tokenizers work as expected with the tf.data API. A simple example is provided below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">([[</span><span class="s1">&#39;Never tell me the odds.&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;It&#39;s a trap!&quot;</span><span class="p">]])</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">tokenized_docs</span> <span class="o">=</span> <span class="n">docs</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">tokenized_docs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Other-Text-Ops">
<h2>Other Text Ops<a class="headerlink" href="#Other-Text-Ops" title="Enlazar permanentemente con este título">¶</a></h2>
<p>TF.Text packages other useful preprocessing ops. We will review a couple below.</p>
<div class="section" id="Wordshape">
<h3>Wordshape<a class="headerlink" href="#Wordshape" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A common feature used in some natural language understanding models is to see if the text string has a certain property. For example, a sentence breaking model might contain features which check for word capitalization or if a punctuation character is at the end of a string.</p>
<p>Wordshape defines a variety of useful regular expression based helper functions for matching various relevant patterns in your input text. Here are a few examples.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">([</span><span class="s1">&#39;Everything not saved will be lost.&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;Sad☹&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)])</span>

<span class="c1"># Is capitalized?</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">wordshape</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">WordShape</span><span class="o">.</span><span class="n">HAS_TITLE_CASE</span><span class="p">)</span>
<span class="c1"># Are all letters uppercased?</span>
<span class="n">f2</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">wordshape</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">WordShape</span><span class="o">.</span><span class="n">IS_UPPERCASE</span><span class="p">)</span>
<span class="c1"># Does the token contain punctuation?</span>
<span class="n">f3</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">wordshape</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">WordShape</span><span class="o">.</span><span class="n">HAS_SOME_PUNCT_OR_SYMBOL</span><span class="p">)</span>
<span class="c1"># Is the token a number?</span>
<span class="n">f4</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">wordshape</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">WordShape</span><span class="o">.</span><span class="n">IS_NUMERIC_VALUE</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f1</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f2</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f3</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f4</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="N-grams-&amp;-Sliding-Window">
<h3>N-grams &amp; Sliding Window<a class="headerlink" href="#N-grams-&-Sliding-Window" title="Enlazar permanentemente con este título">¶</a></h3>
<p>N-grams are sequential words given a sliding window size of <em>n</em>. When combining the tokens, there are three reduction mechanisms supported. For text, you would want to use <code class="docutils literal notranslate"><span class="pre">Reduction.STRING_JOIN</span></code> which appends the strings to each other. The default separator character is a space, but this can be changed with the string_separater argument.</p>
<p>The other two reduction methods are most often used with numerical values, and these are <code class="docutils literal notranslate"><span class="pre">Reduction.SUM</span></code> and <code class="docutils literal notranslate"><span class="pre">Reduction.MEAN</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">([</span><span class="s1">&#39;Everything not saved will be lost.&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;Sad☹&#39;</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)])</span>

<span class="c1"># Ngrams, in this case bi-gram (n = 2)</span>
<span class="n">bigrams</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">ngrams</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">reduction_type</span><span class="o">=</span><span class="n">text</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">STRING_JOIN</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">bigrams</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>